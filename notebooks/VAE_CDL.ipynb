{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a70112b-9d34-4b02-afd5-5bc78744f481",
      "metadata": {
        "id": "6a70112b-9d34-4b02-afd5-5bc78744f481",
        "outputId": "0d75c931-c346-4384-b6af-088cb8e41a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.25.2-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\college\\miniconda3\\envs\\tfenv\\lib\\site-packages (from scikit-image) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\college\\miniconda3\\envs\\tfenv\\lib\\site-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\college\\miniconda3\\envs\\tfenv\\lib\\site-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in c:\\users\\college\\miniconda3\\envs\\tfenv\\lib\\site-packages (from scikit-image) (11.3.0)\n",
            "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
            "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\college\\miniconda3\\envs\\tfenv\\lib\\site-packages (from scikit-image) (24.2)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Downloading scikit_image-0.25.2-cp310-cp310-win_amd64.whl (12.8 MB)\n",
            "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.8/12.8 MB 4.2 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 2.1/12.8 MB 5.3 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 3.1/12.8 MB 5.3 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 4.2/12.8 MB 5.1 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 5.2/12.8 MB 5.0 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 6.8/12.8 MB 5.4 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 8.4/12.8 MB 5.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.0/12.8 MB 5.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.5/12.8 MB 6.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.6/12.8 MB 6.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.8/12.8 MB 5.9 MB/s eta 0:00:00\n",
            "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
            "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
            "\n",
            "   ---------------------------------------- 0/4 [tifffile]\n",
            "   ---------------------------------------- 0/4 [tifffile]\n",
            "   ---------- ----------------------------- 1/4 [lazy-loader]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   -------------------- ------------------- 2/4 [imageio]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ------------------------------ --------- 3/4 [scikit-image]\n",
            "   ---------------------------------------- 4/4 [scikit-image]\n",
            "\n",
            "Successfully installed imageio-2.37.0 lazy-loader-0.4 scikit-image-0.25.2 tifffile-2025.5.10\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d49a60-0889-4b33-9821-7fb31fc2c5f3",
      "metadata": {
        "id": "04d49a60-0889-4b33-9821-7fb31fc2c5f3"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions\n",
        "from torch.distributions import kl, multivariate_normal\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import sys, random\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import math\n",
        "import collections\n",
        "import pickle\n",
        "from shutil import copyfile\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import plot, title, xlabel, ylabel, savefig, legend\n",
        "\n",
        "from PIL import Image\n",
        "import shutil, os\n",
        "from os import listdir\n",
        "\n",
        "from skimage import transform\n",
        "from sklearn import metrics\n",
        "\n",
        "from multiprocessing import Pool\n",
        "import logging\n",
        "import torch.multiprocessing as mp\n",
        "import traceback\n",
        "from contextlib import closing\n",
        "\n",
        "import time\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import plot, title, xlabel, ylabel, savefig, legend\n",
        "from matplotlib import cm\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "reporttpraccuracy = True # True, False for attack, defence\n",
        "# reporttpraccuracy = False\n",
        "reporttprfscore = False # True, False for defence, attack\n",
        "# reporttprfscore = True\n",
        "\n",
        "sasearch = True # True for SA based linesearch\n",
        "\n",
        "rlsearch = False # False for scalars based linesearch\n",
        "\n",
        "attackmean=True\n",
        "\n",
        "attackvar=True\n",
        "\n",
        "savesaruns = False\n",
        "\n",
        "uniformsampling = False\n",
        "\n",
        "combinedattack = False\n",
        "\n",
        "\n",
        "combinedsinglesattack = True\n",
        "\n",
        "# klnorm = True\n",
        "klnorm = True\n",
        "vectornorm = False\n",
        "controlledthreshold_sa=True\n",
        "controlledthreshold_als=True\n",
        "controlledthreshold_game=True\n",
        "\n",
        "savemanipulations = False\n",
        "\n",
        "mnistdataset=False\n",
        "\n",
        "vggfacesdataset=True\n",
        "\n",
        "oldversion=False\n",
        "\n",
        "if (vggfacesdataset):\n",
        "    testvae=True\n",
        "    morelabels=False\n",
        "\n",
        "    vggface_image_length=64\n",
        "\n",
        "    layer_names = ['conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
        "                   'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
        "                   'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3', 'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
        "                   'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3', 'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
        "                   'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3', 'relu5_3', 'conv5_4', 'relu5_4', 'pool5']\n",
        "    vae123_layers = ['relu1_1', 'relu2_1', 'relu3_1']\n",
        "    vae345_layers = ['relu3_1', 'relu4_1', 'relu5_1']\n",
        "\n",
        "    codesize = 61\n",
        "\n",
        "    mylambda = 1.21\n",
        "    mynumsteps = 10000003\n",
        "\n",
        "    batcherror_threshold = 5\n",
        "trainvae = False\n",
        "traincnn = False\n",
        "\n",
        "gamepreprocess = True\n",
        "gamepostprocess = True\n",
        "\n",
        "benchmarkalphas = False\n",
        "benchmarkgasalphas = False\n",
        "benchmarksasalphas = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d190a8a3-c12e-4e81-a320-64b09b8ce402",
      "metadata": {
        "id": "d190a8a3-c12e-4e81-a320-64b09b8ce402"
      },
      "outputs": [],
      "source": [
        "def create_directory_structure():\n",
        "    \"\"\"Create the required directory structure for the project\"\"\"\n",
        "    directories = [\n",
        "        'data',\n",
        "        'data/MNIST',\n",
        "        'data/MNIST/raw',\n",
        "        'data/manipulations',\n",
        "        'data/manipulations/train',\n",
        "        'data/manipulations/test',\n",
        "        'data/originals',\n",
        "        'data/originals/train',\n",
        "        'data/originals/test',\n",
        "        'data/vggfaces2',\n",
        "        'data/manipulations',\n",
        "        'data/manipulations/train',\n",
        "        'data/manipulations/test',\n",
        "        'data/originals',\n",
        "        'data/originals/train',\n",
        "        'data/originals/test'\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        print(f\"Created directory: {directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f015b9-c3b5-4ddd-ab87-e4c1fec081a0",
      "metadata": {
        "id": "a2f015b9-c3b5-4ddd-ab87-e4c1fec081a0",
        "outputId": "40df9145-453a-4cc2-fc2e-a0ef651bc0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directory: data\n",
            "Created directory: data/MNIST\n",
            "Created directory: data/MNIST/raw\n",
            "Created directory: data/manipulations\n",
            "Created directory: data/manipulations/train\n",
            "Created directory: data/manipulations/test\n",
            "Created directory: data/originals\n",
            "Created directory: data/originals/train\n",
            "Created directory: data/originals/test\n",
            "Created directory: data/vggfaces2\n",
            "Created directory: data/manipulations\n",
            "Created directory: data/manipulations/train\n",
            "Created directory: data/manipulations/test\n",
            "Created directory: data/originals\n",
            "Created directory: data/originals/train\n",
            "Created directory: data/originals/test\n",
            "\n"
          ]
        }
      ],
      "source": [
        " # Step 1: Create directory structure\n",
        "create_directory_structure()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daa5ee7-a4d1-4400-a5bb-2745b5a2bfc5",
      "metadata": {
        "id": "8daa5ee7-a4d1-4400-a5bb-2745b5a2bfc5"
      },
      "outputs": [],
      "source": [
        "def download_mnist_pytorch():\n",
        "    \"\"\"Download MNIST using PyTorch's built-in functionality\"\"\"\n",
        "    print(\"Downloading MNIST using PyTorch...\")\n",
        "\n",
        "    # This will download to '../data' relative to current directory\n",
        "    # The code expects it in '../data' based on the datasets.MNIST('../data', ...) calls\n",
        "    train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
        "                                   transform=transforms.Compose([\n",
        "                                       transforms.ToTensor()\n",
        "                                   ]))\n",
        "\n",
        "    test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                                  transform=transforms.Compose([\n",
        "                                      transforms.ToTensor()\n",
        "                                  ]))\n",
        "\n",
        "    print(f\"Training set size: {len(train_dataset)}\")\n",
        "    print(f\"Test set size: {len(test_dataset)}\")\n",
        "    print(\"MNIST dataset downloaded successfully!\")\n",
        "\n",
        "    return train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "385048d1-645e-4915-b8e5-4b64eecc3206",
      "metadata": {
        "id": "385048d1-645e-4915-b8e5-4b64eecc3206",
        "outputId": "fa34425d-90f0-4dd9-9726-ff9c299bd744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading MNIST using PyTorch...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:09<00:00, 1.06MB/s]\n",
            "100%|█████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 56.7kB/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:06<00:00, 239kB/s]\n",
            "100%|█████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 1.39MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 60000\n",
            "Test set size: 10000\n",
            "MNIST dataset downloaded successfully!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = download_mnist_pytorch()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6567e1f0-3f85-499d-ba81-a2032ee9ae2b",
      "metadata": {
        "id": "6567e1f0-3f85-499d-ba81-a2032ee9ae2b"
      },
      "outputs": [],
      "source": [
        "def preprocess_old_alphastar_mnist(alphastar):\n",
        "    manip = torch.tensor(alphastar[:,:,0].reshape(1,32,32)).float()\n",
        "    manip = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize(28),\n",
        "            transforms.ToTensor()\n",
        "        ])(manip)\n",
        "    return manip.clone()\n",
        "\n",
        "def preprocess_old_alphastar_vggfaces2(alphastar):\n",
        "    manip = torch.tensor(alphastar.reshape(3,32,32)).float()\n",
        "    manip_max = torch.max(manip)\n",
        "    manip_min = torch.min(manip)\n",
        "    manip = ((manip - manip_min) / (manip_max - manip_min))*255.\n",
        "    return manip.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2675a2b-94d9-480e-b723-b8c64eba3464",
      "metadata": {
        "id": "b2675a2b-94d9-480e-b723-b8c64eba3464"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CDLLayer(nn.Module):\n",
        "    def __init__(self, latent_dim, dict_size, tau=0.01, p=0.7, device=torch.device(\"cuda:0\")):\n",
        "        super(CDLLayer, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.dict_size = dict_size\n",
        "        self.tau = tau\n",
        "        self.p = p\n",
        "        self.device = device\n",
        "\n",
        "        # Synthesis dictionary U (latent_dim x dict_size)\n",
        "        self.U = nn.Parameter(torch.randn(latent_dim, dict_size, device=device))\n",
        "        # Analysis dictionary V (latent_dim x dict_size)\n",
        "        self.V = nn.Parameter(torch.randn(latent_dim, dict_size, device=device))\n",
        "\n",
        "        self._initialize_dictionaries()\n",
        "\n",
        "    def _initialize_dictionaries(self):\n",
        "        # Initialize U with normalized columns\n",
        "        with torch.no_grad():\n",
        "            for i in range(self.dict_size):\n",
        "                col_norm = torch.norm(self.U[:, i])\n",
        "                if col_norm > 0:\n",
        "                    self.U[:, i] = self.U[:, i] / col_norm\n",
        "\n",
        "        # Initialize V randomly\n",
        "        nn.init.xavier_normal_(self.V)\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Apply CDL to latent representations: Z_recon = U * V^T * Z\n",
        "        z: (batch_size, latent_dim)\n",
        "        \"\"\"\n",
        "        batch_size = z.size(0)\n",
        "\n",
        "        # Analysis: A = V^T * Z (dict_size x batch_size)\n",
        "        VT_Z = torch.mm(self.V.t(), z.t())  # (dict_size, batch_size)\n",
        "\n",
        "        # Synthesis: Z_recon = U * A (latent_dim x batch_size)\n",
        "        z_reconstructed = torch.mm(self.U, VT_Z).t()  # (batch_size, latent_dim)\n",
        "\n",
        "        return z_reconstructed, VT_Z.t()  # (batch_size, dict_size)\n",
        "\n",
        "    def compute_cdl_loss(self, z):\n",
        "        \"\"\"\n",
        "        Compute CDL reconstruction loss and sparsity regularization\n",
        "        \"\"\"\n",
        "        batch_size = z.size(0)\n",
        "\n",
        "        # Get reconstructed latent and coefficients\n",
        "        z_recon, coeffs = self.forward(z)\n",
        "\n",
        "        # Reconstruction loss: ||Z - U*V^T*Z||_F^2\n",
        "        recon_loss = F.mse_loss(z_recon, z, reduction='mean')\n",
        "\n",
        "        # Sparsity regularization on analysis dictionary V: ||V||_{2,p}\n",
        "        row_norms = torch.norm(self.V, dim=1, p=2)  # L2 norm of each row\n",
        "\n",
        "        if self.p == 0:\n",
        "            # L_{2,0}: count of non-zero rows\n",
        "            sparsity_loss = torch.sum((row_norms > 1e-8).float())\n",
        "        else:\n",
        "            # L_{2,p}: Σᵢ ||vᵢ||₂^p\n",
        "            sparsity_loss = torch.sum(torch.pow(row_norms + 1e-8, self.p))\n",
        "\n",
        "        # Total CDL loss\n",
        "        cdl_loss = recon_loss + self.tau * sparsity_loss\n",
        "\n",
        "        return cdl_loss, recon_loss, sparsity_loss\n",
        "\n",
        "    def get_feature_importance(self):\n",
        "        \"\"\"\n",
        "        Get feature importance based on row norms of analysis dictionary V\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            return torch.norm(self.V, dim=1, p=2)\n",
        "\n",
        "    def constraint_projection(self):\n",
        "        \"\"\"\n",
        "        Project synthesis dictionary U to satisfy constraints: ||u_i||_2 <= 1\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            for i in range(self.dict_size):\n",
        "                col_norm = torch.norm(self.U[:, i])\n",
        "                if col_norm > 1.0:\n",
        "                    self.U[:, i] = self.U[:, i] / col_norm\n",
        "\n",
        "    def update_U_admm(self, X, A, rho=1.0, max_iter=25):\n",
        "        \"\"\"\n",
        "        Update synthesis dictionary U using ADMM\n",
        "        Solve: min_U ||X - UA||²_F s.t. ||u_i||²_2 ≤ 1\n",
        "\n",
        "        Args:\n",
        "            X: Data matrix (latent_dim, n_samples)\n",
        "            A: Coefficient matrix (dict_size, n_samples)\n",
        "            rho: ADMM penalty parameter\n",
        "            max_iter: Maximum iterations\n",
        "        \"\"\"\n",
        "        d, k = self.U.shape\n",
        "        n = A.shape[1]\n",
        "\n",
        "        # ADMM variables\n",
        "        U = self.U.data.clone()\n",
        "        Z = self.U.data.clone()  # Auxiliary variable\n",
        "        Lambda = torch.zeros_like(U, device=self.device)  # Dual variable\n",
        "\n",
        "        # Precompute matrices for efficiency\n",
        "        ATA = torch.mm(A, A.t())  # (dict_size, dict_size)\n",
        "        XAT = torch.mm(X, A.t())  # (latent_dim, dict_size)\n",
        "        eye_k = torch.eye(k, device=self.device)\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            # Update U: solve (A*A^T + ρI)U = X*A^T + ρ(Z - Λ/ρ)\n",
        "            lhs = ATA + rho * eye_k  # (dict_size, dict_size)\n",
        "            rhs = XAT + rho * (Z - Lambda / rho)  # (latent_dim, dict_size)\n",
        "\n",
        "            # Solve linear system: lhs^T * U^T = rhs^T\n",
        "            try:\n",
        "                U = torch.linalg.solve(lhs, rhs.t()).t()  # (latent_dim, dict_size)\n",
        "            except RuntimeError:\n",
        "                # Fallback to pseudo-inverse if singular\n",
        "                U = torch.mm(rhs, torch.linalg.pinv(lhs))\n",
        "\n",
        "            # Update Z with projection: ||z_i||_2 ≤ 1\n",
        "            Z = U + Lambda / rho\n",
        "            for i in range(k):\n",
        "                col_norm = torch.norm(Z[:, i])\n",
        "                if col_norm > 1.0:\n",
        "                    Z[:, i] = Z[:, i] / col_norm\n",
        "\n",
        "            # Update dual variable Λ\n",
        "            Lambda = Lambda + rho * (U - Z)\n",
        "\n",
        "            # Check convergence\n",
        "            primal_residual = torch.norm(U - Z)\n",
        "            if primal_residual < 1e-6:\n",
        "                break\n",
        "\n",
        "        # Update parameter\n",
        "        self.U.data.copy_(U)\n",
        "\n",
        "    def update_V_irls(self, X, max_iter=25):\n",
        "        \"\"\"\n",
        "        Update analysis dictionary V using IRLS (Iteratively Reweighted Least Squares)\n",
        "        Solve: min_V ||X - UV^TX||²_F + τ||V||²_{2,p}\n",
        "\n",
        "        Args:\n",
        "            X: Data matrix (latent_dim, n_samples)\n",
        "            max_iter: Maximum iterations\n",
        "        \"\"\"\n",
        "        d, k = self.V.shape\n",
        "        n = X.shape[1]\n",
        "        V = self.V.data.clone()\n",
        "        eps = 1e-8  # For numerical stability\n",
        "\n",
        "        # Precompute matrices\n",
        "        XXT = torch.mm(X, X.t())  # (latent_dim, latent_dim)\n",
        "        UUT = torch.mm(self.U.data, self.U.data.t())  # (latent_dim, latent_dim)\n",
        "        XXT_UUT = torch.mm(XXT, UUT)  # (latent_dim, latent_dim)\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            # Compute current row norms\n",
        "            row_norms = torch.norm(V, dim=1, p=2) + eps  # Add epsilon for stability\n",
        "\n",
        "            # Compute weights for reweighted least squares\n",
        "            if self.p == 0:\n",
        "                weights = torch.ones_like(row_norms)\n",
        "            else:\n",
        "                weights = self.p * torch.pow(row_norms, self.p - 2)\n",
        "\n",
        "            # Create diagonal weight matrix W\n",
        "            W = torch.diag(weights)\n",
        "\n",
        "            # Solve reweighted problem:\n",
        "            # (X*X^T*U*U^T + τW)V = X*X^T*U*U^T*V_old\n",
        "            lhs = XXT_UUT + self.tau * W  # (latent_dim, latent_dim)\n",
        "            rhs = torch.mm(XXT_UUT, V)    # (latent_dim, dict_size)\n",
        "\n",
        "            # Solve linear system\n",
        "            try:\n",
        "                V_new = torch.linalg.solve(lhs, rhs)\n",
        "            except RuntimeError:\n",
        "                # Fallback to pseudo-inverse if singular\n",
        "                V_new = torch.mm(torch.linalg.pinv(lhs), rhs)\n",
        "\n",
        "            # Check convergence\n",
        "            if torch.norm(V_new - V) < 1e-6:\n",
        "                break\n",
        "\n",
        "            V = V_new\n",
        "\n",
        "        # Update parameter\n",
        "        self.V.data.copy_(V)\n",
        "\n",
        "    def cdl_optimization_step(self, X, max_outer_iter=10):\n",
        "        \"\"\"\n",
        "        Perform one complete CDL optimization step with alternating updates\n",
        "\n",
        "        Args:\n",
        "            X: Data matrix (latent_dim, n_samples)\n",
        "            max_outer_iter: Maximum outer iterations\n",
        "        \"\"\"\n",
        "        X = X.t()  # Convert to (latent_dim, n_samples)\n",
        "\n",
        "        for outer_it in range(max_outer_iter):\n",
        "            # Step 1: Update A = V^T * X\n",
        "            with torch.no_grad():\n",
        "                A = torch.mm(self.V.data.t(), X)  # (dict_size, n_samples)\n",
        "\n",
        "            # Step 2: Update U using ADMM\n",
        "            self.update_U_admm(X, A)\n",
        "\n",
        "            # Step 3: Update V using IRLS\n",
        "            self.update_V_irls(X)\n",
        "\n",
        "            # Apply constraints\n",
        "            self.constraint_projection()\n",
        "\n",
        "    def select_features(self, num_features):\n",
        "        \"\"\"\n",
        "        Select top features based on analysis dictionary row norms\n",
        "\n",
        "        Args:\n",
        "            num_features: Number of features to select\n",
        "\n",
        "        Returns:\n",
        "            indices: Indices of selected features\n",
        "            weights: Feature importance weights\n",
        "        \"\"\"\n",
        "        feature_weights = self.get_feature_importance()\n",
        "        _, indices = torch.topk(feature_weights, num_features)\n",
        "        return indices, feature_weights[indices]\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, nc, nef, nz, device):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.nz = nz\n",
        "\n",
        "        # Encoder optimized for 64x64 input\n",
        "        self.encoder = nn.Sequential(\n",
        "            # 64x64 -> 32x32\n",
        "            nn.Conv2d(nc, nef, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(nef),\n",
        "            # 32x32 -> 16x16\n",
        "            nn.Conv2d(nef, nef*2, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(nef*2),\n",
        "            # 16x16 -> 8x8\n",
        "            nn.Conv2d(nef*2, nef*4, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(nef*4),\n",
        "            # 8x8 -> 4x4\n",
        "            nn.Conv2d(nef*4, nef*8, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(nef*8)\n",
        "        )\n",
        "\n",
        "        # For 64x64 input, final feature map is 4x4\n",
        "        self.mean = nn.Linear(nef*8*4*4, nz)\n",
        "        self.logvar = nn.Linear(nef*8*4*4, nz)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        # Encoded feature map (batch_size, nef*8, 4, 4)\n",
        "        hidden = self.encoder(inputs)\n",
        "        # Reshape to (batch_size, nef*8*4*4)\n",
        "        hidden = hidden.view(batch_size, -1)\n",
        "        mean, logvar = self.mean(hidden), self.logvar(hidden)\n",
        "        return mean, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, nc, ndf, nz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.ndf = ndf\n",
        "\n",
        "        # Project latent to spatial feature map (4x4)\n",
        "        self.latent_to_features = nn.Sequential(\n",
        "            nn.Linear(nz, ndf*8*4*4),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # Progressive upsampling for 64x64 output\n",
        "        self.decoder = nn.Sequential(\n",
        "            # 4x4 -> 8x8\n",
        "            nn.ConvTranspose2d(ndf * 8, ndf * 4, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(ndf * 4, 1.e-3),\n",
        "\n",
        "            # 8x8 -> 16x16\n",
        "            nn.ConvTranspose2d(ndf * 4, ndf * 2, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(ndf * 2, 1.e-3),\n",
        "\n",
        "            # 16x16 -> 32x32\n",
        "            nn.ConvTranspose2d(ndf * 2, ndf, 4, 2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.BatchNorm2d(ndf, 1.e-3),\n",
        "\n",
        "            # 32x32 -> 64x64\n",
        "            nn.ConvTranspose2d(ndf, nc, 4, 2, padding=1),\n",
        "            nn.Tanh()  # Output in [-1, 1] range\n",
        "        )\n",
        "\n",
        "    def forward(self, input, target_size=None):\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        # Project to feature map\n",
        "        x = self.latent_to_features(input)\n",
        "        x = x.view(batch_size, self.ndf*8, 4, 4)\n",
        "\n",
        "        # Decode to 64x64\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class FLPLoss(nn.Module):\n",
        "    def __init__(self, model_name, device, reduction='sum'):\n",
        "        super(FLPLoss, self).__init__()\n",
        "        self.device = device\n",
        "        self.reduction = reduction\n",
        "        # MSELoss\n",
        "        self.loss_fn = nn.MSELoss(reduction=reduction)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.loss_fn(input, target)\n",
        "\n",
        "class KLDLoss(nn.Module):\n",
        "    def __init__(self, reduction='sum'):\n",
        "        super(KLDLoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, mean, logvar):\n",
        "        kld = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp(), dim=1)\n",
        "        if self.reduction == 'sum':\n",
        "            return torch.sum(kld)\n",
        "        elif self.reduction == 'mean':\n",
        "            return torch.mean(kld)\n",
        "        else:\n",
        "            return kld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97fd7c2c-4b21-4595-9743-2cf6626c67e5",
      "metadata": {
        "id": "97fd7c2c-4b21-4595-9743-2cf6626c67e5"
      },
      "outputs": [],
      "source": [
        "class VAE_VGGFACES2(nn.Module):\n",
        "    def __init__(self, nc=3, ndf=32, nef=32, nz=128, device=torch.device(\"cuda:0\"),\n",
        "                 is_train=True, use_cdl=True, dict_size=512, cdl_tau=0.01, cdl_p=0.7):\n",
        "        super(VAE_VGGFACES2, self).__init__()\n",
        "        self.device = device\n",
        "        self.nz = nz\n",
        "        self.use_cdl = use_cdl\n",
        "\n",
        "        # Encoder and Decoder for 64x64 images\n",
        "        self.encoder = Encoder(nc=nc, nef=nef, nz=nz, device=device)\n",
        "        self.decoder = Decoder(nc=nc, ndf=ndf, nz=nz)\n",
        "\n",
        "        # CDL layer for latent space dictionary learning\n",
        "        if self.use_cdl:\n",
        "            self.cdl_layer = CDLLayer(nz, dict_size, cdl_tau, cdl_p, device)\n",
        "\n",
        "        if is_train == False:\n",
        "            for param in self.encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.decoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            if self.use_cdl:\n",
        "                for param in self.cdl_layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "    def encode(self, x):\n",
        "        mean, logvar = self.encoder(x)\n",
        "        return mean, logvar\n",
        "\n",
        "    def decode(self, z, target_size=None):\n",
        "        # target_size\n",
        "        return self.decoder(z, target_size)\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps * std + mean\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure input is 64x64\n",
        "        if x.size(2) != 64 or x.size(3) != 64:\n",
        "            x = F.interpolate(x, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "\n",
        "        mean, logvar = self.encoder(x)\n",
        "        latent_z = self.reparameterize(mean, logvar)\n",
        "\n",
        "        # Apply CDL in latent space\n",
        "        if self.use_cdl:\n",
        "            latent_z_cdl, coeffs = self.cdl_layer(latent_z)\n",
        "            rec_x = self.decoder(latent_z_cdl)\n",
        "            return rec_x, mean, logvar, latent_z, coeffs\n",
        "        else:\n",
        "            rec_x = self.decoder(latent_z)\n",
        "            return rec_x, mean, logvar\n",
        "\n",
        "\n",
        "    def compute_cdl_loss(self, latent_z):\n",
        "        \"\"\"\n",
        "        Compute CDL loss for the latent representations\n",
        "        \"\"\"\n",
        "        if self.use_cdl:\n",
        "            return self.cdl_layer.compute_cdl_loss(latent_z)\n",
        "        else:\n",
        "            return 0, 0, 0\n",
        "\n",
        "    def apply_constraints(self):\n",
        "        \"\"\"\n",
        "        Apply constraints to synthesis dictionary\n",
        "        \"\"\"\n",
        "        if self.use_cdl:\n",
        "            self.cdl_layer.constraint_projection()\n",
        "\n",
        "    def get_feature_importance(self):\n",
        "        \"\"\"\n",
        "        Get feature importance from CDL\n",
        "        \"\"\"\n",
        "        if self.use_cdl:\n",
        "            return self.cdl_layer.get_feature_importance()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def perform_cdl_optimization(self, latent_z, max_iter=5):\n",
        "        \"\"\"\n",
        "        Perform explicit CDL optimization step using ADMM/IRLS\n",
        "\n",
        "        Args:\n",
        "            latent_z: Latent representations (batch_size, latent_dim)\n",
        "            max_iter: Maximum iterations for CDL optimization\n",
        "        \"\"\"\n",
        "        if self.use_cdl:\n",
        "            self.cdl_layer.cdl_optimization_step(latent_z, max_iter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02ef306-6da1-4428-803d-985b2cece4c3",
      "metadata": {
        "id": "e02ef306-6da1-4428-803d-985b2cece4c3"
      },
      "outputs": [],
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "def getlabeledindices(target, labels):\n",
        "    labeledindices = torch.zeros(target.shape).byte()\n",
        "    for label in labels:\n",
        "\n",
        "        labeledindices = ((target == label) | labeledindices)\n",
        "\n",
        "    return labeledindices\n",
        "\n",
        "\n",
        "def get_parameters(model, bias=False):\n",
        "    for k, m in model._modules.items():\n",
        "        if k == \"fc\" and isinstance(m, nn.Linear):\n",
        "            if bias:\n",
        "                yield m.bias\n",
        "            else:\n",
        "                yield m.weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e311c189-cff4-4bbd-b62c-396a32c2e95e",
      "metadata": {
        "id": "e311c189-cff4-4bbd-b62c-396a32c2e95e"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if (mnistdataset):\n",
        "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "            # print('x1',x.shape)\n",
        "            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "            # print('x2',x.shape)\n",
        "            x = x.view(-1, 320)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            # print('x6',x.shape)\n",
        "            x = F.dropout(x, training=self.training)\n",
        "            # print('x7',x.shape)\n",
        "            x = self.fc2(x)\n",
        "            # print('x8', x.shape)\n",
        "        return F.log_softmax(x, dim=1) # Acrss CNN's, Make x shape (128,10)\n",
        "\n",
        "# Use gpu for training cnn before and after game not during game?\n",
        "def train(args, model, train_loader, optimizer, epoch):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "        if (vggfacesdataset):\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        if (vggfacesdataset):\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Use this loader to save manipulated images in VGGFace2 dataset. Need to redo preprocessing and training of CNN,VAE models.\n",
        "def loader_vggfaces2(Rootdir, targetkey):\n",
        "    images=[]\n",
        "    labels=[]\n",
        "    for img_file in listdir(Rootdir):\n",
        "        img = Image.open(Rootdir + \"/\" + img_file)\n",
        "        img = torchvision.transforms.Resize((vggface_image_length, vggface_image_length))(img)\n",
        "        img = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])(img)\n",
        "        images.append(img.clone())\n",
        "        labels.append(float(targetkey))\n",
        "\n",
        "    rootimages = torch.stack(images)\n",
        "    rootlabels = torch.from_numpy(np.asarray(labels))\n",
        "\n",
        "    # sys.exit()\n",
        "    return (rootimages.clone(), rootlabels.clone())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004b5416-df50-4c7e-af24-b389a602442a",
      "metadata": {
        "id": "004b5416-df50-4c7e-af24-b389a602442a"
      },
      "outputs": [],
      "source": [
        "def test(args, model, test_loader, savemanipulations=True):\n",
        "\n",
        "    testdata = []\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    tps = {}\n",
        "    ps = {}\n",
        "    for argstarget in range(0, 10):\n",
        "        tps[argstarget] = 0.\n",
        "        ps[argstarget] = 0.\n",
        "\n",
        "    tp = 0.\n",
        "    p = 0.\n",
        "    with torch.no_grad():\n",
        "        batchidx = 0\n",
        "        for data, target, origdata in test_loader:\n",
        "            #data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            if (vggfacesdataset):\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                test_loss += criterion(output, target)\n",
        "\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "\n",
        "            argstarget = list(args['target'])[0]\n",
        "            tp += torch.nonzero((target == argstarget).reshape(pred.shape) & (pred == argstarget)).size(0)\n",
        "            p += torch.nonzero(target == argstarget).size(0)\n",
        "\n",
        "            batcherror = 100. * (1.0 - (tp / p))\n",
        "            print('batcherror=====================,savemanipulations',batcherror,savemanipulations)\n",
        "            if(batcherror > batcherror_threshold):\n",
        "                if (savemanipulations):\n",
        "                    currtarget = target.view_as(pred)\n",
        "                    incorrectidx = (pred != currtarget).reshape(-1)\n",
        "                    print('incorrectidx.shape',incorrectidx.shape)\n",
        "\n",
        "                    misclassifieddata = data[incorrectidx]\n",
        "                    originaldata = origdata[incorrectidx]\n",
        "                    misclassifiedtarget = currtarget[incorrectidx]\n",
        "\n",
        "                    counter=0\n",
        "                    for i in range(0, misclassifieddata.shape[0]):\n",
        "                        advimg = misclassifieddata[i]\n",
        "                        origimg = originaldata[i]\n",
        "                        origclass = misclassifiedtarget[i].item()\n",
        "                        predclass = pred[i].item()\n",
        "\n",
        "                        print('origclass',origclass)\n",
        "                        print('predclass',predclass)\n",
        "\n",
        "                        if (origclass in args['positive_targets'] and predclass in args['negative_target']):\n",
        "                            advimg = transforms.Compose([\n",
        "                                transforms.ToPILImage(),\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.ToTensor()\n",
        "                            ])(advimg)\n",
        "\n",
        "                            origimg = transforms.Compose([\n",
        "                                transforms.ToPILImage(),\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.ToTensor()\n",
        "                            ])(origimg)\n",
        "\n",
        "                            torchvision.utils.save_image(advimg, args['advtestimagessavepath'] + '/' + str(batchidx) + str(\n",
        "                                i) + '_' + str(origclass) + ',' + str(predclass) + '.jpeg')\n",
        "                            torchvision.utils.save_image(origimg,\n",
        "                             args['origtestimagessavepath'] + '/' + str(batchidx) + str(\n",
        "                                 i) + '_' + str(origclass) + ',' + str(predclass) + '.jpeg')\n",
        "                            counter+=1\n",
        "\n",
        "            targets.extend(target.numpy().tolist())\n",
        "            predictions.extend(pred.view_as(target).numpy().tolist())\n",
        "\n",
        "            testdata.extend(data)\n",
        "            batchidx+=1\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    tpr =  tp/p\n",
        "\n",
        "    tprs = {}\n",
        "\n",
        "    if(reporttpraccuracy):\n",
        "        return (100. * (1.0 - tpr), 100. * (1.0 - (correct / len(test_loader.dataset))), tprs)\n",
        "    if(reporttprfscore):\n",
        "        overallperf = 0.\n",
        "\n",
        "        argstarget = list(args['target'])[0]\n",
        "\n",
        "        overallperf += metrics.f1_score(targets, predictions, average=None, labels=[argstarget])[0]\n",
        "        return (100. * (1.0 - tpr), 100. * (1.0 - overallperf), tprs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02955cc6-5838-4a3b-a261-79afb36ee584",
      "metadata": {
        "id": "02955cc6-5838-4a3b-a261-79afb36ee584"
      },
      "outputs": [],
      "source": [
        "def adversarialmanipulation(posnegdata, posindexvector, negindexvector, encodedposwmean, encodedposwstddev,\n",
        "                                deltawmean, deltawstddev, weightwmean, weightwstddev, autoencodermodel):\n",
        "\n",
        "    # print('Entering adversarialmanipulation in maskedclassifiererror')\n",
        "    advdata = torch.zeros(posnegdata.shape) # In generative model, encoded encodedposwmean need not have same shape as original posnegdata\n",
        "\n",
        "    encodedadvdata = autoencodermodel.reparameterize(encodedposwmean + weightwmean,\n",
        "                                                         encodedposwstddev + weightwstddev)\n",
        "    advdata[posindexvector] = autoencodermodel.decode(encodedadvdata)\n",
        "    advdata[negindexvector] = posnegdata[negindexvector]\n",
        "\n",
        "    return advdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30fb50e8-7107-4ac4-8c95-6cba6a9d4583",
      "metadata": {
        "id": "30fb50e8-7107-4ac4-8c95-6cba6a9d4583"
      },
      "outputs": [],
      "source": [
        "def maskedclassifiererror(posnegdata, posnegtargets, posindexvector, negindexvector, args, model, encodedposwmean, encodedposwstddev,\n",
        "                          deltawmean, deltawstddev, weightwmean, weightwstddev, autoencodermodel, savemanipulations=True):\n",
        "\n",
        "\n",
        "    advdata = adversarialmanipulation(posnegdata, posindexvector, negindexvector, encodedposwmean, encodedposwstddev,\n",
        "                                      deltawmean, deltawstddev, weightwmean, weightwstddev, autoencodermodel)\n",
        "\n",
        "    advtargets = posnegtargets\n",
        "\n",
        "    adv_test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(advdata, advtargets.long(), posnegdata),\n",
        "        batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "    return test(args, model, adv_test_loader, savemanipulations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34fcc7f5-0e6b-4941-b12d-d263dd175382",
      "metadata": {
        "id": "34fcc7f5-0e6b-4941-b12d-d263dd175382"
      },
      "outputs": [],
      "source": [
        "def linesearch_loss_function(posnegdata, advdata, autoencodermodel, args):\n",
        "\n",
        "    adv_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(posnegdata, advdata),\n",
        "        batch_size=args['batch_size'], shuffle=True)\n",
        "\n",
        "    meanmu1batches = []\n",
        "    meanmu2batches = []\n",
        "\n",
        "    meanlogvar1batches = []\n",
        "    meanlogvar2batches = []\n",
        "\n",
        "    for posnegdatabatch, advdatabatch in adv_data_loader:\n",
        "        mu1, logvar1 = autoencodermodel.encode(posnegdatabatch)\n",
        "        mu2, logvar2 = autoencodermodel.encode(advdatabatch)\n",
        "\n",
        "        batchmeanmu1 = mu1.mean(dim=0)\n",
        "        batchmeanmu1 = batchmeanmu1.view(1, batchmeanmu1.shape[0])\n",
        "\n",
        "        batchmeanmu2 = mu2.mean(dim=0)\n",
        "        batchmeanmu2 = batchmeanmu2.view(1, batchmeanmu2.shape[0])\n",
        "\n",
        "        batchmeanlogvar1 = logvar1.mean(dim=0)\n",
        "        batchmeanlogvar1 = batchmeanlogvar1.view(1, batchmeanlogvar1.shape[0])\n",
        "\n",
        "        batchmeanlogvar2 = logvar2.mean(dim=0)\n",
        "        batchmeanlogvar2 = batchmeanlogvar2.view(1, batchmeanlogvar2.shape[0])\n",
        "\n",
        "        meanmu1batches.append(batchmeanmu1.clone())\n",
        "        meanmu2batches.append(batchmeanmu2.clone())\n",
        "\n",
        "        meanlogvar1batches.append(batchmeanlogvar1.clone())\n",
        "        meanlogvar2batches.append(batchmeanlogvar2.clone())\n",
        "\n",
        "\n",
        "    mu1 = torch.stack(meanmu1batches)\n",
        "    mu2 = torch.stack(meanmu2batches)\n",
        "    logvar1 = torch.stack(meanlogvar1batches)\n",
        "    logvar2 = torch.stack(meanlogvar2batches)\n",
        "\n",
        "    meanmu1 = mu1.mean(dim=0)\n",
        "\n",
        "\n",
        "    meanmu2 = mu2.mean(dim=0)\n",
        "\n",
        "    meanlogvar1 = logvar1.mean(dim=0)\n",
        "\n",
        "    meanlogvar2 = logvar2.mean(dim=0)\n",
        "\n",
        "    mullogvar1 = torch.mul(meanlogvar1, torch.t(meanlogvar1))\n",
        "    r1, c1 = mullogvar1.shape\n",
        "    meanlogvar1 = torch.mul(mullogvar1,torch.eye(r1,c1))\n",
        "\n",
        "    mullogvar2 = torch.mul(meanlogvar2, torch.t(meanlogvar2))\n",
        "    r2, c2 = mullogvar2.shape\n",
        "    meanlogvar2 = torch.mul(mullogvar2,torch.eye(r2,c2))\n",
        "\n",
        "    advpdf = multivariate_normal.MultivariateNormal(meanmu2, meanlogvar2)\n",
        "    posnegpdf = multivariate_normal.MultivariateNormal(meanmu1, meanlogvar1)\n",
        "\n",
        "    KLD = kl.kl_divergence(advpdf,posnegpdf)\n",
        "\n",
        "    if(torch.isnan(KLD)):\n",
        "        print('Check KLD terms')\n",
        "\n",
        "    return KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1a199e-b562-4464-b315-7512ca8a6e9f",
      "metadata": {
        "id": "1e1a199e-b562-4464-b315-7512ca8a6e9f"
      },
      "outputs": [],
      "source": [
        "def pidloop_test(x):\n",
        "    return x*x\n",
        "\n",
        "def pidloop(candidate_fitnessfnvalues,cid,pidx,candidate_weightwmean,candidate_weightwstddev,\n",
        "            bestweightwmean,bestweightwstddev,deltawmean,deltawstddev,\n",
        "            args,search_iter,weightwmean,weightwstddev,autoencodermodel,optimizemean,\n",
        "            posnegdata,posnegtargets,posindexvector,negindexvector,model,\n",
        "            encodedposwmean,encodedposwstddev):\n",
        "    print('cid,pidx',cid,pidx)\n",
        "\n",
        "    if(optimizemean):\n",
        "        candidate_weightwmean[0, cid] = \\\n",
        "            bestweightwmean[0, cid] + \\\n",
        "            pidx * args['stepsizeweight'] * deltawmean[0, cid] * \\\n",
        "            math.pow(2.0 * args['stepsizeweight'], search_iter)\n",
        "\n",
        "        print('Here3 1')\n",
        "\n",
        "        candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "            maskedclassifiererror(\n",
        "                posnegdata,\n",
        "                posnegtargets,\n",
        "                posindexvector,\n",
        "                negindexvector,\n",
        "                args,\n",
        "                model,\n",
        "                encodedposwmean,\n",
        "                encodedposwstddev,\n",
        "                deltawmean,\n",
        "                deltawstddev,\n",
        "                candidate_weightwmean,\n",
        "                weightwstddev,\n",
        "                autoencodermodel)\n",
        "\n",
        "        print('Here3 2')\n",
        "\n",
        "        candidate_advdata = \\\n",
        "            adversarialmanipulation(\n",
        "                posnegdata,\n",
        "                posindexvector,\n",
        "                negindexvector,\n",
        "                deltawmean,\n",
        "                encodedposwmean,\n",
        "                encodedposwstddev,\n",
        "                deltawstddev,\n",
        "                candidate_weightwmean,\n",
        "                weightwstddev,\n",
        "                autoencodermodel)\n",
        "\n",
        "        print('Here3 3')\n",
        "\n",
        "        candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel, args)\n",
        "        candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "        candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "        print('Here3 4')\n",
        "\n",
        "        candidate_fitnessfnvalues[pidx] = \\\n",
        "            (candidate_fitnessfnvalue,\n",
        "             candidate_intererror2,\n",
        "             candidate_intermanipcost,\n",
        "             search_iter)\n",
        "\n",
        "        print('Here3 final')\n",
        "    else:\n",
        "    # for pidx in pidxrange:\n",
        "        candidate_weightwstddev[0, cid] = \\\n",
        "            bestweightwstddev[0, cid] + \\\n",
        "            pidx * args['stepsizeweight'] * deltawstddev[0, cid] * \\\n",
        "            math.pow(2.0 * args['stepsizeweight'], search_iter)\n",
        "\n",
        "        candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "            maskedclassifiererror(\n",
        "                posnegdata,\n",
        "                posnegtargets,\n",
        "                posindexvector,\n",
        "                negindexvector,\n",
        "                args,\n",
        "                model,\n",
        "                encodedposwmean,\n",
        "                encodedposwstddev,\n",
        "                deltawmean,\n",
        "                deltawstddev,\n",
        "                weightwmean,\n",
        "                candidate_weightwstddev,\n",
        "                autoencodermodel)\n",
        "\n",
        "        candidate_advdata = \\\n",
        "            adversarialmanipulation(\n",
        "                posnegdata,\n",
        "                posindexvector,\n",
        "                negindexvector,\n",
        "                deltawmean,\n",
        "                encodedposwmean,\n",
        "                encodedposwstddev,\n",
        "                deltawstddev,\n",
        "                weightwmean,\n",
        "                candidate_weightwstddev,\n",
        "                autoencodermodel)\n",
        "\n",
        "        candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel, args)\n",
        "        candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "        candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "        candidate_fitnessfnvalues[pidx] = \\\n",
        "            (candidate_fitnessfnvalue,\n",
        "             candidate_intererror2,\n",
        "             candidate_intermanipcost,\n",
        "             search_iter)\n",
        "\n",
        "    return candidate_fitnessfnvalues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da84b3b3-7a33-4370-a00b-c1ba4d8045f1",
      "metadata": {
        "id": "da84b3b3-7a33-4370-a00b-c1ba4d8045f1"
      },
      "outputs": [],
      "source": [
        "def linsearchloop(cid, args, optimizemean, deltawmean, deltawstddev, weightwmean, weightwstddev, initialfitnessfnvalue, initialerror2, posnegdata, posnegtargets, posindexvector, negindexvector, model, encodedposwmean, encodedposwstddev, autoencodermodel, bestiterks, classkey, gameiter):\n",
        "\n",
        "    print('Starting linsearchloop for cid,classkey, gameiter', cid,classkey, gameiter)\n",
        "\n",
        "    bestweightwmean = weightwmean.clone()\n",
        "    bestweightwstddev = weightwstddev.clone()\n",
        "\n",
        "    print('args[maxiter], args[numsteps], args[mininc]', args['maxiter'], args['numsteps'], args['mininc'])\n",
        "\n",
        "    if(optimizemean):\n",
        "        candidate_weightwmean = weightwmean.clone()\n",
        "\n",
        "\n",
        "        epsilon = (deltawmean[0, cid] / args['numsteps']).item()\n",
        "        loopflag = True\n",
        "\n",
        "        fitnessfnvalue = initialfitnessfnvalue  # Initialize fitnessfnvalue for greedy search\n",
        "        error2 = initialerror2\n",
        "\n",
        "        candidate_fitnessfnvalues = {}\n",
        "        searchiter = 0\n",
        "        bestpidx = 0\n",
        "\n",
        "        best_x = bestpidxpayoff = bestpidxerror2 = bestpidxmanipcost = 0\n",
        "        x = 0\n",
        "\n",
        "        jumped = False\n",
        "\n",
        "        while (loopflag and searchiter < args['maxiter']):\n",
        "            x_step = epsilon * random.uniform(args['steplower'], args['stepupper'] - (args['stepdec'] * searchiter))\n",
        "            x += x_step\n",
        "\n",
        "            print('str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid]', str(gameiter) + ':' + classkey,\n",
        "                  cid, searchiter, x, epsilon, deltawmean[0, cid])\n",
        "\n",
        "            candidate_weightwmean[0, cid] += x\n",
        "\n",
        "            candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "                maskedclassifiererror(\n",
        "                    posnegdata,\n",
        "                    posnegtargets,\n",
        "                    posindexvector,\n",
        "                    negindexvector,\n",
        "                    args,\n",
        "                    model,\n",
        "                    encodedposwmean,\n",
        "                    encodedposwstddev,\n",
        "                    deltawmean,\n",
        "                    deltawstddev,\n",
        "                    candidate_weightwmean,\n",
        "                    weightwstddev,\n",
        "                    autoencodermodel)\n",
        "\n",
        "            if (klnorm):\n",
        "                candidate_advdata = \\\n",
        "                    adversarialmanipulation(\n",
        "                        posnegdata,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        deltawmean,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawstddev,\n",
        "                        candidate_weightwmean,\n",
        "                        weightwstddev,\n",
        "                        autoencodermodel)\n",
        "\n",
        "                candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel,\n",
        "                                                                    args)\n",
        "            if (vectornorm):\n",
        "                candidate_intermanipcost = torch.norm(candidate_weightwmean) + torch.norm(weightwstddev)\n",
        "\n",
        "            candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "            candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "            candidate_fitnessfnvalues[searchiter] = \\\n",
        "                (x, candidate_fitnessfnvalue,\n",
        "                 candidate_intererror2,\n",
        "                 candidate_intermanipcost)\n",
        "\n",
        "            fitnessfndiff = candidate_fitnessfnvalue - fitnessfnvalue\n",
        "\n",
        "            errordiff = (candidate_intererror2 - error2)\n",
        "\n",
        "            print('\\n')\n",
        "            print('x,x_step', x, x_step)\n",
        "            print('candidate fitnessfnvalue', candidate_fitnessfnvalue)\n",
        "            print('intermediate fitnessfnvalue', fitnessfnvalue)\n",
        "            print('fitnessfndiff', fitnessfndiff)\n",
        "            print('candidate error2', candidate_intererror2)\n",
        "            print('intermediate error2', error2)\n",
        "            print('errordiff', errordiff)\n",
        "            print('candidate alphacost', candidate_intermanipcost)\n",
        "\n",
        "            if (fitnessfndiff > 0):\n",
        "                fitnessfnvalue = candidate_fitnessfnvalue\n",
        "                error2 = candidate_intererror2\n",
        "                bestpidx = searchiter\n",
        "\n",
        "                (best_x, bestpidxpayoff,\n",
        "                 bestpidxerror2,\n",
        "                 bestpidxmanipcost) = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "                print('Invoking search')\n",
        "\n",
        "                if (controlledthreshold_sa):\n",
        "                    if (candidate_intererror2 > args['maxerror_sa']):\n",
        "                        loopflag = False\n",
        "                        print('Exiting sa for bestweightwmean with maxerror_sa,candidate_intererror2',args['maxerror_sa'],candidate_intererror2)\n",
        "                        break\n",
        "                    else:\n",
        "                        loopflag = True\n",
        "                else:\n",
        "                    loopflag = True\n",
        "\n",
        "            elif (errordiff > 0 and jumped == False):\n",
        "                loopflag = True\n",
        "                x += epsilon * random.uniform(args['steplower'], args['stepupper'])\n",
        "                print('Invoking jump')\n",
        "                jumped = True\n",
        "            else:\n",
        "                loopflag = False\n",
        "                print('Exiting sa for bestweightwmean')\n",
        "\n",
        "            searchiter += 1\n",
        "\n",
        "            print('loopflag', loopflag)\n",
        "            print('\\n')\n",
        "\n",
        "        bestweightwmean[0, cid] = candidate_weightwmean[0, cid]\n",
        "\n",
        "\n",
        "\n",
        "        print('bestweightwmean[0, cid],cid', bestweightwmean[0, cid], cid)\n",
        "        print('args[minpercent]', args['minpercent'])\n",
        "        print('bestpidx', bestpidx)\n",
        "        print('best_x', best_x)\n",
        "        print('cid',cid)\n",
        "        print('deltawmean[0, cid]', deltawmean[0, cid])\n",
        "        print('\\n')\n",
        "    else:\n",
        "        candidate_weightwstddev =  weightwstddev.clone()\n",
        "\n",
        "        epsilon = (deltawstddev[0, cid] / args['numsteps']).item()\n",
        "\n",
        "        loopflag = True\n",
        "\n",
        "        fitnessfnvalue = initialfitnessfnvalue  # Initialize fitnessfnvalue for greedy search\n",
        "\n",
        "        error2 = initialerror2\n",
        "\n",
        "        candidate_fitnessfnvalues = {}\n",
        "        searchiter = 0\n",
        "        bestpidx = 0\n",
        "\n",
        "        best_x = bestpidxpayoff = bestpidxerror2 = bestpidxmanipcost = 0\n",
        "        x = 0\n",
        "\n",
        "        jumped = False\n",
        "\n",
        "        while (loopflag and searchiter < args['maxiter']):\n",
        "            x_step = epsilon * random.uniform(args['steplower'], args['stepupper'] - (args['stepdec'] * searchiter))\n",
        "            x += x_step\n",
        "\n",
        "            print('str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawstddev[0, cid]',\n",
        "                  str(gameiter) + ':' + classkey, cid, searchiter, x, epsilon, deltawstddev[0, cid])\n",
        "\n",
        "            # candidate_weightwstddev[0, cid] = bestweightwstddev[0, cid] + x\n",
        "            candidate_weightwstddev[0, cid] += x\n",
        "\n",
        "            candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "                maskedclassifiererror(\n",
        "                    posnegdata,\n",
        "                    posnegtargets,\n",
        "                    posindexvector,\n",
        "                    negindexvector,\n",
        "                    args,\n",
        "                    model,\n",
        "                    encodedposwmean,\n",
        "                    encodedposwstddev,\n",
        "                    deltawmean,\n",
        "                    deltawstddev,\n",
        "                    weightwmean,\n",
        "                    candidate_weightwstddev,\n",
        "                    autoencodermodel)\n",
        "\n",
        "            if (klnorm):\n",
        "                candidate_advdata = \\\n",
        "                    adversarialmanipulation(\n",
        "                        posnegdata,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        deltawmean,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawstddev,\n",
        "                        weightwmean,\n",
        "                        candidate_weightwstddev,\n",
        "                        autoencodermodel)\n",
        "\n",
        "                candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel,\n",
        "                                                                    args)\n",
        "            if (vectornorm):\n",
        "                candidate_intermanipcost = torch.norm(weightwmean) + torch.norm(candidate_weightwstddev)\n",
        "\n",
        "            candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "            candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "            candidate_fitnessfnvalues[searchiter] = \\\n",
        "                (x, candidate_fitnessfnvalue,\n",
        "                 candidate_intererror2,\n",
        "                 candidate_intermanipcost)\n",
        "\n",
        "            fitnessfndiff = candidate_fitnessfnvalue - fitnessfnvalue\n",
        "            # percentfitnessfndiff = ((candidate_fitnessfnvalue - fitnessfnvalue) / candidate_fitnessfnvalue) * 100\n",
        "\n",
        "            errordiff = (candidate_intererror2 - error2)\n",
        "\n",
        "            print('\\n')\n",
        "            print('x,x_step', x, x_step)\n",
        "            print('candidate fitnessfnvalue', candidate_fitnessfnvalue)\n",
        "            print('intermediate fitnessfnvalue', fitnessfnvalue)\n",
        "            print('fitnessfndiff', fitnessfndiff)\n",
        "            print('candidate error2', candidate_intererror2)\n",
        "            print('intermediate error2', error2)\n",
        "            print('errordiff', errordiff)\n",
        "            print('candidate alphacost', candidate_intermanipcost)\n",
        "\n",
        "            if (fitnessfndiff > 0):\n",
        "\n",
        "                fitnessfnvalue = candidate_fitnessfnvalue\n",
        "                error2 = candidate_intererror2\n",
        "                bestpidx = searchiter\n",
        "\n",
        "                (best_x, bestpidxpayoff,\n",
        "                 bestpidxerror2,\n",
        "                 bestpidxmanipcost) = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "\n",
        "                print('Invoking search')\n",
        "\n",
        "                if (controlledthreshold_sa):\n",
        "                    if (candidate_intererror2 > args['maxerror_sa']):\n",
        "                        loopflag = False\n",
        "                        print('Exiting sa for bestweightwmean with maxerror_sa,candidate_intererror2',args['maxerror_sa'],candidate_intererror2)\n",
        "                        break\n",
        "                    else:\n",
        "                        loopflag = True\n",
        "                else:\n",
        "                    loopflag = True\n",
        "\n",
        "            elif (errordiff > 0 and jumped == False):\n",
        "                loopflag = True\n",
        "                x += epsilon * random.uniform(args['steplower'], args['stepupper'])\n",
        "                print('Invoking jump')\n",
        "                jumped = True\n",
        "            else:\n",
        "                loopflag = False\n",
        "                print('Exiting sa for bestweightwstddev')\n",
        "\n",
        "            searchiter += 1\n",
        "\n",
        "            print('loopflag', loopflag)\n",
        "            print('\\n')\n",
        "\n",
        "        bestweightwstddev[0, cid] = candidate_weightwstddev[0, cid]\n",
        "\n",
        "        print('bestweightwstddev[0, cid],cid', bestweightwstddev[0, cid], cid)\n",
        "        print('args[minpercent]', args['minpercent'])\n",
        "        print('bestpidx', bestpidx)\n",
        "        print('best_x', best_x)\n",
        "        print('cid',cid)\n",
        "        print('deltawstddev[0, cid]', deltawstddev[0, cid])\n",
        "\n",
        "\n",
        "\n",
        "    best_intererror2, best_interoverallerror2, best_intertprserrors = \\\n",
        "        maskedclassifiererror(\n",
        "            posnegdata,\n",
        "            posnegtargets,\n",
        "            posindexvector,\n",
        "            negindexvector,\n",
        "            args,\n",
        "            model,\n",
        "            encodedposwmean,\n",
        "            encodedposwstddev,\n",
        "            deltawmean,\n",
        "            deltawstddev,\n",
        "            bestweightwmean,\n",
        "            bestweightwstddev,\n",
        "            autoencodermodel)\n",
        "\n",
        "    if (klnorm):\n",
        "        best_advdata = \\\n",
        "            adversarialmanipulation(\n",
        "                posnegdata,\n",
        "                posindexvector,\n",
        "                negindexvector,\n",
        "                deltawmean,\n",
        "                encodedposwmean,\n",
        "                encodedposwstddev,\n",
        "                deltawstddev,\n",
        "                bestweightwmean,\n",
        "                bestweightwstddev,\n",
        "                autoencodermodel)\n",
        "\n",
        "        best_intermanipcost = linesearch_loss_function(posnegdata, best_advdata, autoencodermodel,\n",
        "                                                       args)\n",
        "    if(vectornorm):\n",
        "        best_intermanipcost = torch.norm(bestweightwmean) + torch.norm(bestweightwstddev)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    best_intermanipcost = best_intermanipcost.item()\n",
        "    best_fitnessfnvalue = (best_intererror2 - args['lambda'] * best_intermanipcost)\n",
        "\n",
        "    print('best_intererror2,best_intermanipcost,best_fitnessfnvalue in linsearchloop', best_intererror2, best_intermanipcost,\n",
        "          best_fitnessfnvalue)\n",
        "\n",
        "    print('Ending linsearchloop for cid,classkey, gameiter', cid,classkey, gameiter)\n",
        "\n",
        "    return (bestweightwmean, bestweightwstddev,bestiterks, best_fitnessfnvalue, best_intererror2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1b6a55-a90c-453d-af53-23e844677480",
      "metadata": {
        "id": "0b1b6a55-a90c-453d-af53-23e844677480"
      },
      "outputs": [],
      "source": [
        "# Greedy Search or Simulated Annealing Search:\n",
        "def linsearch(initialfitnessfnvalue, initialerror2, initialmanipcost, args, model, weightwmean, weightwstddev, optimizemean, posnegdata, posnegtargets, posindexvector, negindexvector,\n",
        "              deltawmean, deltawstddev, encodedposwmean, encodedposwstddev, autoencodermodel, bestiterks, classkey, gameiter):\n",
        "\n",
        "    if (savesaruns):\n",
        "        fitnessfnvalues = torch.zeros(deltawmean.shape[1],args['maxiter'])\n",
        "        error2s = torch.zeros(deltawmean.shape[1],args['maxiter'])\n",
        "        manipcosts = torch.zeros(deltawmean.shape[1],args['maxiter'])\n",
        "\n",
        "        weightwmeans = torch.zeros(deltawmean.shape[1],args['maxiter'],weightwmean.shape[0],weightwmean.shape[1])\n",
        "        weightwstddevs = torch.zeros(deltawmean.shape[1],args['maxiter'],weightwmean.shape[0],weightwmean.shape[1])\n",
        "\n",
        "    bestweightwmean = weightwmean.clone()\n",
        "    bestweightwstddev = weightwstddev.clone()\n",
        "\n",
        "\n",
        "    bestweightwmeans = {}\n",
        "    bestweightwstddevs = {}\n",
        "\n",
        "    print('args[maxiter], args[numsteps], args[mininc]', args['maxiter'], args['numsteps'], args['mininc'])\n",
        "    print('---------------------------------------Starting SA loops--------------------------------------------')\n",
        "    if(optimizemean):\n",
        "        # for cid in xrange(0, 2):\n",
        "        cids = range(0, deltawmean.shape[1])\n",
        "        # random.shuffle(cids)\n",
        "        completedcids = []\n",
        "        sasattack=True\n",
        "        cidsx=0\n",
        "        while(sasattack and cidsx < len(cids)):\n",
        "\n",
        "            cid = cids[cidsx]\n",
        "            print('cid in optimizemean=True',cid)\n",
        "            if (not combinedattack):\n",
        "                candidate_weightwmean = weightwmean.clone()\n",
        "            else:\n",
        "                candidate_weightwmean = bestweightwmean.clone()\n",
        "\n",
        "\n",
        "            epsilon = (deltawmean[0, cid] / args['numsteps']).item()\n",
        "            print('epsilon',epsilon)\n",
        "\n",
        "            loopflag = True\n",
        "\n",
        "            fitnessfnvalue = initialfitnessfnvalue # Initialize fitnessfnvalue for greedy search\n",
        "\n",
        "            error2 = initialerror2\n",
        "\n",
        "            candidate_fitnessfnvalues = {}\n",
        "            searchiter = 0\n",
        "            bestpidx = 0\n",
        "\n",
        "            best_x = bestpidxpayoff = bestpidxerror2 = bestpidxmanipcost = 0\n",
        "\n",
        "            x = 0\n",
        "\n",
        "            jumped=False\n",
        "\n",
        "            while (loopflag and searchiter < args['maxiter']):\n",
        "\n",
        "                x_step = epsilon * random.uniform(args['steplower'], args['stepupper'] - (args['stepdec'] * searchiter))\n",
        "                x += x_step\n",
        "\n",
        "                if (savesaruns):\n",
        "                    fitnessfnvalues[cid, searchiter] = fitnessfnvalue\n",
        "                    error2s[cid, searchiter] = error2\n",
        "                    manipcosts[cid, searchiter] = initialmanipcost # Not using initialmanipcost in greedy search of generative model\n",
        "                    weightwmeans[cid, searchiter, :, :] = bestweightwmean\n",
        "                    weightwstddevs[cid, searchiter, :, :] = weightwstddev\n",
        "\n",
        "                # x = x_range[idx_x]\n",
        "                print('str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid]', str(gameiter) + ':' + classkey, cid, searchiter, x, epsilon, deltawmean[0, cid])\n",
        "\n",
        "                # candidate_weightwmean[0, cid] = bestweightwmean[0, cid] + x\n",
        "                candidate_weightwmean[0, cid] += x\n",
        "\n",
        "                candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "                    maskedclassifiererror(\n",
        "                        posnegdata,\n",
        "                        posnegtargets,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        args,\n",
        "                        model,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawmean,\n",
        "                        deltawstddev,\n",
        "                        candidate_weightwmean,\n",
        "                        weightwstddev,\n",
        "                        autoencodermodel, True)\n",
        "\n",
        "                if(klnorm):\n",
        "                    candidate_advdata = \\\n",
        "                        adversarialmanipulation(\n",
        "                            posnegdata,\n",
        "                            posindexvector,\n",
        "                            negindexvector,\n",
        "                            deltawmean,\n",
        "                            encodedposwmean,\n",
        "                            encodedposwstddev,\n",
        "                            deltawstddev,\n",
        "                            candidate_weightwmean,\n",
        "                            weightwstddev,\n",
        "                            autoencodermodel)\n",
        "\n",
        "                    candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel,\n",
        "                                                                        args)\n",
        "\n",
        "                if(vectornorm):\n",
        "                    candidate_intermanipcost = torch.norm(candidate_weightwmean) + torch.norm(weightwstddev)\n",
        "\n",
        "                candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "                candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "                candidate_fitnessfnvalues[searchiter] = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "                fitnessfndiff = candidate_fitnessfnvalue - fitnessfnvalue\n",
        "\n",
        "                errordiff = (candidate_intererror2 - error2)\n",
        "\n",
        "                print('\\n')\n",
        "\n",
        "                print('cid, searchiter, x,x_step', cid, searchiter, x, x_step)\n",
        "                print('candidate fitnessfnvalue', candidate_fitnessfnvalue)\n",
        "                print('intermediate fitnessfnvalue', fitnessfnvalue)\n",
        "                print('fitnessfndiff', fitnessfndiff)\n",
        "                # print('percentfitnessfndiff', percentfitnessfndiff)\n",
        "                print('candidate error2', candidate_intererror2)\n",
        "                print('intermediate error2', error2)\n",
        "                print('errordiff', errordiff)\n",
        "                # print('percenterrordiff', percenterrordiff)\n",
        "                print('candidate alphacost', candidate_intermanipcost)\n",
        "\n",
        "\n",
        "                if (fitnessfndiff > 0):\n",
        "                    fitnessfnvalue = candidate_fitnessfnvalue\n",
        "                    error2 = candidate_intererror2\n",
        "                    bestpidx = searchiter\n",
        "\n",
        "                    (best_x, bestpidxpayoff,\n",
        "                     bestpidxerror2,\n",
        "                     bestpidxmanipcost) = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "                    print('Invoking search')\n",
        "\n",
        "                    if (controlledthreshold_sa):\n",
        "                        if (candidate_intererror2 > args['maxerror_sa']):\n",
        "                            loopflag = False\n",
        "                            print('Exiting sa for bestweightwmean with maxerror_sa,candidate_intererror2',args['maxerror_sa'],candidate_intererror2)\n",
        "                            print('candidate_fitnessfnvalue, candidate_intererror2, candidate_intermanipcost', candidate_fitnessfnvalue, candidate_intererror2, candidate_intermanipcost)\n",
        "                            break\n",
        "                        else:\n",
        "                            loopflag = True\n",
        "                    else:\n",
        "                        loopflag = True\n",
        "\n",
        "                elif (errordiff > 0 and jumped == False):\n",
        "                    loopflag = True\n",
        "                    x += epsilon * random.uniform(args['steplower'], args['stepupper'])\n",
        "                    print('Invoking jump')\n",
        "                    jumped = True\n",
        "                else:\n",
        "                    loopflag = False\n",
        "                    print('Exiting sa for bestweightwmean')\n",
        "\n",
        "                searchiter+=1\n",
        "\n",
        "                print('loopflag', loopflag)\n",
        "                print('\\n')\n",
        "\n",
        "            if (not combinedattack):\n",
        "                bestweightwmean = weightwmean.clone()\n",
        "                bestweightwmean[0, cid] = candidate_weightwmean[0, cid]\n",
        "            else:\n",
        "                bestweightwmean = candidate_weightwmean.clone()\n",
        "\n",
        "\n",
        "            best_intererror2, best_interoverallerror2, best_intertprserrors = \\\n",
        "                    maskedclassifiererror(\n",
        "                        posnegdata,\n",
        "                        posnegtargets,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        args,\n",
        "                        model,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawmean,\n",
        "                        deltawstddev,\n",
        "                        bestweightwmean,\n",
        "                        bestweightwstddev,\n",
        "                        autoencodermodel)\n",
        "            if (klnorm):\n",
        "                best_advdata = \\\n",
        "                    adversarialmanipulation(\n",
        "                        posnegdata,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        deltawmean,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawstddev,\n",
        "                        bestweightwmean,\n",
        "                        bestweightwstddev,\n",
        "                        autoencodermodel)\n",
        "\n",
        "                best_intermanipcost = linesearch_loss_function(posnegdata, best_advdata, autoencodermodel,\n",
        "                                                                args)\n",
        "\n",
        "            if (vectornorm):\n",
        "                best_intermanipcost = torch.norm(bestweightwmean) + torch.norm(bestweightwstddev)\n",
        "\n",
        "            best_intermanipcost = best_intermanipcost.item()\n",
        "            best_fitnessfnvalue = (best_intererror2 - args['lambda'] * best_intermanipcost)\n",
        "\n",
        "            print('\\n')\n",
        "            print('weightwmean[0, cid],cid', weightwmean[0, cid], cid)\n",
        "            print('bestweightwmean[0, cid],cid', bestweightwmean[0, cid], cid)\n",
        "            print('bestweightwmean[0, cid] + best_x,cid', bestweightwmean[0, cid] + best_x, cid)\n",
        "            print('best_x', best_x)\n",
        "            print('best_intererror2,best_intermanipcost,best_fitnessfnvalue',best_intererror2,best_intermanipcost,best_fitnessfnvalue)\n",
        "            print('deltawmean[0, cid]', deltawmean[0, cid])\n",
        "            print('args[minpercent]', args['minpercent'])\n",
        "            print('bestpidx', bestpidx)\n",
        "            print('classkey, gameiter',classkey, gameiter)\n",
        "            print('\\n')\n",
        "\n",
        "            bestweightwmeans[cid] = (bestweightwmean,best_fitnessfnvalue,best_intererror2,best_intermanipcost)\n",
        "            bestweightwstddevs[cid] = (bestweightwstddev,best_fitnessfnvalue,best_intererror2,best_intermanipcost)\n",
        "\n",
        "            completedcids.append(cid)\n",
        "            cidsx += 1\n",
        "\n",
        "\n",
        "    else:\n",
        "        cids = range(0, deltawstddev.shape[1])\n",
        "        sasattack=True\n",
        "        cidsx=0\n",
        "        while(sasattack and cidsx < len(cids)):\n",
        "            cid = cids[cidsx]\n",
        "            print('cid in optimizemean=False',cid)\n",
        "            if (not combinedattack):\n",
        "                candidate_weightwstddev = weightwstddev.clone()\n",
        "            else:\n",
        "                candidate_weightwstddev = bestweightwstddev.clone()\n",
        "\n",
        "            epsilon = (deltawstddev[0, cid] / args['numsteps']).item()\n",
        "            loopflag = True\n",
        "\n",
        "            fitnessfnvalue = initialfitnessfnvalue # Initialize fitnessfnvalue for greedy search\n",
        "\n",
        "            error2 = initialerror2\n",
        "\n",
        "            candidate_fitnessfnvalues = {}\n",
        "            searchiter = 0\n",
        "            bestpidx = 0\n",
        "\n",
        "            best_x = bestpidxpayoff = bestpidxerror2 = bestpidxmanipcost = 0\n",
        "\n",
        "            x = 0\n",
        "\n",
        "            jumped=False\n",
        "\n",
        "            while (loopflag and searchiter < args['maxiter']):\n",
        "\n",
        "                x_step = epsilon * random.uniform(args['steplower'], args['stepupper'] - (args['stepdec'] * searchiter))\n",
        "                x += x_step\n",
        "\n",
        "                if (savesaruns):\n",
        "                    fitnessfnvalues[cid, searchiter] = fitnessfnvalue\n",
        "                    error2s[cid, searchiter] = error2\n",
        "                    manipcosts[cid, searchiter] = initialmanipcost # Not using initialmanipcost in greedy search of generative model\n",
        "                    weightwmeans[cid, searchiter, :, :] = weightwmean\n",
        "                    weightwstddevs[cid, searchiter, :, :] = bestweightwstddev\n",
        "\n",
        "                print('str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawstddev[0, cid]', str(gameiter) + ':' + classkey, cid, searchiter, x, epsilon, deltawstddev[0, cid])\n",
        "                candidate_weightwstddev[0, cid] += x\n",
        "\n",
        "                candidate_intererror2, candidate_interoverallerror2, candidate_intertprserrors = \\\n",
        "                    maskedclassifiererror(\n",
        "                        posnegdata,\n",
        "                        posnegtargets,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        args,\n",
        "                        model,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawmean,\n",
        "                        deltawstddev,\n",
        "                        weightwmean,\n",
        "                        candidate_weightwstddev,\n",
        "                        autoencodermodel)\n",
        "\n",
        "                if (klnorm):\n",
        "                    candidate_advdata = \\\n",
        "                        adversarialmanipulation(\n",
        "                            posnegdata,\n",
        "                            posindexvector,\n",
        "                            negindexvector,\n",
        "                            deltawmean,\n",
        "                            encodedposwmean,\n",
        "                            encodedposwstddev,\n",
        "                            deltawstddev,\n",
        "                            weightwmean,\n",
        "                            candidate_weightwstddev,\n",
        "                            autoencodermodel)\n",
        "\n",
        "                    candidate_intermanipcost = linesearch_loss_function(posnegdata, candidate_advdata, autoencodermodel,\n",
        "                                                                        args)\n",
        "\n",
        "                if (vectornorm):\n",
        "                    candidate_intermanipcost = torch.norm(weightwmean) + torch.norm(candidate_weightwstddev)\n",
        "\n",
        "                candidate_intermanipcost = candidate_intermanipcost.item()\n",
        "                candidate_fitnessfnvalue = (candidate_intererror2 - args['lambda'] * candidate_intermanipcost)\n",
        "\n",
        "                candidate_fitnessfnvalues[searchiter] = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "                fitnessfndiff = candidate_fitnessfnvalue - fitnessfnvalue\n",
        "\n",
        "                errordiff = (candidate_intererror2 - error2)\n",
        "                print('\\n')\n",
        "                print('x,x_step', x,x_step)\n",
        "                print('candidate fitnessfnvalue', candidate_fitnessfnvalue)\n",
        "                print('intermediate fitnessfnvalue', fitnessfnvalue)\n",
        "                print('fitnessfndiff', fitnessfndiff)\n",
        "                # print('percentfitnessfndiff', percentfitnessfndiff)\n",
        "                print('candidate error2', candidate_intererror2)\n",
        "                print('intermediate error2', error2)\n",
        "                print('errordiff', errordiff)\n",
        "                # print('percenterrordiff', percenterrordiff)\n",
        "                print('candidate alphacost', candidate_intermanipcost)\n",
        "\n",
        "                if (fitnessfndiff > 0):\n",
        "                    fitnessfnvalue = candidate_fitnessfnvalue\n",
        "                    error2 = candidate_intererror2\n",
        "                    bestpidx = searchiter\n",
        "\n",
        "                    (best_x, bestpidxpayoff,\n",
        "                     bestpidxerror2,\n",
        "                     bestpidxmanipcost) = \\\n",
        "                    (x, candidate_fitnessfnvalue,\n",
        "                     candidate_intererror2,\n",
        "                     candidate_intermanipcost)\n",
        "\n",
        "                    print('Invoking search')\n",
        "\n",
        "                    if (controlledthreshold_sa):\n",
        "                        if (candidate_intererror2 > args['maxerror_sa']):\n",
        "                            loopflag = False\n",
        "                            print('Exiting sa for bestweightwmean with maxerror_sa,candidate_intererror2',args['maxerror_sa'],candidate_intererror2)\n",
        "                            break\n",
        "                        else:\n",
        "                            loopflag = True\n",
        "                    else:\n",
        "                        loopflag = True\n",
        "\n",
        "                elif (errordiff > 0 and jumped == False):\n",
        "                    loopflag = True\n",
        "                    x += epsilon * random.uniform(args['steplower'], args['stepupper'])\n",
        "                    print('Invoking jump')\n",
        "                    jumped = True\n",
        "                else:\n",
        "                    loopflag = False\n",
        "                    print('Exiting sa for bestweightwstddev')\n",
        "\n",
        "                searchiter+=1\n",
        "\n",
        "                print('loopflag', loopflag)\n",
        "                print('\\n')\n",
        "\n",
        "            if (not combinedattack):\n",
        "                bestweightwstddev = weightwstddev.clone()\n",
        "                bestweightwstddev[0, cid] = candidate_weightwstddev[0, cid]\n",
        "            else:\n",
        "                bestweightwstddev = candidate_weightwstddev.clone()\n",
        "\n",
        "            best_intererror2, best_interoverallerror2, best_intertprserrors = \\\n",
        "                    maskedclassifiererror(\n",
        "                        posnegdata,\n",
        "                        posnegtargets,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        args,\n",
        "                        model,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawmean,\n",
        "                        deltawstddev,\n",
        "                        bestweightwmean,\n",
        "                        bestweightwstddev,\n",
        "                        autoencodermodel)\n",
        "            if (klnorm):\n",
        "                best_advdata = \\\n",
        "                    adversarialmanipulation(\n",
        "                        posnegdata,\n",
        "                        posindexvector,\n",
        "                        negindexvector,\n",
        "                        deltawmean,\n",
        "                        encodedposwmean,\n",
        "                        encodedposwstddev,\n",
        "                        deltawstddev,\n",
        "                        bestweightwmean,\n",
        "                        bestweightwstddev,\n",
        "                        autoencodermodel)\n",
        "\n",
        "                best_intermanipcost = linesearch_loss_function(posnegdata, best_advdata, autoencodermodel,\n",
        "                                                                args)\n",
        "\n",
        "            if(vectornorm):\n",
        "                best_intermanipcost = torch.norm(bestweightwmean) + torch.norm(bestweightwstddev)\n",
        "\n",
        "\n",
        "            best_intermanipcost = best_intermanipcost.item()\n",
        "            best_fitnessfnvalue = (best_intererror2 - args['lambda'] * best_intermanipcost)\n",
        "\n",
        "            print('bestweightwstddev[0, cid],cid', bestweightwstddev[0, cid], cid)\n",
        "            # print('percentfitnessfndiff', percentfitnessfndiff)\n",
        "            print('args[minpercent]', args['minpercent'])\n",
        "            # print('percentfitnessfndiff>args[minpercent]', percentfitnessfndiff > args['minpercent'])\n",
        "            print('bestpidx', bestpidx)\n",
        "            print('best_intererror2,best_intermanipcost,best_fitnessfnvalue',best_intererror2,best_intermanipcost,best_fitnessfnvalue)\n",
        "            print('best_x', best_x)\n",
        "            print('classkey, gameiter',classkey, gameiter)\n",
        "            print('deltawstddev[0, cid]', deltawstddev[0, cid])\n",
        "            print('\\n')\n",
        "\n",
        "            bestweightwstddevs[cid] = (bestweightwstddev,best_fitnessfnvalue,best_intererror2,best_intermanipcost)\n",
        "            bestweightwmeans[cid] = (bestweightwmean,best_fitnessfnvalue,best_intererror2,best_intermanipcost)\n",
        "\n",
        "\n",
        "\n",
        "            cidsx += 1\n",
        "\n",
        "\n",
        "    print('---------------------------------------Ending SA loops--------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "    if(optimizemean):\n",
        "        sortedbestweightwmeans = sorted(bestweightwmeans.items(), key=lambda kv: kv[1][1], reverse=True)\n",
        "        bestweightwmeancid = sortedbestweightwmeans[0][0]\n",
        "        bestweightwmean,bestwmeanpayoff,bestwmeanerror2,bestwmeanmanipcost = sortedbestweightwmeans[0][1]\n",
        "\n",
        "\n",
        "        print('bestweightwmeancid,bestweightwmean,bestwmeanpayoff,bestwmeanerror2,bestwmeanmanipcost',\n",
        "              bestweightwmeancid, bestweightwmean, bestwmeanpayoff,bestwmeanerror2,bestwmeanmanipcost)\n",
        "    else:\n",
        "        sortedbestweightwstddevs = sorted(bestweightwstddevs.items(), key=lambda kv: kv[1][1], reverse=True)\n",
        "        bestweightwstddevcid = sortedbestweightwstddevs[0][0]\n",
        "        bestweightwstddev,bestwstddevpayoff,bestwstddeverror2,bestwstddevmanipcost = sortedbestweightwstddevs[0][1]\n",
        "\n",
        "        print('bestweightwstddevcid, bestweightwstddev,bestwstddevpayoff,bestwstddeverror2,bestwstddevmanipcost',\n",
        "              bestweightwstddevcid, bestweightwstddev, bestwstddevpayoff,bestwstddeverror2,bestwstddevmanipcost)\n",
        "\n",
        "\n",
        "    if (savesaruns):\n",
        "        if(optimizemean):\n",
        "            args['error2ssavepath'] = args['error2ssavepath'].rstrip('.pkl')+'mu'+'.pkl'\n",
        "            args['manipcostssavepath'] = args['manipcostssavepath'].rstrip('.pkl')+'mu'+'.pkl'\n",
        "            args['fitnessfnvaluessavepath'] = args['fitnessfnvaluessavepath'].rstrip('.pkl')+'mu'+'.pkl'\n",
        "\n",
        "            args['weightwmeanssavepath'] = args['weightwmeanssavepath'].rstrip('.pkl')+'mu'+'.pkl'\n",
        "            args['weightwstddevssavepath'] = args['weightwstddevssavepath'].rstrip('.pkl')+'mu'+'.pkl'\n",
        "\n",
        "            error2sfp = open(args['error2ssavepath'], 'wb')\n",
        "            torch.save(error2s, error2sfp)\n",
        "\n",
        "            manipcostsfp = open(args['manipcostssavepath'], 'wb')\n",
        "            torch.save(manipcosts, manipcostsfp)\n",
        "\n",
        "            fitnessfnvaluesfp = open(args['fitnessfnvaluessavepath'], 'wb')\n",
        "            torch.save(fitnessfnvalues, fitnessfnvaluesfp)\n",
        "\n",
        "            weightwmeansfp = open(args['weightwmeanssavepath'], 'wb')\n",
        "            torch.save(weightwmeans, weightwmeansfp)\n",
        "\n",
        "            weightwstddevsfp = open(args['weightwstddevssavepath'], 'wb')\n",
        "\n",
        "\n",
        "            torch.save(weightwstddevs, weightwstddevsfp)\n",
        "\n",
        "            print('weightwmeansfp',args['weightwmeanssavepath'])\n",
        "            print('weightwstddevssavepath',args['weightwstddevssavepath'])\n",
        "            print('classkey', classkey)\n",
        "\n",
        "            for cid in range(0, deltawmean.shape[1]):\n",
        "                myx = weightwmeans[cid, :, :, cid].view(-1)\n",
        "                myx = myx[myx.nonzero()].tolist()\n",
        "\n",
        "                my1 = fitnessfnvalues[cid, :].view(-1)\n",
        "                my1 = my1[my1.nonzero()].tolist()\n",
        "\n",
        "                my2 = manipcosts[cid, :].view(-1)\n",
        "                my2 = my2[my2.nonzero()].tolist()\n",
        "\n",
        "                my3 = error2s[cid, :].view(-1)\n",
        "                my3 = my3[my3.nonzero()].tolist()\n",
        "\n",
        "                fig = plt.figure(1)\n",
        "                ax = fig.add_subplot(111)\n",
        "                ax.set_color_cycle(['blue', 'green', 'red'])\n",
        "\n",
        "                ax.plot(myx, my1, label='payoffs', linestyle='-', marker='o', linewidth=2)\n",
        "                ax.plot(myx, my2, label='costs', linestyle='--', marker='v', linewidth=2)\n",
        "                ax.plot(myx, my3, label='errors', linestyle='-', marker='^', linewidth=2)\n",
        "\n",
        "                xlabel('Step', fontsize=20)\n",
        "                ylabel('Fitness', fontsize=20)\n",
        "\n",
        "                handles, labels = ax.get_legend_handles_labels()\n",
        "                lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), prop={'size': 20})\n",
        "\n",
        "                ax.grid(linestyle='-', linewidth=0.4)\n",
        "                ax.xaxis.set_tick_params(labelsize=20)\n",
        "                ax.yaxis.set_tick_params(labelsize=20)\n",
        "\n",
        "                fig.savefig(\n",
        "                    \"/home/achivuku/PycharmProjects/adversariallearning/saimages/\" + str(gameiter) + ':' + classkey +'mu' + str(cid) + \".jpeg\",\n",
        "                    format='jpg', dpi=1200\n",
        "                    # )\n",
        "                    , bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "            myx = weightwmeans[0,:,:,0].view(-1)\n",
        "            myx = myx[myx.nonzero()].tolist()\n",
        "\n",
        "            my1 = fitnessfnvalues[0, :].view(-1)\n",
        "\n",
        "\n",
        "            my1 = my1[my1.nonzero()].tolist()\n",
        "\n",
        "            my2 = manipcosts[0,:].view(-1)\n",
        "\n",
        "\n",
        "            my2 = my2[my2.nonzero()].tolist()\n",
        "\n",
        "            my3 = error2s[0,:].view(-1)\n",
        "\n",
        "            my3 = my3[my3.nonzero()].tolist()\n",
        "\n",
        "            print('myx',myx)\n",
        "            print(weightwmeans[0,:,:,0].shape)\n",
        "            print('my1',my1)\n",
        "            print(fitnessfnvalues[0, :].shape)\n",
        "\n",
        "            fig = plt.figure(1)\n",
        "            ax = fig.add_subplot(111)\n",
        "            ax.set_color_cycle(['blue', 'green', 'red'])\n",
        "\n",
        "            ax.plot(myx, my1, label='payoffs', linestyle='-', marker='o', linewidth=2)\n",
        "            ax.plot(myx, my2, label='costs', linestyle='--', marker='v', linewidth=2)\n",
        "            ax.plot(myx, my3, label='errors', linestyle='-', marker='^', linewidth=2)\n",
        "\n",
        "            xlabel('Step', fontsize=20)\n",
        "            ylabel('Fitness', fontsize=20)\n",
        "\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "            lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), prop={'size': 20})\n",
        "\n",
        "            ax.grid(linestyle='-', linewidth=0.4)\n",
        "            ax.xaxis.set_tick_params(labelsize=20)\n",
        "            ax.yaxis.set_tick_params(labelsize=20)\n",
        "\n",
        "            fig.savefig(\n",
        "                \"/home/achivuku/PycharmProjects/adversariallearning/saimages/\" + str(gameiter) + ':' + classkey + 'mu' + \".jpeg\",\n",
        "                format='jpg', dpi=1200\n",
        "                # )\n",
        "                , bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            print('Check payoff plots for gameiter:'+str(gameiter)+' ,classkey:'+classkey)\n",
        "            # sys.exit()\n",
        "\n",
        "        else:\n",
        "            args['error2ssavepath'] = args['error2ssavepath'].rstrip('.pkl')+'var'+'.pkl'\n",
        "            args['manipcostssavepath'] = args['manipcostssavepath'].rstrip('.pkl')+'var'+'.pkl'\n",
        "            args['fitnessfnvaluessavepath'] = args['fitnessfnvaluessavepath'].rstrip('.pkl')+'var'+'.pkl'\n",
        "\n",
        "            args['weightwmeanssavepath'] = args['weightwmeanssavepath'].rstrip('.pkl')+'var'+'.pkl'\n",
        "            args['weightwstddevssavepath'] = args['weightwstddevssavepath'].rstrip('.pkl')+'var'+'.pkl'\n",
        "\n",
        "            error2sfp = open(args['error2ssavepath'], 'wb')\n",
        "            torch.save(error2s, error2sfp)\n",
        "\n",
        "            manipcostsfp = open(args['manipcostssavepath'], 'wb')\n",
        "            torch.save(manipcosts, manipcostsfp)\n",
        "\n",
        "            fitnessfnvaluesfp = open(args['fitnessfnvaluessavepath'], 'wb')\n",
        "            torch.save(fitnessfnvalues, fitnessfnvaluesfp)\n",
        "\n",
        "            weightwmeansfp = open(args['weightwmeanssavepath'], 'wb')\n",
        "            torch.save(weightwmeans, weightwmeansfp)\n",
        "\n",
        "            weightwstddevsfp = open(args['weightwstddevssavepath'], 'wb')\n",
        "            torch.save(weightwstddevs, weightwstddevsfp)\n",
        "\n",
        "            print('weightwmeansfp',args['weightwmeanssavepath'])\n",
        "            print('weightwstddevssavepath',args['weightwstddevssavepath'])\n",
        "            print('classkey', classkey)\n",
        "\n",
        "            for cid in xrange(0, deltawstddev.shape[1]):\n",
        "                myx = weightwstddevs[cid, :, :, cid].view(-1)\n",
        "                myx = myx[myx.nonzero()].tolist()\n",
        "\n",
        "                my1 = fitnessfnvalues[cid, :].view(-1)\n",
        "                my1 = my1[my1.nonzero()].tolist()\n",
        "\n",
        "                my2 = manipcosts[cid, :].view(-1)\n",
        "                my2 = my2[my2.nonzero()].tolist()\n",
        "\n",
        "                my3 = error2s[cid, :].view(-1)\n",
        "                my3 = my3[my3.nonzero()].tolist()\n",
        "\n",
        "                fig = plt.figure(1)\n",
        "                ax = fig.add_subplot(111)\n",
        "                ax.set_color_cycle(['blue', 'green', 'red'])\n",
        "\n",
        "                ax.plot(myx, my1, label='payoffs', linestyle='-', marker='o', linewidth=2)\n",
        "                ax.plot(myx, my2, label='costs', linestyle='--', marker='v', linewidth=2)\n",
        "                ax.plot(myx, my3, label='errors', linestyle='-', marker='^', linewidth=2)\n",
        "\n",
        "                xlabel('Step', fontsize=20)\n",
        "                ylabel('Fitness', fontsize=20)\n",
        "\n",
        "                handles, labels = ax.get_legend_handles_labels()\n",
        "                lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), prop={'size': 20})\n",
        "\n",
        "                ax.grid(linestyle='-', linewidth=0.4)\n",
        "                ax.xaxis.set_tick_params(labelsize=20)\n",
        "                ax.yaxis.set_tick_params(labelsize=20)\n",
        "\n",
        "                fig.savefig(\n",
        "                    \"/home/achivuku/PycharmProjects/adversariallearning/saimages/\" + str(gameiter) + ':' + classkey + 'var' + str(cid) + \".jpeg\",\n",
        "                    format='jpg', dpi=1200\n",
        "                    # )\n",
        "                    , bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "            myx = weightwstddevs[0,:,:,0].view(-1)\n",
        "\n",
        "            # myx = weightwmeans[1,:,:,1].view(-1)\n",
        "            myx = myx[myx.nonzero()].tolist()\n",
        "\n",
        "            my1 = fitnessfnvalues[0, :].view(-1)\n",
        "            # my1 = fitnessfnvalues[1, :].view(-1)\n",
        "            my1 = my1[my1.nonzero()].tolist()\n",
        "\n",
        "            my2 = manipcosts[0,:].view(-1)\n",
        "            # my2 = manipcosts[1,:].view(-1)\n",
        "            my2 = my2[my2.nonzero()].tolist()\n",
        "\n",
        "            my3 = error2s[0,:].view(-1)\n",
        "            # my3 = error2s[1,:].view(-1)\n",
        "            my3 = my3[my3.nonzero()].tolist()\n",
        "\n",
        "            print('myx',myx)\n",
        "            print(weightwstddevs[0,:,:,0].shape)\n",
        "            print('my1',my1)\n",
        "            print(fitnessfnvalues[0, :].shape)\n",
        "\n",
        "\n",
        "            fig = plt.figure(1)\n",
        "            ax = fig.add_subplot(111)\n",
        "            ax.set_color_cycle(['blue', 'green', 'red'])\n",
        "\n",
        "            ax.plot(myx, my1, label='payoffs', linestyle='-', marker='o', linewidth=2)\n",
        "            ax.plot(myx, my2, label='costs', linestyle='--', marker='v', linewidth=2)\n",
        "            ax.plot(myx, my3, label='errors', linestyle='-', marker='^', linewidth=2)\n",
        "\n",
        "            xlabel('Step', fontsize=20)\n",
        "            ylabel('Fitness', fontsize=20)\n",
        "\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "            lgd = ax.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), prop={'size': 20})\n",
        "\n",
        "            ax.grid(linestyle='-', linewidth=0.4)\n",
        "            ax.xaxis.set_tick_params(labelsize=20)\n",
        "            ax.yaxis.set_tick_params(labelsize=20)\n",
        "\n",
        "            fig.savefig(\n",
        "                \"/home/achivuku/PycharmProjects/adversariallearning/saimages/\" + str(gameiter) + ':' + classkey + 'var' + \".jpeg\",\n",
        "                format='jpg', dpi=1200\n",
        "                # )\n",
        "                , bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "    if(optimizemean):\n",
        "        return (bestweightwmeancid, bestweightwmean.clone(), bestweightwstddev.clone(), bestiterks, bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost)\n",
        "    else:\n",
        "        return (bestweightwstddevcid, bestweightwmean.clone(), bestweightwstddev.clone(), bestiterks, bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fde4cc-4d41-4672-94c9-fa96ca14285a",
      "metadata": {
        "id": "16fde4cc-4d41-4672-94c9-fa96ca14285a"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "import traceback\n",
        "\n",
        "class OutputCapture:\n",
        "    def __init__(self, log_file_path):\n",
        "        self.log_file = open(log_file_path, 'w', buffering=1)  # Line buffered\n",
        "        self.original_stdout = sys.stdout\n",
        "        self.original_stderr = sys.stderr\n",
        "\n",
        "    def write(self, text):\n",
        "        # Write to both console and file\n",
        "        self.original_stdout.write(text)\n",
        "        self.log_file.write(text)\n",
        "        self.log_file.flush()  # Ensure immediate write to disk\n",
        "\n",
        "    def flush(self):\n",
        "        self.original_stdout.flush()\n",
        "        self.log_file.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.log_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4434de33-fc83-454e-9c2a-6ad7e24b28bd",
      "metadata": {
        "id": "4434de33-fc83-454e-9c2a-6ad7e24b28bd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "def plot_learning_curves(train_losses, val_losses, title, filename):\n",
        "    \"\"\"Plot and save learning curves\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Create subplots for different loss components\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Total loss\n",
        "    axes[0, 0].plot(train_losses['total'], label='Training Loss', color='blue')\n",
        "    axes[0, 0].plot(val_losses['total'], label='Validation Loss', color='red')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Total Loss')\n",
        "    axes[0, 0].set_title('Total Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    # CDL loss\n",
        "    axes[0, 1].plot(train_losses['cdl'], label='Training CDL Loss', color='green')\n",
        "    axes[0, 1].plot(val_losses['cdl'], label='Validation CDL Loss', color='orange')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('CDL Loss')\n",
        "    axes[0, 1].set_title('CDL Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    # Reconstruction loss\n",
        "    axes[1, 0].plot(train_losses['recon'], label='Training Recon Loss', color='purple')\n",
        "    axes[1, 0].plot(val_losses['recon'], label='Validation Recon Loss', color='brown')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Reconstruction Loss')\n",
        "    axes[1, 0].set_title('Reconstruction Loss')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    # KLD loss\n",
        "    axes[1, 1].plot(train_losses['kld'], label='Training KLD Loss', color='pink')\n",
        "    axes[1, 1].plot(val_losses['kld'], label='Validation KLD Loss', color='gray')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('KLD Loss')\n",
        "    axes[1, 1].set_title('KLD Loss')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Learning curves saved to {filename}\")\n",
        "\n",
        "def save_reconstructed_and_original_images_cdl(model, traindata, traintargets, classes, num_images=20, device=torch.device('cpu'), save_dir='data/vae-cfm/cdl_vae_reconstructions/'):\n",
        "    \"\"\"\n",
        "    Save original and reconstructed images for specified classes - CDL-VAE version\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "\n",
        "    all_original_images = []\n",
        "    all_reconstructed_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for cls in classes:\n",
        "            print(f'Processing class {cls}...')\n",
        "\n",
        "            cls_indices = (traintargets == cls).nonzero(as_tuple=True)[0]\n",
        "\n",
        "            if len(cls_indices) < num_images:\n",
        "                print(f'Warning: Only {len(cls_indices)} images available for class {cls}')\n",
        "                selected_indices = cls_indices\n",
        "            else:\n",
        "                selected_indices = cls_indices[:num_images]\n",
        "\n",
        "            class_original_images = []\n",
        "            class_reconstructed_images = []\n",
        "\n",
        "            for i, idx in enumerate(selected_indices):\n",
        "                original_img = traindata[idx].unsqueeze(0).to(device)\n",
        "\n",
        "                # Ensure image is 64x64\n",
        "                if original_img.shape[-1] != 64 or original_img.shape[-2] != 64:\n",
        "                    original_img = F.interpolate(original_img, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "\n",
        "                # Get reconstruction from CDL-VAE\n",
        "                if model.use_cdl:\n",
        "                    results = model(original_img)\n",
        "                    if len(results) == 5:  # CDL format\n",
        "                        rec_img, mean, logvar, latent_z, coeffs = results\n",
        "                    else:  # Standard VAE\n",
        "                        rec_img, mean, logvar = results\n",
        "                else:\n",
        "                    rec_img, mean, logvar = model(original_img)\n",
        "\n",
        "                original_img = original_img.cpu()\n",
        "                rec_img = rec_img.cpu()\n",
        "\n",
        "                class_original_images.append(original_img)\n",
        "                class_reconstructed_images.append(rec_img)\n",
        "\n",
        "                # Save individual images\n",
        "                vutils.save_image(original_img, f'{save_dir}/class_{cls}_original_{i}.png', normalize=True)\n",
        "                vutils.save_image(rec_img, f'{save_dir}/class_{cls}_reconstructed_{i}.png', normalize=True)\n",
        "\n",
        "            # Create class-wise comparison grids\n",
        "            class_original_grid = torch.cat(class_original_images, dim=0)\n",
        "            class_reconstructed_grid = torch.cat(class_reconstructed_images, dim=0)\n",
        "\n",
        "            vutils.save_image(class_original_grid, f'{save_dir}/class_{cls}_original_grid.png',\n",
        "                            nrow=5, normalize=True, padding=2)\n",
        "            vutils.save_image(class_reconstructed_grid, f'{save_dir}/class_{cls}_reconstructed_grid.png',\n",
        "                            nrow=5, normalize=True, padding=2)\n",
        "\n",
        "            all_original_images.extend(class_original_images)\n",
        "            all_reconstructed_images.extend(class_reconstructed_images)\n",
        "\n",
        "            print(f'Saved {len(selected_indices)} images for class {cls}')\n",
        "\n",
        "    # Create overall comparison\n",
        "    comparison_images = []\n",
        "    for orig, recon in zip(all_original_images, all_reconstructed_images):\n",
        "        comparison_images.extend([orig, recon])\n",
        "\n",
        "    comparison_tensor = torch.cat(comparison_images, dim=0)\n",
        "    vutils.save_image(comparison_tensor, f'{save_dir}/all_classes_comparison.png',\n",
        "                     nrow=10, normalize=True, padding=2)\n",
        "\n",
        "    print(f'All images saved to {save_dir}')\n",
        "    return all_original_images, all_reconstructed_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a69e54-4fb0-4df9-8704-980b82f04d09",
      "metadata": {
        "id": "a9a69e54-4fb0-4df9-8704-980b82f04d09"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def reconstruct_with_selected_features(model, data, indices, device):\n",
        "    \"\"\"\n",
        "    Reconstruct images using only selected feature indices\n",
        "\n",
        "    Args:\n",
        "        model: Your trained CDL-VAE model\n",
        "        data: Input batch of images [batch_size, channels, height, width]\n",
        "        indices: Feature indices to keep (numpy array or tensor)\n",
        "        device: torch device (cpu or cuda)\n",
        "\n",
        "    Returns:\n",
        "        reconstructed: Reconstructed images using only selected features\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Forward pass to get latent representation\n",
        "        if model.use_cdl:\n",
        "            _, mean, logvar, latent_z, _ = model(data)\n",
        "        else:\n",
        "            _, mean, logvar = model(data)\n",
        "            latent_z = mean\n",
        "\n",
        "        # Create mask for selected features\n",
        "        mask = torch.zeros(latent_z.shape[1], device=device)\n",
        "        if isinstance(indices, np.ndarray):\n",
        "            indices = torch.from_numpy(indices).to(device)\n",
        "        mask[indices] = 1.0\n",
        "\n",
        "        # Apply mask to latent representation\n",
        "        masked_latent = latent_z * mask.unsqueeze(0)\n",
        "\n",
        "        # Decode masked latent vector\n",
        "        reconstructed = model.decode(masked_latent)\n",
        "\n",
        "    return reconstructed\n",
        "\n",
        "def calculate_reconstruction_metrics(original, reconstructed):\n",
        "    \"\"\"\n",
        "    Calculate various reconstruction error metrics\n",
        "\n",
        "    Args:\n",
        "        original: Original images tensor\n",
        "        reconstructed: Reconstructed images tensor\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of metrics\n",
        "    \"\"\"\n",
        "    mse = F.mse_loss(reconstructed, original, reduction='mean').item()\n",
        "    mae = F.l1_loss(reconstructed, original, reduction='mean').item()\n",
        "\n",
        "    # PSNR calculation\n",
        "    psnr = 20 * torch.log10(1.0 / torch.sqrt(F.mse_loss(reconstructed, original)))\n",
        "\n",
        "    return {\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'PSNR': psnr.item()\n",
        "    }\n",
        "\n",
        "def plot_feature_comparison(original_data, recon_128, recon_64, recon_32,\n",
        "                          metrics_128, metrics_64, metrics_32, num_imgs=6):\n",
        "    \"\"\"\n",
        "    Plot comparison of reconstructions with different feature counts\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(4, num_imgs, figsize=(3*num_imgs, 12))\n",
        "\n",
        "    for i in range(num_imgs):\n",
        "        # Original\n",
        "        axes[0, i].imshow(original_data[i].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
        "        axes[0, i].set_title('Original')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # 128 features\n",
        "        axes[1, i].imshow(recon_128[i].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
        "        axes[1, i].set_title(f'128 features\\nMSE: {metrics_128[\"MSE\"]:.4f}')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "        # 64 features\n",
        "        axes[2, i].imshow(recon_64[i].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
        "        axes[2, i].set_title(f'64 features\\nMSE: {metrics_64[\"MSE\"]:.4f}')\n",
        "        axes[2, i].axis('off')\n",
        "\n",
        "        # 32 features\n",
        "        axes[3, i].imshow(recon_32[i].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
        "        axes[3, i].set_title(f'32 features\\nMSE: {metrics_32[\"MSE\"]:.4f}')\n",
        "        axes[3, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_comparison_reconstructions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Main execution code\n",
        "def compare_reconstructions_by_features(model, test_loader, device, results_dir='data/vae-cdl/vae-cdl_results'):\n",
        "    \"\"\"\n",
        "    Compare reconstructions using different numbers of features\n",
        "    \"\"\"\n",
        "    # Load feature indices\n",
        "    indices_32 = np.load(f'{results_dir}/final_selected_features_32.npy')[:32]\n",
        "    indices_64 = np.load(f'{results_dir}/final_selected_features_64.npy')[:64]\n",
        "    indices_128 = np.arange(128)  # All features\n",
        "\n",
        "    # Get a batch of test data\n",
        "    data_iter = iter(test_loader)\n",
        "    test_data, _ = next(data_iter)\n",
        "    test_data = test_data[:8]  # Use first 8 images\n",
        "\n",
        "    print(\"Performing reconstructions with different feature counts...\")\n",
        "\n",
        "    # Reconstruct with different feature counts\n",
        "    with torch.no_grad():\n",
        "        # Full reconstruction (128 features)\n",
        "        model.eval()\n",
        "        if model.use_cdl:\n",
        "            recon_128, _, _, _, _ = model(test_data.to(device))\n",
        "        else:\n",
        "            recon_128, _, _ = model(test_data.to(device))\n",
        "\n",
        "        # Selective reconstructions\n",
        "        recon_64 = reconstruct_with_selected_features(model, test_data, indices_64, device)\n",
        "        recon_32 = reconstruct_with_selected_features(model, test_data, indices_32, device)\n",
        "\n",
        "    # Calculate metrics\n",
        "    original_data = test_data.to(device)\n",
        "    metrics_128 = calculate_reconstruction_metrics(original_data, recon_128)\n",
        "    metrics_64 = calculate_reconstruction_metrics(original_data, recon_64)\n",
        "    metrics_32 = calculate_reconstruction_metrics(original_data, recon_32)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n=== Reconstruction Quality Comparison ===\")\n",
        "    print(f\"128 features: MSE={metrics_128['MSE']:.6f}, MAE={metrics_128['MAE']:.6f}, PSNR={metrics_128['PSNR']:.2f}dB\")\n",
        "    print(f\"64 features:  MSE={metrics_64['MSE']:.6f}, MAE={metrics_64['MAE']:.6f}, PSNR={metrics_64['PSNR']:.2f}dB\")\n",
        "    print(f\"32 features:  MSE={metrics_32['MSE']:.6f}, MAE={metrics_32['MAE']:.6f}, PSNR={metrics_32['PSNR']:.2f}dB\")\n",
        "\n",
        "    # Calculate quality retention\n",
        "    quality_64 = 100 * (1 - (metrics_64['MSE'] - metrics_128['MSE']) / metrics_128['MSE'])\n",
        "    quality_32 = 100 * (1 - (metrics_32['MSE'] - metrics_128['MSE']) / metrics_128['MSE'])\n",
        "\n",
        "    print(f\"\\n=== Feature Efficiency ===\")\n",
        "    print(f\"64 features retain {quality_64:.1f}% of 128-feature quality using 50% features\")\n",
        "    print(f\"32 features retain {quality_32:.1f}% of 128-feature quality using 25% features\")\n",
        "\n",
        "    # Plot comparison\n",
        "    plot_feature_comparison(test_data, recon_128, recon_64, recon_32,\n",
        "                          metrics_128, metrics_64, metrics_32, num_imgs=6)\n",
        "\n",
        "    return {\n",
        "        'metrics_128': metrics_128,\n",
        "        'metrics_64': metrics_64,\n",
        "        'metrics_32': metrics_32,\n",
        "        'quality_retention_64': quality_64,\n",
        "        'quality_retention_32': quality_32\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a0c954-9d59-4cb3-bd25-51832f9e294f",
      "metadata": {
        "id": "68a0c954-9d59-4cb3-bd25-51832f9e294f"
      },
      "outputs": [],
      "source": [
        "def playgame():\n",
        "     # Create logs directory\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "\n",
        "    # Generate timestamp for unique log file\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    log_file_path = f\"logs/experiment_output_{timestamp}.log\"\n",
        "\n",
        "    # Set up output capture\n",
        "    output_capture = OutputCapture(log_file_path)\n",
        "\n",
        "    # Redirect stdout to capture all print statements\n",
        "    sys.stdout = output_capture\n",
        "    args = {}\n",
        "\n",
        "\n",
        "    if(vggfacesdataset):\n",
        "        args['batch_size'] = 64\n",
        "        args['test_batch_size'] = 64\n",
        "        args['lr'] = 1.0e-1\n",
        "        args['momentum'] = 0.9\n",
        "        args['weight_decay'] = 0.0\n",
        "        args['step_size'] = 50\n",
        "        args['gamma'] = 0.1\n",
        "        args['epochs'] = 10\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    args['log_interval'] = 10\n",
        "    args['seed'] = 1\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        args['vae_num_epochs'] = 100\n",
        "        args['model'] = \"vae-123\"\n",
        "        args['initial_lr'] = 0.0005\n",
        "        args['alpha'] = 1.0\n",
        "        args['beta'] = 0.5\n",
        "\n",
        "\n",
        "    args['cuda'] = torch.cuda.is_available()\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        positive_targets_ids = {}\n",
        "        # positive_targets_ids[\"Andy_Lau\"] = 1\n",
        "        # positive_targets_ids[\"Zhang_Jingchu\"] = 2\n",
        "        positive_targets_ids[\"bkl\"] = 0\n",
        "        # positive_targets_ids[\"Aishwarya_Rai_Bachchan\"] = 4\n",
        "        # positive_targets_ids[\"Amy_Smart\"] = 5\n",
        "        # positive_targets_ids[\"Jada_Pinkett_Smith\"] = 6\n",
        "        # positive_targets_ids[\"Bruce_Willis\"] = 7\n",
        "        # positive_targets_ids[\"Oprah_Winfrey\"] = 8\n",
        "        # positive_targets_ids[\"Denzel_Washington\"] = 9\n",
        "\n",
        "        negative_targets_ids = {}\n",
        "        negative_targets_ids[\"mel\"] = 1\n",
        "        # negative_targets_ids[\"Azim_Premji\"] = 11\n",
        "        negativeclasslabel = \"mel\"\n",
        "\n",
        "        args['positive_targets'] = []\n",
        "        for id in positive_targets_ids.values():\n",
        "            args['positive_targets'].append(id)\n",
        "        args['positive_targets'] = set(args['positive_targets'])\n",
        "        args['negative_target'] = set(negative_targets_ids.values())\n",
        "\n",
        "\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        args['lambda'] = mylambda\n",
        "\n",
        "        args['target'] = set([positive_targets_ids[\"bkl\"]])\n",
        "        positiveclasslabel = \"bkl\"\n",
        "        positiveclasslabels = [\"bkl\"]\n",
        "\n",
        "        if(trainvae):\n",
        "            positiveclasslabels = [\"bkl\"]\n",
        "        if(traincnn):\n",
        "            positiveclasslabels = [\"bkl\"]\n",
        "    if (vggfacesdataset):\n",
        "        if(morelabels):\n",
        "            additionalclasslabels = [\"akiec\", \"bcc\", \"df\", \"nv\", \"vasc\"]\n",
        "\n",
        "\n",
        "    positiveskey = ''.join(map(str, args['positive_targets']))\n",
        "    targetkey = ''.join(map(str, args['target']))\n",
        "    negkey = ''.join(map(str, args['negative_target']))\n",
        "    args['stepsizeweight'] = 1. / 100 # selected parameter value\n",
        "    args['maxiter'] = 100\n",
        "\n",
        "    args['numsteps'] = 20\n",
        "    if (vggfacesdataset):\n",
        "        args['numsteps'] = mynumsteps\n",
        "\n",
        "    args['steplower'] = 1\n",
        "    args['stepupper'] = 5\n",
        "    args['stepdec'] = 0.5\n",
        "\n",
        "    args['minpercent'] = 1\n",
        "    args['mininc'] = 0.1\n",
        "    args['maxerror_sa'] = 10\n",
        "    args['maxerror_sa_combined'] = 10\n",
        "    args['maxerror_als'] = 15\n",
        "    args['maxerror_game'] = 15\n",
        "    args['cdl_weight'] = 0.5\n",
        "    args['cdl_update_freq'] = 15\n",
        "    args['cdl_max_iter'] = 5\n",
        "    args['feature_monitor_freq'] = 50\n",
        "    args['num_selected_features'] = 100\n",
        "    args['save_freq'] = 10\n",
        "    args['results_dir'] = 'data/vae-cdl/vae-cdl_results'\n",
        "    args['cdl_tau'] = 0.01\n",
        "    args['cdl_p'] = 0.7\n",
        "    args['dict_size'] = 512\n",
        "\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        args['vaetrainmodelsavepath'] = 'data/vae-cdl/initialvggfaces2vae-b3'+ str(codesize) +'.pth'\n",
        "\n",
        "        args['traindatasetssavepath'] = 'data/vae-cdl/vggfaces2datasets-b3' + positiveskey + negkey + targetkey + '.pkl'\n",
        "        args['trainlabelssavepath'] = 'data/vae-cdl/vggfaces2labels-b3' + positiveskey + negkey + targetkey + '.pkl'\n",
        "\n",
        "        args['advtraindatasetssavepath'] = 'data/vae-cdl/vggfaces2advdatasets-b3'  + positiveskey + negkey + targetkey + '.pkl'\n",
        "        args['advtrainlabelssavepath'] = 'data/vae-cdl/vggfaces2advlabels-b3'  + positiveskey + negkey + targetkey + '.pkl'\n",
        "\n",
        "        args['advtestdatasetssavepath'] = 'data/vae-cdl/vggfaces2advtestdatasets-b3'  + positiveskey + negkey + targetkey + '.pkl'\n",
        "        args['advtestlabelssavepath'] = 'data/vae-cdl/vggfaces2advtestlabels-b3'  + positiveskey + negkey + targetkey + '.pkl'\n",
        "\n",
        "        # args['initialtrainmodelsavepath'] = '/data/achivuku/PycharmProjects/adversariallearning/vggfaces2/initialvggfaces2cnn-b3' + positiveskey + negkey + '.pth'\n",
        "        args['initialtrainmodelsavepath'] = 'data/vae-cdl/initialvggfaces2cnn-b3' + positiveskey + negkey + targetkey + '.pth'\n",
        "\n",
        "\n",
        "    args['advtrainimagessavepath'] = 'data/vae-cdl/manipulations/train'\n",
        "    args['origtrainimagessavepath'] = 'data/vae-cdl/originals/train'\n",
        "\n",
        "    args['advtestimagessavepath'] = 'data/vae-cdl/manipulations/test'\n",
        "    args['origtestimagessavepath'] = 'data/vae-cdl/originals/test'\n",
        "\n",
        "\n",
        "    if (not oldversion):\n",
        "\n",
        "        # Uncomment this code block when experimenting with numsteps,lambda,codesize in cifar10\n",
        "        if (vggfacesdataset):\n",
        "            args['bestwmeanssavepath'] = 'data/vae-cdl/vggfaces2wmeanmanips-b3'  + targetkey + negkey + str(args['numsteps']) + str(args['lambda'])+ str(codesize) + '.pkl'\n",
        "            args['bestwstddevssavepath'] = 'data/vae-cdl/vggfaces2wstddevmanips-b3'  + targetkey + negkey + str(args['numsteps']) + str(args['lambda'])+ str(codesize) + '.pkl'\n",
        "\n",
        "            args['trainmodelsavepath'] = 'data/vae-cdl/vggfaces2cnn-b3' + targetkey + negkey  + str(args['numsteps']) + str(args['lambda']) + str(codesize) + '.pth'\n",
        "            args['finaltrainmodelsavepath'] = 'data/vae-cdl/finalvggfaces2cnn-b3' + targetkey + negkey + str(args['numsteps']) + str(args['lambda']) + str(codesize) + '.pth'\n",
        "\n",
        "\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        negative_train = \"ham10000/classified_images_train/\" + negativeclasslabel\n",
        "        Rootdir = negative_train\n",
        "        negtrainimages, negtrainlabels = loader_vggfaces2(Rootdir, negkey)\n",
        "\n",
        "        vggfacestraindata = negtrainimages.clone()\n",
        "        vggfacestraintargets = negtrainlabels.clone()\n",
        "\n",
        "        vggfacespostraindata = torch.zeros(0, 3, vggface_image_length, vggface_image_length)\n",
        "        vggfacespostraintargets = torch.zeros(0, )\n",
        "\n",
        "        vggfacesnegtraindata = negtrainimages.clone()\n",
        "        vggfacesnegtraintargets = negtrainlabels.clone()\n",
        "\n",
        "        for allpositiveclasslabel in positiveclasslabels:\n",
        "            positive_train = \"ham10000/classified_images_train/\" + allpositiveclasslabel\n",
        "\n",
        "            Rootdir = positive_train\n",
        "            postrainimages, postrainlabels = loader_vggfaces2(Rootdir, targetkey)\n",
        "\n",
        "            vggfacestraindata = torch.cat((vggfacestraindata, postrainimages), 0)\n",
        "            vggfacestraintargets = torch.cat((vggfacestraintargets, postrainlabels), 0)\n",
        "\n",
        "\n",
        "            vggfacespostraindata = torch.cat((vggfacespostraindata, postrainimages), 0)\n",
        "            vggfacespostraintargets = torch.cat((vggfacespostraintargets, postrainlabels.float()), 0)\n",
        "\n",
        "\n",
        "        positive_test = \"ham10000/classified_images_val/\" + positiveclasslabel\n",
        "        negative_test = \"ham10000/classified_images_val/\" + negativeclasslabel\n",
        "\n",
        "        Rootdir = positive_test\n",
        "        postestimages, postestlabels = loader_vggfaces2(Rootdir, targetkey)\n",
        "        Rootdir = negative_test\n",
        "        negtestimages, negtestlabels = loader_vggfaces2(Rootdir, negkey)\n",
        "\n",
        "        vggfacestestdata = torch.cat((postestimages, negtestimages), 0)\n",
        "        vggfacestesttargets = torch.cat((postestlabels, negtestlabels), 0)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(vggfacestraindata, vggfacestraintargets.long()),\n",
        "            batch_size=args['batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(vggfacestestdata, vggfacestesttargets.long()),\n",
        "            batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "    # vaepreprocess = True\n",
        "    vaepreprocess = True # No need to preprocess VAE data until entire MNIST database is used\n",
        "    if(vaepreprocess):\n",
        "        classpartitioneddatasets = collections.defaultdict()\n",
        "        classpartitionedlabels = collections.defaultdict()\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            classpartitioneddatasets[targetkey] = vggfacespostraindata.clone()\n",
        "            classpartitionedlabels[targetkey] = vggfacespostraintargets.clone()\n",
        "\n",
        "            classpartitioneddatasets[negkey] = vggfacesnegtraindata.clone()\n",
        "            classpartitionedlabels[negkey] = vggfacesnegtraintargets.clone()\n",
        "\n",
        "\n",
        "        datasetsfp = open(args['traindatasetssavepath'],'wb')\n",
        "        labelsfp = open(args['trainlabelssavepath'],'wb')\n",
        "        pickle.dump(classpartitioneddatasets,datasetsfp)\n",
        "        pickle.dump(classpartitionedlabels,labelsfp)\n",
        "        print('Data preprocessing done !')\n",
        "        # sys.exit()\n",
        "\n",
        "    datasetsfp = open(args['traindatasetssavepath'], 'rb')\n",
        "    labelsfp = open(args['trainlabelssavepath'], 'rb')\n",
        "    traindatasets = pickle.load(datasetsfp)\n",
        "    trainlabels = pickle.load(labelsfp)\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        # traindata = torch.zeros(0, 3, 28, 28)\n",
        "        traindata = torch.zeros(0, 3, vggface_image_length, vggface_image_length)\n",
        "\n",
        "    traintargets = torch.zeros(0, )\n",
        "    for key in traindatasets.keys():\n",
        "        data, target = traindatasets[key], trainlabels[key].float()\n",
        "        print('data.shape','target.shape',data.shape,target.shape)\n",
        "        print('traindata.shape','traintargets.shape',traindata.shape,traintargets.shape)\n",
        "        traindata, traintargets = torch.cat((traindata,data),0), torch.cat((traintargets,target),0)\n",
        "\n",
        "    # sys.exit()\n",
        "\n",
        "\n",
        "    if(trainvae):\n",
        "        device = torch.device(\"cuda\" if args['cuda'] else \"cpu\")\n",
        "\n",
        "        # Initialize loss tracking\n",
        "        train_losses = {\n",
        "            'total': [],\n",
        "            'kld': [],\n",
        "            'recon': [],\n",
        "            'cdl': [],\n",
        "            'cdl_recon': [],\n",
        "            'cdl_sparsity': []\n",
        "        }\n",
        "        val_losses = {\n",
        "            'total': [],\n",
        "            'kld': [],\n",
        "            'recon': [],\n",
        "            'cdl': [],\n",
        "            'cdl_recon': [],\n",
        "            'cdl_sparsity': []\n",
        "        }\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            # Initialize model with CDL parameters\n",
        "            model = VAE_VGGFACES2(\n",
        "                nc=3,                                    # RGB channels\n",
        "                ndf=32,                                  # Decoder feature dimension\n",
        "                nef=32,                                  # Encoder feature dimension\n",
        "                nz=128,                                  # Latent dimension\n",
        "                device=device,\n",
        "                is_train=True,                           # Training mode\n",
        "                use_cdl=True,                           # Enable CDL\n",
        "                dict_size=args.get('dict_size', 256),   # Dictionary size\n",
        "                cdl_tau=args.get('cdl_tau', 0.1),       # CDL sparsity weight\n",
        "                cdl_p=args.get('cdl_p', 0.5)            # CDL regularization parameter\n",
        "            ).to(device)\n",
        "\n",
        "            # Reconstruction loss\n",
        "            reconst_criterion = FLPLoss(args['model'], device, reduction='sum')\n",
        "            # KLD loss\n",
        "            kld_criterion = KLDLoss(reduction='sum')\n",
        "            optimizer = optim.Adam(model.parameters(), lr=args['initial_lr'])\n",
        "            model.train(True)\n",
        "\n",
        "        for epoch in range(args['vae_num_epochs']):\n",
        "            # TRAINING PHASE\n",
        "            model.train()\n",
        "            epoch_loss = 0\n",
        "            epoch_kld = 0\n",
        "            epoch_recon = 0\n",
        "            epoch_cdl = 0\n",
        "            epoch_cdl_recon = 0\n",
        "            epoch_cdl_sparsity = 0\n",
        "\n",
        "            for batch_idx, (data, target) in enumerate(train_loader):\n",
        "                if (vggfacesdataset):\n",
        "                    data = data.to(device)\n",
        "\n",
        "                    # Ensure data is 64x64 (the model will auto-resize if needed)\n",
        "                    if data.size(2) != 64 or data.size(3) != 64:\n",
        "                        data = F.interpolate(data, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if (vggfacesdataset):\n",
        "                    # Forward pass - handle CDL outputs\n",
        "                    if model.use_cdl and model.training:\n",
        "                        rec_data, mean, logvar, latent_z, coeffs = model(data)\n",
        "                        # Compute CDL loss components\n",
        "                        cdl_loss, cdl_recon_loss, cdl_sparsity_loss = model.compute_cdl_loss(latent_z)\n",
        "                    else:\n",
        "                        rec_data, mean, logvar = model(data)\n",
        "                        cdl_loss = 0\n",
        "                        cdl_recon_loss = 0\n",
        "                        cdl_sparsity_loss = 0\n",
        "\n",
        "                    # Compute standard losses\n",
        "                    reconst_loss = reconst_criterion(rec_data, data)\n",
        "                    kld_loss = kld_criterion(mean, logvar)\n",
        "\n",
        "                    # Total loss with CDL component\n",
        "                    loss = (args[\"alpha\"] * kld_loss +\n",
        "                           args[\"beta\"] * reconst_loss +\n",
        "                           args.get(\"cdl_weight\", 1.0) * cdl_loss)\n",
        "\n",
        "                    # Accumulate losses for logging\n",
        "                    epoch_loss += loss.item()\n",
        "                    epoch_kld += kld_loss.item()\n",
        "                    epoch_recon += reconst_loss.item()\n",
        "\n",
        "                    # Handle CDL losses (check if tensor or scalar)\n",
        "                    if isinstance(cdl_loss, torch.Tensor):\n",
        "                        epoch_cdl += cdl_loss.item()\n",
        "                        epoch_cdl_recon += cdl_recon_loss.item()\n",
        "                        epoch_cdl_sparsity += cdl_sparsity_loss.item()\n",
        "                    else:\n",
        "                        epoch_cdl += cdl_loss\n",
        "                        epoch_cdl_recon += cdl_recon_loss\n",
        "                        epoch_cdl_sparsity += cdl_sparsity_loss\n",
        "\n",
        "                # Standard gradient-based optimization\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Apply dictionary constraints after parameter update\n",
        "                if model.use_cdl:\n",
        "                    model.apply_constraints()\n",
        "\n",
        "                # **NEW: Explicit CDL optimization using ADMM/IRLS every N batches**\n",
        "                if (model.use_cdl and model.training and\n",
        "                    batch_idx % args.get('cdl_update_freq', 10) == 0):\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        # Perform explicit CDL optimization step\n",
        "                        model.perform_cdl_optimization(latent_z,\n",
        "                                                     max_iter=args.get('cdl_max_iter', 3))\n",
        "\n",
        "                # **NEW: Optional feature selection monitoring every M batches**\n",
        "                if (model.use_cdl and\n",
        "                    batch_idx % args.get('feature_monitor_freq', 50) == 0):\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        feature_importance = model.get_feature_importance()\n",
        "                        num_active_features = torch.sum(feature_importance > 1e-6).item()\n",
        "                        avg_importance = torch.mean(feature_importance).item()\n",
        "\n",
        "                        if batch_idx % 100 == 0:  # Print less frequently\n",
        "                            print(f'Batch {batch_idx}: Active features: {num_active_features}/{len(feature_importance)}, '\n",
        "                                  f'Avg importance: {avg_importance:.6f}')\n",
        "\n",
        "            # VALIDATION PHASE\n",
        "            model.eval()\n",
        "            val_epoch_loss = 0\n",
        "            val_epoch_kld = 0\n",
        "            val_epoch_recon = 0\n",
        "            val_epoch_cdl = 0\n",
        "            val_epoch_cdl_recon = 0\n",
        "            val_epoch_cdl_sparsity = 0\n",
        "            val_batches = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for val_data, val_target in test_loader:\n",
        "                    if vggfacesdataset:\n",
        "                        val_data = val_data.to(device)\n",
        "                        if val_data.size(2) != 64 or val_data.size(3) != 64:\n",
        "                            val_data = F.interpolate(val_data, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "\n",
        "                    if vggfacesdataset:\n",
        "                        # Forward pass - handle outputs consistently\n",
        "                        val_results = model(val_data)\n",
        "\n",
        "                        if model.use_cdl:\n",
        "                            # CDL enabled: expect 5 outputs\n",
        "                            if len(val_results) == 5:\n",
        "                                val_rec_data, val_mean, val_logvar, val_latent_z, val_coeffs = val_results\n",
        "                                val_cdl_loss, val_cdl_recon_loss, val_cdl_sparsity_loss = model.compute_cdl_loss(val_latent_z)\n",
        "                            else:\n",
        "                                raise ValueError(f\"Expected 5 outputs with CDL enabled, got {len(val_results)}\")\n",
        "                        else:\n",
        "                            # CDL disabled: expect 3 outputs\n",
        "                            if len(val_results) == 3:\n",
        "                                val_rec_data, val_mean, val_logvar = val_results\n",
        "                                val_cdl_loss = 0\n",
        "                                val_cdl_recon_loss = 0\n",
        "                                val_cdl_sparsity_loss = 0\n",
        "                            else:\n",
        "                                raise ValueError(f\"Expected 3 outputs with CDL disabled, got {len(val_results)}\")\n",
        "\n",
        "                        # Compute validation losses\n",
        "                        val_reconst_loss = reconst_criterion(val_rec_data, val_data)\n",
        "                        val_kld_loss = kld_criterion(val_mean, val_logvar)\n",
        "\n",
        "                        val_loss = (args[\"alpha\"] * val_kld_loss +\n",
        "                                   args[\"beta\"] * val_reconst_loss +\n",
        "                                   args.get(\"cdl_weight\", 1.0) * val_cdl_loss)\n",
        "\n",
        "                        # Accumulate validation losses\n",
        "                        val_epoch_loss += val_loss.item()\n",
        "                        val_epoch_kld += val_kld_loss.item()\n",
        "                        val_epoch_recon += val_reconst_loss.item()\n",
        "\n",
        "                        if isinstance(val_cdl_loss, torch.Tensor):\n",
        "                            val_epoch_cdl += val_cdl_loss.item()\n",
        "                            val_epoch_cdl_recon += val_cdl_recon_loss.item()\n",
        "                            val_epoch_cdl_sparsity += val_cdl_sparsity_loss.item()\n",
        "                        else:\n",
        "                            val_epoch_cdl += val_cdl_loss\n",
        "                            val_epoch_cdl_recon += val_cdl_recon_loss\n",
        "                            val_epoch_cdl_sparsity += val_cdl_sparsity_loss\n",
        "\n",
        "                    val_batches += 1\n",
        "\n",
        "            # Store losses for plotting\n",
        "            num_train_batches = len(train_loader)\n",
        "            num_val_batches = val_batches\n",
        "\n",
        "            train_losses['total'].append(epoch_loss / num_train_batches)\n",
        "            train_losses['kld'].append(epoch_kld / num_train_batches)\n",
        "            train_losses['recon'].append(epoch_recon / num_train_batches)\n",
        "            train_losses['cdl'].append(epoch_cdl / num_train_batches)\n",
        "            train_losses['cdl_recon'].append(epoch_cdl_recon / num_train_batches)\n",
        "            train_losses['cdl_sparsity'].append(epoch_cdl_sparsity / num_train_batches)\n",
        "\n",
        "            val_losses['total'].append(val_epoch_loss / num_val_batches)\n",
        "            val_losses['kld'].append(val_epoch_kld / num_val_batches)\n",
        "            val_losses['recon'].append(val_epoch_recon / num_val_batches)\n",
        "            val_losses['cdl'].append(val_epoch_cdl / num_val_batches)\n",
        "            val_losses['cdl_recon'].append(val_epoch_cdl_recon / num_val_batches)\n",
        "            val_losses['cdl_sparsity'].append(val_epoch_cdl_sparsity / num_val_batches)\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print('=== Epoch [{}/{}] Summary ==='.format(epoch + 1, args['vae_num_epochs']))\n",
        "            print('  TRAINING:')\n",
        "            print('    Avg Total Loss: {:.4f}, KLD: {:.4f}, Recon: {:.4f}, CDL: {:.4f}, CDL_Recon: {:.4f}, CDL_Sparse: {:.4f}'\n",
        "                  .format(train_losses['total'][-1], train_losses['kld'][-1], train_losses['recon'][-1],\n",
        "                         train_losses['cdl'][-1], train_losses['cdl_recon'][-1], train_losses['cdl_sparsity'][-1]))\n",
        "            print('  VALIDATION:')\n",
        "            print('    Avg Total Loss: {:.4f}, KLD: {:.4f}, Recon: {:.4f}, CDL: {:.4f}, CDL_Recon: {:.4f}, CDL_Sparse: {:.4f}'\n",
        "                  .format(val_losses['total'][-1], val_losses['kld'][-1], val_losses['recon'][-1],\n",
        "                         val_losses['cdl'][-1], val_losses['cdl_recon'][-1], val_losses['cdl_sparsity'][-1]))\n",
        "            print('=' * 40)\n",
        "\n",
        "            # **NEW: Save feature importance at end of each epoch**\n",
        "            if model.use_cdl and (epoch + 1) % args.get('save_freq', 10) == 0:\n",
        "                feature_importance = model.get_feature_importance().cpu().numpy()\n",
        "                os.makedirs(args.get('results_dir', './results'), exist_ok=True)\n",
        "                np.save(f\"{args.get('results_dir', './results')}/feature_importance_epoch_{epoch+1}.npy\",\n",
        "                       feature_importance)\n",
        "\n",
        "                # Select top features and save indices\n",
        "                num_top_features = args.get('num_selected_features', 64)\n",
        "                if model.use_cdl:\n",
        "                    indices, weights = model.cdl_layer.select_features(num_top_features)\n",
        "                    np.save(f\"{args.get('results_dir', './results')}/selected_features_epoch_{epoch+1}.npy\",\n",
        "                           indices.cpu().numpy())\n",
        "                    print(f'Selected top {num_top_features} features with weights: '\n",
        "                          f'mean={torch.mean(weights):.6f}, std={torch.std(weights):.6f}')\n",
        "\n",
        "        # POST-TRAINING ANALYSIS\n",
        "        print('Saving reconstructed and original images...')\n",
        "\n",
        "        # Save model and images\n",
        "        model.to(device)\n",
        "        classes_to_save = [0, 1] if hasattr(args, 'classes_to_save') else [0, 1]\n",
        "        original_images, reconstructed_images = save_reconstructed_and_original_images_cdl(\n",
        "            model=model,\n",
        "            traindata=traindata,\n",
        "            traintargets=traintargets,\n",
        "            classes=classes_to_save,\n",
        "            num_images=20,\n",
        "            device=device,\n",
        "            save_dir='data/vae-cdl/cdl_vae_reconstructions/'\n",
        "        )\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            model.cpu()\n",
        "\n",
        "\n",
        "            if model.use_cdl:\n",
        "                model.to(device)\n",
        "                model.eval()\n",
        "\n",
        "                # Get final feature importance rankings\n",
        "                with torch.no_grad():\n",
        "                    final_importance = model.get_feature_importance()\n",
        "\n",
        "                    # Select different numbers of features for analysis\n",
        "                    for num_features in [32, 64, 128]:\n",
        "                        if num_features <= len(final_importance):\n",
        "                            indices, weights = model.cdl_layer.select_features(num_features)\n",
        "                            print(f'Top {num_features} features - indices: {indices[:10].cpu().numpy()}, '\n",
        "                                  f'weights: {weights[:10].cpu().numpy()}')\n",
        "\n",
        "                            # Save final selections\n",
        "                            os.makedirs(args.get('results_dir', './results'), exist_ok=True)\n",
        "                            np.save(f\"{args.get('results_dir', './results')}/final_selected_features_{num_features}.npy\",\n",
        "                                   indices.cpu().numpy())\n",
        "                            np.save(f\"{args.get('results_dir', './results')}/final_feature_weights_{num_features}.npy\",\n",
        "                                   weights.cpu().numpy())\n",
        "\n",
        "                model.cpu()\n",
        "\n",
        "        torch.save(model.state_dict(), args['vaetrainmodelsavepath'])\n",
        "        print('Training Variational Autoencoder with CDL done')\n",
        "\n",
        "        # Plot learning curves\n",
        "        if 'train_losses' in locals():\n",
        "            plot_learning_curves(train_losses, val_losses, 'CDL-VAE Learning Curves', args.get('results_dir', './results') + '/cdl_vae_learning_curves.png')\n",
        "\n",
        "            # Save loss data for later analysis\n",
        "            np.save(f\"{args.get('results_dir', './results')}/train_losses.npy\", train_losses)\n",
        "            np.save(f\"{args.get('results_dir', './results')}/val_losses.npy\", val_losses)\n",
        "\n",
        "            print(f\"\\n=== CDL-VAE Training Complete ===\")\n",
        "            print(f\"Final Training Loss: {train_losses['total'][-1]:.6f}\")\n",
        "            print(f\"Final Validation Loss: {val_losses['total'][-1]:.6f}\")\n",
        "            print(f\"Final CDL Loss: {train_losses['cdl'][-1]:.6f}\")\n",
        "\n",
        "    if(traincnn):\n",
        "        traincnn_start = time.time()\n",
        "\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            model = models.resnet18(pretrained=True)\n",
        "            model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            model.maxpool = nn.Identity()\n",
        "            optimizer = torch.optim.SGD(\n",
        "                [\n",
        "                    {'params': get_parameters(model, bias=False)},\n",
        "                    {'params': get_parameters(model, bias=True), 'lr': args['lr'] * 2, 'weight_decay': args['weight_decay']},\n",
        "                ],\n",
        "                lr=args['lr'],\n",
        "                momentum=args['momentum'],\n",
        "                weight_decay=args['weight_decay'])\n",
        "\n",
        "        device = torch.device(\"cuda\" if args['cuda'] else \"cpu\")\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "\n",
        "        for epoch in range(1, args['epochs'] + 1):\n",
        "            train(args, model, train_loader, optimizer, epoch)\n",
        "        # torch.save(model.state_dict(), args['trainmodelsavepath'])\n",
        "\n",
        "        model.cpu()\n",
        "        torch.save(model.state_dict(), args['initialtrainmodelsavepath'])\n",
        "        print('Training CNN done')\n",
        "        # sys.exit()\n",
        "        traincnn_end = time.time()\n",
        "        print('CNN training time in hours:', (traincnn_end - traincnn_start) / (60 * 60))\n",
        "\n",
        "\n",
        "    print('Training autoencoder and cnn models completed on mnist database. Start game preprocessing on labelsets.')\n",
        "    # sys.exit()\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # model = VAE_VGGFACES2(\n",
        "    #             nc=3,                                    # RGB channels\n",
        "    #             ndf=32,                                  # Decoder feature dimension\n",
        "    #             nef=32,                                  # Encoder feature dimension\n",
        "    #             nz=128,                                  # Latent dimension\n",
        "    #             device=device,\n",
        "    #             is_train=True,                           # Training mode\n",
        "    #             use_cdl=True,                           # Enable CDL\n",
        "    #             dict_size=args.get('dict_size', 256),   # Dictionary size\n",
        "    #             cdl_tau=args.get('cdl_tau', 0.1),       # CDL sparsity weight\n",
        "    #             cdl_p=args.get('cdl_p', 0.5)            # CDL regularization parameter\n",
        "    #         ).to(device)\n",
        "    # model.load_state_dict(torch.load(args['vaetrainmodelsavepath']))\n",
        "    # model = model.to(device)\n",
        "    # results = compare_reconstructions_by_features(model, test_loader, device)\n",
        "    if (gamepreprocess):\n",
        "        classpartitioneddatasets = collections.defaultdict(dict)\n",
        "        classpartitionedlabels = collections.defaultdict(dict)\n",
        "\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            for argstarget in args['positive_targets']:\n",
        "                for classlabel in args['negative_target']:\n",
        "                    classpartitioneddatasets[argstarget][classlabel] = torch.zeros(0, 3, vggface_image_length, vggface_image_length)\n",
        "                    classpartitionedlabels[argstarget][classlabel] = torch.zeros(0, )\n",
        "\n",
        "            for argstarget in args['positive_targets']:\n",
        "                for data, target in train_loader:\n",
        "                    indexvector1 = target == argstarget\n",
        "                    for classlabel in args['negative_target']:\n",
        "                        indexvector2 = target == classlabel\n",
        "\n",
        "                        # print(target[indexvector1],'target[indexvector1]')\n",
        "                        classpartitioneddatasets[argstarget][classlabel], classpartitionedlabels[argstarget][classlabel] = \\\n",
        "                            torch.cat((classpartitioneddatasets[argstarget][classlabel], data[indexvector1]), 0), \\\n",
        "                            torch.cat((classpartitionedlabels[argstarget][classlabel], target[indexvector1].float()), 0)\n",
        "\n",
        "                        classpartitioneddatasets[argstarget][classlabel], classpartitionedlabels[argstarget][classlabel] = \\\n",
        "                            torch.cat((classpartitioneddatasets[argstarget][classlabel], data[indexvector2]), 0), \\\n",
        "                            torch.cat((classpartitionedlabels[argstarget][classlabel], target[indexvector2].float()), 0)\n",
        "\n",
        "\n",
        "        datasetsfp = open(args['advtraindatasetssavepath'],'wb')\n",
        "        labelsfp = open(args['advtrainlabelssavepath'],'wb')\n",
        "        pickle.dump(classpartitioneddatasets,datasetsfp)\n",
        "        pickle.dump(classpartitionedlabels,labelsfp)\n",
        "        print('Game Data preprocessing done !')\n",
        "        # sys.exit()\n",
        "\n",
        "\n",
        "\n",
        "    if (gamepostprocess):\n",
        "\n",
        "        advtestdatasets = collections.defaultdict(dict)\n",
        "        advtestlabels = collections.defaultdict(dict)\n",
        "\n",
        "\n",
        "        if (vggfacesdataset):\n",
        "            for argstarget in args['positive_targets']:\n",
        "                for classlabel in args['negative_target']:\n",
        "                    advtestdatasets[argstarget][classlabel] = torch.zeros(0, 3, vggface_image_length, vggface_image_length)\n",
        "                    advtestlabels[argstarget][classlabel] = torch.zeros(0, )\n",
        "\n",
        "\n",
        "            for argstarget in args['positive_targets']:\n",
        "                for data, target in test_loader:\n",
        "                    indexvector1 = target == argstarget\n",
        "                    for classlabel in args['negative_target']:\n",
        "                        indexvector2 = target == classlabel\n",
        "\n",
        "                        advtestdatasets[argstarget][classlabel], advtestlabels[argstarget][classlabel] = \\\n",
        "                            torch.cat((advtestdatasets[argstarget][classlabel], data[indexvector1]), 0), \\\n",
        "                            torch.cat((advtestlabels[argstarget][classlabel], target[indexvector1].float()), 0)\n",
        "\n",
        "                        advtestdatasets[argstarget][classlabel], advtestlabels[argstarget][classlabel] = \\\n",
        "                            torch.cat((advtestdatasets[argstarget][classlabel], data[indexvector2]), 0), \\\n",
        "                            torch.cat((advtestlabels[argstarget][classlabel], target[indexvector2].float()), 0)\n",
        "\n",
        "\n",
        "\n",
        "        datasetsfp = open(args['advtestdatasetssavepath'],'wb')\n",
        "        labelsfp = open(args['advtestlabelssavepath'],'wb')\n",
        "        pickle.dump(advtestdatasets,datasetsfp)\n",
        "        pickle.dump(advtestlabels,labelsfp)\n",
        "        print('Game Data postprocessing done !')\n",
        "        # sys.exit()\n",
        "\n",
        "\n",
        "    datasetsfp = open(args['advtestdatasetssavepath'], 'rb')\n",
        "    labelsfp = open(args['advtestlabelssavepath'], 'rb')\n",
        "    advtestdatasets = pickle.load(datasetsfp)\n",
        "    advtestlabels = pickle.load(labelsfp)\n",
        "\n",
        "\n",
        "    datasetsfp = open(args['advtraindatasetssavepath'], 'rb')\n",
        "    labelsfp = open(args['advtrainlabelssavepath'], 'rb')\n",
        "    advtraindatasets = pickle.load(datasetsfp)\n",
        "    advtrainlabels = pickle.load(labelsfp)\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        autoencodermodel = VAE_VGGFACES2(device=torch.device(\"cpu\"))\n",
        "\n",
        "    autoencodermodel.load_state_dict(torch.load(args['vaetrainmodelsavepath']))\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        model.maxpool = nn.Identity()\n",
        "\n",
        "    model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "    print('Processing labelsets and Loading models done. Start game to generate manipulations.')\n",
        "\n",
        "    generatemanipulations = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if(generatemanipulations):\n",
        "\n",
        "        game_start = time.time()\n",
        "\n",
        "\n",
        "        bestwmeans = {}\n",
        "        bestwstddevs = {}\n",
        "\n",
        "        weightwmeans = {}\n",
        "        weightwstddevs = {}\n",
        "\n",
        "\n",
        "        for argstarget in args['target']:\n",
        "            for splitlabel in args['negative_target']:\n",
        "                print('argstarget, splitlabel', argstarget, splitlabel)\n",
        "                print('=========================================Begin Game======================================================')\n",
        "\n",
        "                bestiterks = {}\n",
        "                classkey = str(argstarget) + str(splitlabel)\n",
        "                if (vggfacesdataset):\n",
        "                    model = models.resnet18(pretrained=True)\n",
        "                    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "                    model.maxpool = nn.Identity()\n",
        "\n",
        "                model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "                posnegdata = advtraindatasets[argstarget][splitlabel]\n",
        "                posnegtargets = advtrainlabels[argstarget][splitlabel].float()\n",
        "\n",
        "                adv_split_loader = torch.utils.data.DataLoader(\n",
        "                        torch.utils.data.TensorDataset(posnegdata,posnegtargets.long(),posnegdata),\n",
        "                        batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "\n",
        "                error1, overallerror1, tprserrors1 = test(args, model, adv_split_loader)\n",
        "                print('initial train error1', error1, ' given argstarget, splitlabel ', argstarget, splitlabel)\n",
        "\n",
        "                testposnegdata = advtestdatasets[argstarget][splitlabel]\n",
        "                testposnegtargets = advtestlabels[argstarget][splitlabel].float().long()\n",
        "                test_adv_split_loader = torch.utils.data.DataLoader(\n",
        "                    torch.utils.data.TensorDataset(testposnegdata, testposnegtargets, testposnegdata),\n",
        "                    batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "                error1, overallerror1, tprserrors1 = test(args, model, test_adv_split_loader)\n",
        "                print('initial test error1', error1, ' given argstarget, splitlabel ', argstarget, splitlabel)\n",
        "\n",
        "\n",
        "                copyfile(args['initialtrainmodelsavepath'], args['trainmodelsavepath'])\n",
        "\n",
        "\n",
        "                posindexvector = posnegtargets == argstarget\n",
        "                negindexvector = posnegtargets == splitlabel\n",
        "\n",
        "                encodednegwmean, encodednegwstddev = autoencodermodel.encode(posnegdata[negindexvector])\n",
        "                encodedposwmean, encodedposwstddev = autoencodermodel.encode(posnegdata[posindexvector])\n",
        "\n",
        "                encodedposwmean = encodedposwmean.detach()\n",
        "                encodednegwmean = encodednegwmean.detach()\n",
        "\n",
        "                encodedposwstddev = encodedposwstddev.detach()\n",
        "                encodednegwstddev = encodednegwstddev.detach()\n",
        "\n",
        "                print(encodednegwmean.shape)\n",
        "                print(encodedposwmean.shape)\n",
        "                print(posindexvector.shape)\n",
        "\n",
        "\n",
        "                encodedposnegreconwmean, encodedposnegreconwstddev = autoencodermodel.encode(posnegdata)\n",
        "                print(encodedposnegreconwmean, encodedposnegreconwstddev,'encodedposnegreconwmean, encodedposnegreconwstddev')\n",
        "                print('autoencodermodel',autoencodermodel)\n",
        "\n",
        "                encodedadvrecondata = autoencodermodel.reparameterize(encodedposnegreconwmean, encodedposnegreconwstddev)\n",
        "                posnegrecondata = autoencodermodel.decode(encodedadvrecondata)\n",
        "                advrecon_split_loader = torch.utils.data.DataLoader(\n",
        "                    torch.utils.data.TensorDataset(posnegrecondata, posnegtargets.long(), posnegrecondata),\n",
        "                    batch_size=args['test_batch_size'], shuffle=True)\n",
        "                reconerror1, reconoverallerror1, recontprserrors1 = test(args, model, advrecon_split_loader)\n",
        "                print('after encoding+decoding initial error1', reconerror1, ' given argstarget, splitlabel ', argstarget, splitlabel)\n",
        "\n",
        "\n",
        "                deltawmean = encodednegwmean.mean(dim=0) - encodedposwmean.mean(dim=0)\n",
        "                deltawstddev = encodednegwstddev.mean(dim=0) - encodedposwstddev.mean(dim=0)\n",
        "                deltawmean = deltawmean.view(1,encodednegwmean.shape[1])\n",
        "                deltawstddev = deltawstddev.view(1,encodednegwstddev.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "                deltawmean = deltawmean.detach()\n",
        "                deltawstddev = deltawstddev.detach()\n",
        "\n",
        "                if (sasearch):\n",
        "\n",
        "\n",
        "                    weightwmean = encodedposwmean.mean(dim=0)\n",
        "                    weightwmean = weightwmean.view(1, encodedposwmean.shape[1])\n",
        "\n",
        "                    weightwstddev = encodedposwstddev.mean(dim=0)\n",
        "                    weightwstddev = weightwstddev.view(1, encodedposwstddev.shape[1])\n",
        "\n",
        "                    weightwmean = torch.zeros(weightwmean.shape, dtype=torch.float).clone()\n",
        "                    weightwstddev = torch.zeros(weightwstddev.shape, dtype=torch.float).clone()\n",
        "\n",
        "                    weightwmeans[classkey], weightwstddevs[classkey] = weightwmean, weightwstddev\n",
        "                    bestweightwmean, bestweightwstddev = weightwmean.clone(), weightwstddev.clone()\n",
        "\n",
        "\n",
        "\n",
        "                else:\n",
        "                    weightwstddev = Variable(torch.FloatTensor(torch.zeros(1, deltawstddev.size(1))), requires_grad=True)\n",
        "                    weightwmean = Variable(torch.FloatTensor(torch.zeros(1, deltawmean.size(1))), requires_grad=True)\n",
        "\n",
        "                playgameflag = True\n",
        "                gameiter = 0\n",
        "                alsiter = 1\n",
        "\n",
        "                while (playgameflag):\n",
        "                    gameiter += 1\n",
        "                    model.load_state_dict(torch.load(args['trainmodelsavepath']))\n",
        "                    alsloopflag = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    if (vggfacesdataset):\n",
        "                        args['error2ssavepath'] = 'data/vae-cdl/vggfaces2manips-error2s-b3' + str(gameiter) + classkey + targetkey + negkey + str(\n",
        "                            args['numsteps']) + str(args['minpercent']) + str(args['mininc']) + str(args['lambda']) + str(codesize) + '.pkl'\n",
        "                        args['manipcostssavepath'] = 'data/vae-cdl/vggfaces2manips-manipcosts-b3' + str(gameiter) + classkey + targetkey + negkey + str(\n",
        "                            args['numsteps']) + str(args['minpercent']) + str(args['mininc']) + str(args['lambda']) + str(codesize) + '.pkl'\n",
        "                        args['fitnessfnvaluessavepath'] = 'data/vae-cdl/vggfaces2manips-fitnessfnvalues-b3' + str(gameiter) + classkey + targetkey + negkey + str(\n",
        "                            args['numsteps']) + str(args['minpercent']) + str(args['mininc']) + str(args['lambda']) + str(codesize) + '.pkl'\n",
        "\n",
        "                        args['weightwmeanssavepath'] = 'data/vae-cdl/vggfaces2manips-weightwmeans-b3' + str(gameiter) + classkey + targetkey + negkey + str(\n",
        "                            args['numsteps']) + str(args['minpercent']) + str(args['mininc']) + str(args['lambda']) + str(codesize) + '.pkl'\n",
        "                        args['weightwstddevssavepath'] = 'data/vae-cdl/vggfaces2manips-weightwstddevs-b3' + str(gameiter) + classkey + targetkey + negkey + str(\n",
        "                            args['numsteps']) + str(args['minpercent']) + str(args['mininc']) + str(args['lambda']) + str(codesize) + '.pkl'\n",
        "\n",
        "\n",
        "\n",
        "                    initialerror2, initialoverallerror2, initialtprserrors = maskedclassifiererror(posnegdata,\n",
        "                                                                                                   posnegtargets,\n",
        "                                                                                                   posindexvector,\n",
        "                                                                                                   negindexvector,\n",
        "                                                                                                   args,\n",
        "                                                                                                   model,\n",
        "                                                                                                   # deltawmean.detach(),\n",
        "                                                                                                   # deltawstddev.detach(),\n",
        "                                                                                                   # weightwmean.detach().numpy()[0],\n",
        "                                                                                                   # weightwstddev.detach().numpy()[0],\n",
        "                                                                                                   # encodedposwmean[0:1],\n",
        "                                                                                                   # encodedposwstddev[0:1],\n",
        "                                                                                                   encodedposwmean,\n",
        "                                                                                                   encodedposwstddev,\n",
        "                                                                                                   deltawmean,\n",
        "                                                                                                   deltawstddev,\n",
        "                                                                                                   weightwmean,\n",
        "                                                                                                   weightwstddev,\n",
        "                                                                                                   autoencodermodel)\n",
        "                    if(klnorm):\n",
        "                        advdata = adversarialmanipulation(posnegdata, posindexvector, negindexvector, deltawmean,\n",
        "                                                          # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                                          encodedposwmean,\n",
        "                                                          encodedposwstddev,\n",
        "                                                          deltawstddev,\n",
        "                                                          weightwmean, weightwstddev, autoencodermodel)\n",
        "\n",
        "                        initialmanipcost = linesearch_loss_function(posnegdata, advdata, autoencodermodel, args)\n",
        "                    if (vectornorm):\n",
        "                        initialmanipcost = torch.norm(weightwmean) + torch.norm(weightwstddev)\n",
        "\n",
        "                    print('initialmanipcost',initialmanipcost)\n",
        "\n",
        "\n",
        "\n",
        "                    initialfitnessfnvalue = (initialerror2 - args['lambda'] * initialmanipcost.item())\n",
        "\n",
        "\n",
        "                    print('weightwmean, weightwstddev', weightwmean, weightwstddev)\n",
        "\n",
        "                    print('initial fitnessfnvalue', initialfitnessfnvalue)\n",
        "                    print('initial error2', initialerror2)\n",
        "                    print('initial manipcost', initialmanipcost)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    start = time.time()\n",
        "\n",
        "\n",
        "                    prevpayoff, preverror2, prevmanipcost = initialfitnessfnvalue, initialerror2, initialmanipcost\n",
        "\n",
        "                    while(alsloopflag):\n",
        "                        print('Alternating least squares attack started for alsiter:', alsiter)\n",
        "\n",
        "\n",
        "                        if(alsiter==1):\n",
        "\n",
        "                            if(attackmean):\n",
        "                                bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost = prevpayoff, preverror2, prevmanipcost\n",
        "                                print(\n",
        "                                    '=========================================Begin Mean Attack======================================================')\n",
        "                                print('bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost before mean attack',bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost)\n",
        "\n",
        "                                bestweightwmeancid, bestweightwmean, bestweightwstddev, bestiterks, bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost = \\\n",
        "                                    linsearch(bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost, args, model,\n",
        "                                              bestweightwmean, bestweightwstddev, True,\n",
        "                                          posnegdata, posnegtargets, posindexvector, negindexvector,\n",
        "                                          deltawmean, deltawstddev, encodedposwmean, encodedposwstddev, autoencodermodel,\n",
        "                                              bestiterks, classkey, gameiter)\n",
        "                                print('bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost after mean attack',bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost)\n",
        "\n",
        "\n",
        "                                # sys.exit()\n",
        "\n",
        "                                payoffdiff = (bestwmeanpayoff - prevpayoff)\n",
        "                                errordiff = (bestwmeanerror2 - preverror2)\n",
        "\n",
        "                                if(not (attackmean and attackvar)):\n",
        "                                    if (payoffdiff > 0):\n",
        "                                        if(controlledthreshold_als):\n",
        "                                            if (bestwmeanerror2 > args['maxerror_als']):\n",
        "                                                alsloopflag = False\n",
        "                                                break\n",
        "                                            else:\n",
        "                                                alsloopflag = True\n",
        "                                        else:\n",
        "                                            alsloopflag = True\n",
        "                                    else:\n",
        "                                        alsloopflag = False\n",
        "\n",
        "\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================End Mean Attack======================================================')\n",
        "                                prevpayoff, preverror2, prevmanipcost = bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost\n",
        "                                print('payoffdiff,alsloopflag,bestweightwmeancid,alsiter',payoffdiff,alsloopflag,bestweightwmeancid,alsiter)\n",
        "\n",
        "\n",
        "                            if(attackvar):\n",
        "                                bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost = prevpayoff, preverror2, prevmanipcost\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================Begin Variance Attack======================================================')\n",
        "\n",
        "                                print('bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost before variance attack',bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost)\n",
        "\n",
        "                                bestweightwstddevcid, bestweightwmean, bestweightwstddev, bestiterks, bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost = \\\n",
        "                                    linsearch(bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost, args, model,\n",
        "                                              bestweightwmean, bestweightwstddev, False,\n",
        "                                          posnegdata, posnegtargets, posindexvector, negindexvector,\n",
        "                                          deltawmean, deltawstddev, encodedposwmean, encodedposwstddev, autoencodermodel,\n",
        "                                              bestiterks, classkey, gameiter)\n",
        "\n",
        "\n",
        "                                print('bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost after variance attack',bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost)\n",
        "\n",
        "                                payoffdiff = (bestwstddevpayoff - prevpayoff)\n",
        "                                errordiff = (bestwstddeverror2 - preverror2)\n",
        "\n",
        "                                if (payoffdiff > 0):\n",
        "                                    if(controlledthreshold_als):\n",
        "                                        if (bestwstddeverror2 > args['maxerror_als']):\n",
        "                                            alsloopflag = False\n",
        "                                            break\n",
        "                                        else:\n",
        "                                            alsloopflag = True\n",
        "                                    else:\n",
        "                                        alsloopflag = True\n",
        "                                else:\n",
        "                                    alsloopflag = False\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================End Variance Attack======================================================')\n",
        "                                prevpayoff, preverror2, prevmanipcost = bestwstddevpayoff, bestwstddeverror2, bestwstddevmanipcost\n",
        "                                print('payoffdiff,alsloopflag,bestweightwstddevcid,alsiter',payoffdiff,alsloopflag,bestweightwstddevcid,alsiter)\n",
        "\n",
        "\n",
        "                            if(not combinedsinglesattack):\n",
        "                                if(not combinedattack):\n",
        "                                    alsiter += 1\n",
        "\n",
        "\n",
        "                        elif(alsiter>1):\n",
        "                            if(attackmean):\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================Begin Mean Attack======================================================')\n",
        "                                bestwmeanpayoff, bestwmeanerror2 = prevpayoff, preverror2\n",
        "                                print('bestwmeanpayoff, bestwmeanerror2 before mean attack',bestwmeanpayoff, bestwmeanerror2)\n",
        "\n",
        "                                bestweightwmean, bestweightwstddev, bestiterks, bestwmeanpayoff, bestwmeanerror2 \\\n",
        "                                    = linsearchloop(bestweightwmeancid, args, True, deltawmean, deltawstddev, bestweightwmean,\n",
        "                                              bestweightwstddev, bestwmeanpayoff, bestwmeanerror2, posnegdata,\n",
        "                                              posnegtargets, posindexvector, negindexvector, model, encodedposwmean,\n",
        "                                              encodedposwstddev, autoencodermodel, bestiterks, classkey, gameiter)\n",
        "\n",
        "                                print('bestwmeanpayoff, bestwmeanerror2 after mean attack',bestwmeanpayoff, bestwmeanerror2)\n",
        "\n",
        "\n",
        "                                payoffdiff = (bestwmeanpayoff - prevpayoff)\n",
        "                                errordiff = (bestwmeanerror2 - preverror2)\n",
        "\n",
        "                                if(not (attackmean and attackvar)):\n",
        "                                    if (payoffdiff > 0):\n",
        "                                        if(controlledthreshold_als):\n",
        "                                            if (bestwmeanerror2 > args['maxerror_als']):\n",
        "                                                alsloopflag = False\n",
        "                                                break\n",
        "                                            else:\n",
        "                                                alsloopflag = True\n",
        "                                        else:\n",
        "                                            alsloopflag = True\n",
        "                                    else:\n",
        "                                        alsloopflag = False\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================End Mean Attack======================================================')\n",
        "                                prevpayoff, preverror2 = bestwmeanpayoff, bestwmeanerror2\n",
        "                                print('payoffdiff,alsloopflag,bestweightwmeancid,alsiter',payoffdiff,alsloopflag,bestweightwmeancid,alsiter)\n",
        "\n",
        "                            if (attackvar):\n",
        "                            # if(not combinedattack):\n",
        "                                print(\n",
        "                                    '=========================================Begin Variance Attack======================================================')\n",
        "                                bestwstddevpayoff, bestwstddeverror2 = prevpayoff, preverror2\n",
        "\n",
        "                                print('bestwstddevpayoff, bestwstddeverror2 before variance attack', bestwstddevpayoff,\n",
        "                                      bestwstddeverror2)\n",
        "\n",
        "                                bestweightwmean, bestweightwstddev, bestiterks, bestwstddevpayoff, bestwstddeverror2 \\\n",
        "                                        = linsearchloop(bestweightwstddevcid, args, False, deltawmean, deltawstddev, bestweightwmean,\n",
        "                                                  bestweightwstddev, bestwstddevpayoff, bestwstddeverror2, posnegdata,\n",
        "                                                  posnegtargets, posindexvector, negindexvector, model, encodedposwmean,\n",
        "                                                  encodedposwstddev, autoencodermodel, bestiterks, classkey, gameiter)\n",
        "\n",
        "                                print('bestwstddevpayoff, bestwstddeverror2 after variance attack',bestwstddevpayoff, bestwstddeverror2)\n",
        "\n",
        "\n",
        "                                payoffdiff = (bestwstddevpayoff - prevpayoff)\n",
        "                                errordiff = (bestwstddeverror2 - preverror2)\n",
        "                                if (payoffdiff > 0):\n",
        "                                    if(controlledthreshold_als):\n",
        "                                        if (bestwstddeverror2 > args['maxerror_als']):\n",
        "                                            alsloopflag = False\n",
        "                                            break\n",
        "                                        else:\n",
        "                                            alsloopflag = True\n",
        "                                    else:\n",
        "                                        alsloopflag = True\n",
        "                                else:\n",
        "                                    alsloopflag = False\n",
        "\n",
        "\n",
        "                                print(\n",
        "                                    '=========================================End Variance Attack======================================================')\n",
        "                                prevpayoff, preverror2 = bestwstddevpayoff, bestwstddeverror2\n",
        "                                print('payoffdiff,alsloopflag,bestweightwstddevcid,alsiter', payoffdiff, alsloopflag, bestweightwstddevcid, alsiter)\n",
        "\n",
        "                            alsiter += 1\n",
        "\n",
        "\n",
        "                        print('Alternating least squares attack completed for alsiter:',alsiter)\n",
        "\n",
        "                    end = time.time()\n",
        "                    print('Alternating least squares search time in hours:',(end - start) / (60*60))\n",
        "\n",
        "                    print('bestweightwmean',bestweightwmean)\n",
        "                    print('bestweightwstddev',bestweightwstddev)\n",
        "                    # sys.exit()\n",
        "\n",
        "                    besterror2, bestoverallerror2, besttprserrors = maskedclassifiererror(posnegdata,\n",
        "                                                                                         posnegtargets,\n",
        "                                                                                         posindexvector,\n",
        "                                                                                         negindexvector,\n",
        "                                                                                         args,\n",
        "                                                                                         model,\n",
        "                                                                                         # deltawmean.detach(),\n",
        "                                                                                         # deltawstddev.detach(),\n",
        "                                                                                         # weightwmean.detach().numpy()[0],\n",
        "                                                                                         # weightwstddev.detach().numpy()[0],\n",
        "                                                                                         #  encodedposwmean[0:1],\n",
        "                                                                                         #  encodedposwstddev[0:1],\n",
        "                                                                                          encodedposwmean,\n",
        "                                                                                          encodedposwstddev,\n",
        "                                                                                          deltawmean,\n",
        "                                                                                          deltawstddev,\n",
        "                                                                                          bestweightwmean,\n",
        "                                                                                          bestweightwstddev,\n",
        "                                                                                          autoencodermodel)\n",
        "                    if(klnorm):\n",
        "                        advdata = adversarialmanipulation(posnegdata, posindexvector, negindexvector, deltawmean,\n",
        "                                                          # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                                          encodedposwmean,\n",
        "                                                          encodedposwstddev,\n",
        "                                                          deltawstddev,\n",
        "                                                          bestweightwmean, bestweightwstddev, autoencodermodel)\n",
        "                        bestmanipcost = linesearch_loss_function(posnegdata, advdata, autoencodermodel, args)\n",
        "\n",
        "                    if(vectornorm):\n",
        "                        bestmanipcost = torch.norm(bestweightwmean) + torch.norm(bestweightwstddev)\n",
        "\n",
        "                    # bestmanipcost = bestmanipcost.detatch()\n",
        "                    bestfitnessfnvalue = (besterror2 - args['lambda'] * bestmanipcost.item())\n",
        "\n",
        "                    gamefitnessfndiff = (bestfitnessfnvalue - initialfitnessfnvalue)\n",
        "                    gamepercentfitnessfndiff = ((bestfitnessfnvalue - initialfitnessfnvalue) / initialfitnessfnvalue) * 100\n",
        "\n",
        "                    gameerrordiff = besterror2 - initialerror2\n",
        "\n",
        "                    print('besterror2', besterror2)\n",
        "                    print('bestmanipcost', bestmanipcost)\n",
        "                    print('bestfitnessfnvalue', bestfitnessfnvalue)\n",
        "\n",
        "                    if (gamefitnessfndiff > 0):\n",
        "\n",
        "                        print('found a valid manipulation across game iters')\n",
        "                        # sys.exit()\n",
        "\n",
        "                        if (controlledthreshold_game):\n",
        "                            if(besterror2 > args['maxerror_game']):\n",
        "                                playgameflag = False\n",
        "                                break\n",
        "                            else:\n",
        "                                playgameflag = True\n",
        "                        else:\n",
        "                            playgameflag = True\n",
        "\n",
        "\n",
        "                        maskedposnegdata = adversarialmanipulation(posnegdata, posindexvector, negindexvector, deltawmean,\n",
        "                                                                   # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                                                   encodedposwmean,\n",
        "                                                                   encodedposwstddev,\n",
        "                                                                   deltawstddev,\n",
        "                                                                   bestweightwmean, bestweightwstddev, autoencodermodel)\n",
        "\n",
        "                        advdata = maskedposnegdata\n",
        "                        advtargets = posnegtargets\n",
        "                        advdata, advtargets = torch.cat((advdata, traindata), 0), torch.cat((advtargets, traintargets), 0)\n",
        "                        adv_train_loader = torch.utils.data.DataLoader(\n",
        "                            torch.utils.data.TensorDataset(advdata, advtargets.long()),\n",
        "                            batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "                        print('advdata.shape',advdata.shape)\n",
        "                        print('advtargets.shape',advtargets.shape)\n",
        "\n",
        "\n",
        "                        if (vggfacesdataset):\n",
        "                            model = models.resnet18(pretrained=True)\n",
        "                            model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "                            model.maxpool = nn.Identity()\n",
        "                            optimizer = torch.optim.SGD(\n",
        "                            [\n",
        "                                {'params': get_parameters(model, bias=False)},\n",
        "                                {'params': get_parameters(model, bias=True), 'lr': args['lr'] * 2,\n",
        "                                 'weight_decay': args['weight_decay']},\n",
        "                            ],\n",
        "                            lr=args['lr'],\n",
        "                            momentum=args['momentum'],\n",
        "                            weight_decay=args['weight_decay'])\n",
        "\n",
        "                        device = torch.device(\"cuda\" if args['cuda'] else \"cpu\")\n",
        "                        model.train()\n",
        "                        model.to(device)\n",
        "\n",
        "                        # model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "                        for epoch in range(1, args['epochs'] + 1):\n",
        "                            train(args, model, adv_train_loader, optimizer, epoch)\n",
        "\n",
        "                        model.cpu()\n",
        "                        torch.save(model.state_dict(), args['trainmodelsavepath'])\n",
        "\n",
        "                    else:\n",
        "                        playgameflag = False\n",
        "\n",
        "                    # initialfitnessfnvalue = bestfitnessfnvalue\n",
        "                    weightwmean, weightwstddev = bestweightwmean.clone(), bestweightwstddev.clone()\n",
        "\n",
        "                    print('splitlabel', splitlabel)\n",
        "                    print('bestiterks', bestiterks)\n",
        "                    print('gamefitnessfndiff', gamefitnessfndiff)\n",
        "                    print('gamefitnessfndiff>0', gamefitnessfndiff>0)\n",
        "\n",
        "                    # sys.exit()\n",
        "\n",
        "                bestwmeans[classkey] = bestweightwmean\n",
        "                bestwstddevs[classkey] = bestweightwstddev\n",
        "\n",
        "                print(classkey, bestwmeans, bestwstddevs)\n",
        "                # print(maskedclassifiererror(posnegdata, posnegtargets, args, model, bestalphas[k], autoencodermodel))\n",
        "                print('argstarget, splitlabel', argstarget, splitlabel)\n",
        "                print('gameiter', gameiter)\n",
        "                print('===============================================End Game================================================')\n",
        "                # sys.exit()\n",
        "\n",
        "        bestwmeansfp = open(args['bestwmeanssavepath'], 'wb')\n",
        "        pickle.dump(bestwmeans, bestwmeansfp)\n",
        "\n",
        "        bestwstddevsfp = open(args['bestwstddevssavepath'], 'wb')\n",
        "        pickle.dump(bestwstddevs, bestwstddevsfp)\n",
        "        print('Saved best adversarial manipulations to disk')\n",
        "        # sys.exit()\n",
        "        # Add this code after the game loop completes (after the pickle.dump operations)\n",
        "\n",
        "        print(\"Generating and saving final manipulated images...\")\n",
        "\n",
        "        # Create directories for final manipulated images\n",
        "        os.makedirs('data/vae-cdl/final_manipulations/', exist_ok=True)\n",
        "        os.makedirs('data/vae-cdl/final_originals/', exist_ok=True)\n",
        "\n",
        "        # Generate final manipulated images for each class combination\n",
        "        for argstarget in args['target']:\n",
        "            for splitlabel in args['negative_target']:\n",
        "                classkey = str(argstarget) + str(splitlabel)\n",
        "\n",
        "                if classkey in bestwmeans and classkey in bestwstddevs:\n",
        "                    print(f\"Generating final images for target {argstarget} vs {splitlabel}...\")\n",
        "\n",
        "                    # Get the original data\n",
        "                    posnegdata = advtraindatasets[argstarget][splitlabel]\n",
        "                    posnegtargets = advtrainlabels[argstarget][splitlabel].float()\n",
        "\n",
        "                    # Create index vectors\n",
        "                    posindexvector = posnegtargets == argstarget\n",
        "                    negindexvector = posnegtargets == splitlabel\n",
        "\n",
        "                    # Encode the data\n",
        "                    encodednegwmean, encodednegwstddev = autoencodermodel.encode(posnegdata[negindexvector])\n",
        "                    encodedposwmean, encodedposwstddev = autoencodermodel.encode(posnegdata[posindexvector])\n",
        "\n",
        "                    # Get delta values\n",
        "                    deltawmean = encodednegwmean.mean(dim=0) - encodedposwmean.mean(dim=0)\n",
        "                    deltawstddev = encodednegwstddev.mean(dim=0) - encodedposwstddev.mean(dim=0)\n",
        "                    deltawmean = deltawmean.view(1, encodednegwmean.shape[1])\n",
        "                    deltawstddev = deltawstddev.view(1, encodednegwstddev.shape[1])\n",
        "\n",
        "                    # Get best weights\n",
        "                    bestweightwmean = bestwmeans[classkey]\n",
        "                    bestweightwstddev = bestwstddevs[classkey]\n",
        "\n",
        "                    # Generate final manipulated images\n",
        "                    final_advdata = adversarialmanipulation(posnegdata, posindexvector, negindexvector,\n",
        "                                                           deltawmean, encodedposwmean, encodedposwstddev,\n",
        "                                                           deltawstddev, bestweightwmean, bestweightwstddev,\n",
        "                                                           autoencodermodel)\n",
        "\n",
        "                    # Save a subset of manipulated images (first 10 from each class)\n",
        "                    num_images_to_save = min(10, posnegdata.shape[0])\n",
        "\n",
        "                    for i in range(num_images_to_save):\n",
        "                        # Original image\n",
        "                        orig_img = posnegdata[i]\n",
        "                        orig_class = posnegtargets[i].item()\n",
        "\n",
        "                        # Manipulated image\n",
        "                        manip_img = final_advdata[i]\n",
        "\n",
        "                        # Resize and save original\n",
        "                        orig_img_resized = transforms.Compose([\n",
        "                            transforms.ToPILImage(),\n",
        "                            transforms.Resize(256),\n",
        "                            transforms.ToTensor()\n",
        "                        ])(orig_img)\n",
        "\n",
        "                        # Resize and save manipulated\n",
        "                        manip_img_resized = transforms.Compose([\n",
        "                            transforms.ToPILImage(),\n",
        "                            transforms.Resize(256),\n",
        "                            transforms.ToTensor()\n",
        "                        ])(manip_img)\n",
        "\n",
        "                        # Save images with descriptive names\n",
        "                        orig_filename = f'data/vae-cdl/final_originals/orig_{argstarget}v{splitlabel}_{i}_class{orig_class}.jpeg'\n",
        "                        manip_filename = f'data/vae-cdl/final_manipulations/manip_{argstarget}v{splitlabel}_{i}_class{orig_class}.jpeg'\n",
        "\n",
        "                        torchvision.utils.save_image(orig_img_resized, orig_filename)\n",
        "                        torchvision.utils.save_image(manip_img_resized, manip_filename)\n",
        "\n",
        "                    print(f\"Saved {num_images_to_save} image pairs for {argstarget} vs {splitlabel}\")\n",
        "\n",
        "        print(\"Final manipulated images saved successfully!\")\n",
        "\n",
        "        game_end = time.time()\n",
        "        print('Game optimization time in hours:', (game_end - game_start) / (60 * 60))\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=== CALCULATING FINAL ERROR2 IMMEDIATELY AFTER OPTIMIZATION ===\")\n",
        "\n",
        "    # Calculate for each target-class combination\n",
        "    argstarget = list(args['target'])[0]\n",
        "    classlabel = list(args['negative_target'])[0]\n",
        "    classkey = str(argstarget) + str(classlabel)\n",
        "\n",
        "    # Load original model\n",
        "    if vggfacesdataset:\n",
        "        orig_model = models.resnet18(pretrained=True)\n",
        "        orig_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        orig_model.maxpool = nn.Identity()\n",
        "\n",
        "    orig_model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "    # Get test data\n",
        "    test_data = advtestdatasets[argstarget][classlabel]\n",
        "    test_targets = advtestlabels[argstarget][classlabel].float()\n",
        "\n",
        "    # Generate adversarial test data using best parameters\n",
        "    pos_idx = test_targets == argstarget\n",
        "    neg_idx = test_targets == classlabel\n",
        "\n",
        "    encoded_neg_mean, encoded_neg_std = autoencodermodel.encode(test_data[neg_idx])\n",
        "    encoded_pos_mean, encoded_pos_std = autoencodermodel.encode(test_data[pos_idx])\n",
        "\n",
        "    delta_mean = encoded_neg_mean.mean(dim=0) - encoded_pos_mean.mean(dim=0)\n",
        "    delta_std = encoded_neg_std.mean(dim=0) - encoded_pos_std.mean(dim=0)\n",
        "    delta_mean = delta_mean.view(1, encoded_neg_mean.shape[1])\n",
        "    delta_std = delta_std.view(1, encoded_neg_std.shape[1])\n",
        "\n",
        "    # Generate adversarial data\n",
        "    adv_test_data = adversarialmanipulation(\n",
        "        test_data, pos_idx, neg_idx, delta_mean,\n",
        "        encoded_pos_mean, encoded_pos_std, delta_std,\n",
        "        bestwmeans[classkey], bestwstddevs[classkey], autoencodermodel\n",
        "    )\n",
        "\n",
        "    # Calculate errors\n",
        "    clean_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(test_data, test_targets.long(), test_data),\n",
        "        batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "    adv_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(adv_test_data, test_targets.long(), adv_test_data),\n",
        "        batch_size=args['test_batch_size'], shuffle=True)\n",
        "\n",
        "    final_error1, _, _ = test(args, orig_model, clean_loader)\n",
        "    final_error2, _, _ = test(args, orig_model, adv_loader)\n",
        "\n",
        "    print(\"=== FINAL ERRORS (CALCULATED EARLY) ===\")\n",
        "    print(f'Final Error1 (Clean): {final_error1}')\n",
        "    print(f'Final Error2 (Adversarial): {final_error2}')\n",
        "    print(f'Attack Effectiveness: {final_error2 - final_error1:.4f}')\n",
        "\n",
        "    bestwmeansfp = open(args['bestwmeanssavepath'], 'rb')\n",
        "    bestwstddevsfp = open(args['bestwstddevssavepath'], 'rb')\n",
        "\n",
        "    bestwmeans = pickle.load(bestwmeansfp)\n",
        "    bestwstddevs = pickle.load(bestwstddevsfp)\n",
        "\n",
        "    print('starwmeans',bestwmeans)\n",
        "    print('starwstddevs',bestwstddevs)\n",
        "\n",
        "\n",
        "    datasetsfp = open(args['advtestdatasetssavepath'], 'rb')\n",
        "    labelsfp = open(args['advtestlabelssavepath'], 'rb')\n",
        "    advtestdatasets = pickle.load(datasetsfp)\n",
        "    advtestlabels = pickle.load(labelsfp)\n",
        "\n",
        "\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "\n",
        "        finaladvtraindata = torch.zeros(0, 3, 64, 64)\n",
        "        finaladvtestdata = torch.zeros(0, 3, 64, 64)\n",
        "        originaladvtestdata = torch.zeros(0, 3, 64, 64)\n",
        "        originaladvtraindata = torch.zeros(0, 3, 64, 64)\n",
        "\n",
        "    finaladvtraintargets = torch.zeros(0, )\n",
        "    finaladvtesttargets = torch.zeros(0, )\n",
        "    originaladvtesttargets = torch.zeros(0, )\n",
        "    originaladvtraintargets = torch.zeros(0, )\n",
        "\n",
        "\n",
        "    argstarget=list(args['target'])[0]\n",
        "    classlabel=list(args['negative_target'])[0]\n",
        "\n",
        "    classkey = str(argstarget) + str(classlabel)\n",
        "    bestweightwmean = bestwmeans[classkey]\n",
        "    bestweightwstddev = bestwstddevs[classkey]\n",
        "\n",
        "    if(benchmarkalphas==False):\n",
        "        posnegtraindata = advtraindatasets[argstarget][classlabel]\n",
        "        posnegtraintargets = advtrainlabels[argstarget][classlabel].float()\n",
        "\n",
        "        posnegtestdata = advtestdatasets[argstarget][classlabel]\n",
        "        posnegtesttargets = advtestlabels[argstarget][classlabel].float()\n",
        "\n",
        "        finaladvtraindata = torch.cat((posnegtraindata, finaladvtraindata), 0)\n",
        "        finaladvtraintargets = torch.cat((posnegtraintargets, finaladvtraintargets), 0)\n",
        "\n",
        "        postraindataindexvector = posnegtraintargets == argstarget\n",
        "        negtraindataindexvector = posnegtraintargets == classlabel\n",
        "        encodednegtraindatawmean, encodednegtraindatawstddev = autoencodermodel.encode(posnegtraindata[negtraindataindexvector])\n",
        "        encodedpostraindatawmean, encodedpostraindatawstddev = autoencodermodel.encode(posnegtraindata[postraindataindexvector])\n",
        "        encodedpostraindatawmean = encodedpostraindatawmean.detach()\n",
        "        encodednegtraindatawmean = encodednegtraindatawmean.detach()\n",
        "        encodedpostraindatawstddev = encodedpostraindatawstddev.detach()\n",
        "        encodednegtraindatawstddev = encodednegtraindatawstddev.detach()\n",
        "        deltawmean_traindata = encodednegtraindatawmean.mean(dim=0) - encodedpostraindatawmean.mean(dim=0)\n",
        "        deltawstddev_traindata = encodednegtraindatawstddev.mean(dim=0) - encodedpostraindatawstddev.mean(dim=0)\n",
        "        deltawmean_traindata = deltawmean_traindata.view(1, encodednegtraindatawmean.shape[1])\n",
        "        deltawstddev_traindata = deltawstddev_traindata.view(1, encodednegtraindatawstddev.shape[1])\n",
        "        maskedposnegtraindata = adversarialmanipulation(posnegtraindata, postraindataindexvector, negtraindataindexvector, deltawmean_traindata,\n",
        "                                                   # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                                   encodedpostraindatawmean,\n",
        "                                                   encodedpostraindatawstddev,\n",
        "                                                   deltawstddev_traindata,\n",
        "                                                   bestweightwmean, bestweightwstddev, autoencodermodel)\n",
        "        maskedposnegtraindata = maskedposnegtraindata.detach()\n",
        "\n",
        "\n",
        "        if (not savemanipulations):\n",
        "            if (mnistdataset):\n",
        "                model = Net()\n",
        "            if (vggfacesdataset):\n",
        "                model = models.resnet18(pretrained=True)\n",
        "                model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "                model.maxpool = nn.Identity()\n",
        "\n",
        "            model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "            besterror2, bestoverallerror2, besttprserrors = maskedclassifiererror(posnegtraindata,\n",
        "                                                                                  posnegtraintargets,\n",
        "                                                                                  postraindataindexvector,\n",
        "                                                                                  negtraindataindexvector,\n",
        "                                                                                  args,\n",
        "                                                                                  model,\n",
        "                                                                                  # deltawmean.detach(),\n",
        "                                                                                  # deltawstddev.detach(),\n",
        "                                                                                  # weightwmean.detach().numpy()[0],\n",
        "                                                                                  # weightwstddev.detach().numpy()[0],\n",
        "                                                                                  #  encodedposwmean[0:1],\n",
        "                                                                                  #  encodedposwstddev[0:1],\n",
        "                                                                                  encodedpostraindatawmean,\n",
        "                                                                                  encodedpostraindatawstddev,\n",
        "                                                                                  deltawmean_traindata,\n",
        "                                                                                  deltawstddev_traindata,\n",
        "                                                                                  bestweightwmean,\n",
        "                                                                                  bestweightwstddev,\n",
        "                                                                                  autoencodermodel)\n",
        "            print('besterror2 train after',besterror2)\n",
        "            print('bestoverallerror2 train after', bestoverallerror2)\n",
        "    # sys.exit()\n",
        "\n",
        "    postestdataindexvector = posnegtesttargets == argstarget\n",
        "    negtestdataindexvector = posnegtesttargets == classlabel\n",
        "    encodednegtestdatawmean, encodednegtestdatawstddev = autoencodermodel.encode(posnegtestdata[negtestdataindexvector])\n",
        "    encodedpostestdatawmean, encodedpostestdatawstddev = autoencodermodel.encode(posnegtestdata[postestdataindexvector])\n",
        "    encodedpostestdatawmean = encodedpostestdatawmean.detach()\n",
        "    encodednegtestdatawmean = encodednegtestdatawmean.detach()\n",
        "    encodedpostestdatawstddev = encodedpostestdatawstddev.detach()\n",
        "    encodednegtestdatawstddev = encodednegtestdatawstddev.detach()\n",
        "    deltawmean_testdata = encodednegtestdatawmean.mean(dim=0) - encodedpostestdatawmean.mean(dim=0)\n",
        "    deltawstddev_testdata = encodednegtestdatawstddev.mean(dim=0) - encodedpostestdatawstddev.mean(dim=0)\n",
        "    deltawmean_testdata = deltawmean_testdata.view(1, encodednegtestdatawmean.shape[1])\n",
        "    deltawstddev_testdata = deltawstddev_testdata.view(1, encodednegtestdatawstddev.shape[1])\n",
        "    maskedposnegtestdata = adversarialmanipulation(posnegtestdata, postestdataindexvector, negtestdataindexvector, deltawmean_testdata,\n",
        "                                               # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                               encodedpostestdatawmean,\n",
        "                                               encodedpostestdatawstddev,\n",
        "                                               deltawstddev_testdata,\n",
        "                                               bestweightwmean, bestweightwstddev, autoencodermodel)\n",
        "\n",
        "    if(benchmarkalphas==False):\n",
        "        print('posnegtestdata.shape',posnegtestdata.shape)\n",
        "        print('deltawmean_traindata.shape',deltawmean_traindata.shape)\n",
        "        print('deltawstddev_traindata.shape',deltawstddev_traindata.shape)\n",
        "        print('encodedpostraindatawmean.shape',encodedpostraindatawmean.shape)\n",
        "        print('encodedpostraindatawstddev.shape',encodedpostraindatawstddev.shape)\n",
        "\n",
        "\n",
        "    maskedposnegtestdata = maskedposnegtestdata.detach()\n",
        "\n",
        "\n",
        "    besterror2, bestoverallerror2, besttprserrors = maskedclassifiererror(posnegtestdata,\n",
        "                                                                          posnegtesttargets,\n",
        "                                                                          postestdataindexvector,\n",
        "                                                                          negtestdataindexvector,\n",
        "                                                                          args,\n",
        "                                                                          model,\n",
        "                                                                          encodedpostestdatawmean,\n",
        "                                                                          encodedpostestdatawstddev,\n",
        "                                                                          deltawmean_testdata,\n",
        "                                                                          deltawstddev_testdata,\n",
        "                                                                          bestweightwmean,\n",
        "                                                                          bestweightwstddev,\n",
        "                                                                          autoencodermodel)\n",
        "\n",
        "\n",
        "    if (not savemanipulations):\n",
        "        if (mnistdataset):\n",
        "            model = Net()\n",
        "        if (vggfacesdataset):\n",
        "            model = models.resnet18(pretrained=True)\n",
        "            model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            model.maxpool = nn.Identity()\n",
        "        model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "        initial_test_data_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(posnegtestdata, posnegtesttargets.long(), posnegtestdata),\n",
        "            batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "        final_error1, final_overallerror1, final_tprserrors1 = test(args, model,\n",
        "                                                                    initial_test_data_loader)  # Train on x-train and test on x-test\n",
        "        print('final error1', final_error1)\n",
        "        print('final overall error1', final_overallerror1)\n",
        "\n",
        "    print('besterror2 test after', besterror2)\n",
        "    print('bestoverallerror2 test after', bestoverallerror2)\n",
        "\n",
        "\n",
        "\n",
        "    originaladvtraindata = torch.cat((posnegtraindata, originaladvtraindata), 0)\n",
        "    originaladvtraintargets = torch.cat((posnegtraintargets, originaladvtraintargets), 0)\n",
        "    finaladvtraindata = torch.cat((maskedposnegtraindata, finaladvtraindata), 0)\n",
        "    finaladvtraintargets = torch.cat((posnegtraintargets, finaladvtraintargets), 0)\n",
        "\n",
        "    if(benchmarkalphas==True):\n",
        "        finaladvtraindata = torch.cat((originaladvtraindata, finaladvtraindata), 0)\n",
        "        finaladvtraintargets = torch.cat((originaladvtraintargets, finaladvtraintargets), 0)\n",
        "    final_adv_train_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(finaladvtraindata, finaladvtraintargets.long()),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "    if (vggfacesdataset):\n",
        "        args['epochs'] = 10\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        model.maxpool = nn.Identity()\n",
        "        optimizer = torch.optim.SGD(\n",
        "            [\n",
        "                {'params': get_parameters(model, bias=False)},\n",
        "                {'params': get_parameters(model, bias=True), 'lr': args['lr'] * 2,\n",
        "                 'weight_decay': args['weight_decay']},\n",
        "            ],\n",
        "            lr=args['lr'],\n",
        "            momentum=args['momentum'],\n",
        "            weight_decay=args['weight_decay'])\n",
        "\n",
        "    device = torch.device(\"cuda\" if args['cuda'] else \"cpu\")\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1, args['epochs'] + 1):\n",
        "        train(args, model, final_adv_train_data_loader, optimizer, epoch)\n",
        "\n",
        "    model.cpu()\n",
        "\n",
        "    originaladvtestdata = torch.cat((posnegtestdata, originaladvtestdata), 0)\n",
        "    originaladvtesttargets = torch.cat((posnegtesttargets, originaladvtesttargets), 0)\n",
        "    finaladvtestdata = torch.cat((maskedposnegtestdata, finaladvtestdata), 0)\n",
        "    finaladvtesttargets = torch.cat((posnegtesttargets, finaladvtesttargets), 0)\n",
        "\n",
        "    if(benchmarkalphas==True):\n",
        "        finaladvtestdata = torch.cat((originaladvtestdata, finaladvtestdata), 0)\n",
        "        finaladvtesttargets = torch.cat((originaladvtesttargets, finaladvtesttargets), 0)\n",
        "    final_adv_test_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(finaladvtestdata, finaladvtesttargets.long(), finaladvtestdata),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "    final_error3_1, final_overallerror3_1, final_tprserrors3_1 = test(args, model, final_adv_test_data_loader)\n",
        "    print('final error3_1', final_error3_1)\n",
        "    print('final overallerror3_1', final_overallerror3_1)\n",
        "    finaladvtraintargets = torch.zeros(0, )\n",
        "    finaladvtesttargets = torch.zeros(0, )\n",
        "    originaladvtesttargets = torch.zeros(0, )\n",
        "    originaladvtraintargets = torch.zeros(0, )\n",
        "\n",
        "    print('bestwmeanssavepath', args['bestwmeanssavepath'])\n",
        "    args['positive_targets'] = [4]\n",
        "    args['negative_target'] = [10]\n",
        "\n",
        "\n",
        "    for argstarget in args['positive_targets']:\n",
        "        for classlabel in args['negative_target']:\n",
        "\n",
        "            posnegtraindata = advtraindatasets[argstarget][classlabel]\n",
        "            posnegtraintargets = advtrainlabels[argstarget][classlabel].float()\n",
        "\n",
        "            finaladvtraindata = torch.cat((posnegtraindata, finaladvtraindata), 0)\n",
        "            finaladvtraintargets = torch.cat((posnegtraintargets, finaladvtraintargets), 0)\n",
        "\n",
        "            classkey = str(argstarget) + str(classlabel)\n",
        "\n",
        "            # TO DO : Update with runs params for each target\n",
        "            if(argstarget==2):\n",
        "                # codesize = 50\n",
        "                args['numsteps'] = 7\n",
        "                args['lambda'] = 0.8\n",
        "                args['target']=set([2])\n",
        "            elif(argstarget==3):\n",
        "                # codesize = 50\n",
        "                args['numsteps'] = 12\n",
        "                args['lambda'] = 0.8\n",
        "                args['target']=set([3])\n",
        "            elif (argstarget == 5):\n",
        "                # codesize = 50\n",
        "                args['numsteps'] = 10\n",
        "                args['lambda'] = 7.0\n",
        "                args['target']=set([5])\n",
        "            elif (argstarget == 6):\n",
        "                # codesize = 50\n",
        "                args['numsteps'] = 15\n",
        "                args['lambda'] = 0.8\n",
        "                args['target']=set([6])\n",
        "            elif (argstarget == 9):\n",
        "                # codesize = 50\n",
        "                args['numsteps'] = 10\n",
        "                args['lambda'] = 0.8\n",
        "                args['target']=set([9])\n",
        "\n",
        "            targetkey = ''.join(map(str, args['target']))\n",
        "\n",
        "            print('bestwmeanssavepath',args['bestwmeanssavepath'])\n",
        "\n",
        "            bestwmeansfp = open(args['bestwmeanssavepath'], 'rb')\n",
        "            bestwstddevsfp = open(args['bestwstddevssavepath'], 'rb')\n",
        "            bestwmeans = pickle.load(bestwmeansfp)\n",
        "            bestwstddevs = pickle.load(bestwstddevsfp)\n",
        "\n",
        "            bestweightwmean = bestwmeans[classkey]\n",
        "            bestweightwstddev = bestwstddevs[classkey]\n",
        "\n",
        "            postraindataindexvector = posnegtraintargets == argstarget\n",
        "            negtraindataindexvector = posnegtraintargets == classlabel\n",
        "            encodednegtraindatawmean, encodednegtraindatawstddev = autoencodermodel.encode(posnegtraindata[negtraindataindexvector])\n",
        "            encodedpostraindatawmean, encodedpostraindatawstddev = autoencodermodel.encode(posnegtraindata[postraindataindexvector])\n",
        "            encodedpostraindatawmean = encodedpostraindatawmean.detach()\n",
        "            encodednegtraindatawmean = encodednegtraindatawmean.detach()\n",
        "            encodedpostraindatawstddev = encodedpostraindatawstddev.detach()\n",
        "            encodednegtraindatawstddev = encodednegtraindatawstddev.detach()\n",
        "            deltawmean_traindata = encodednegtraindatawmean.mean(dim=0) - encodedpostraindatawmean.mean(dim=0)\n",
        "            deltawstddev_traindata = encodednegtraindatawstddev.mean(dim=0) - encodedpostraindatawstddev.mean(dim=0)\n",
        "            deltawmean_traindata = deltawmean_traindata.view(1, encodednegtraindatawmean.shape[1])\n",
        "            deltawstddev_traindata = deltawstddev_traindata.view(1, encodednegtraindatawstddev.shape[1])\n",
        "            maskedposnegtraindata = adversarialmanipulation(posnegtraindata, postraindataindexvector, negtraindataindexvector, deltawmean_traindata,\n",
        "                                                       # encodedposwmean[0:1], encodedposwstddev[0:1],\n",
        "                                                       encodedpostraindatawmean,\n",
        "                                                       encodedpostraindatawstddev,\n",
        "                                                       deltawstddev_traindata,\n",
        "                                                       bestweightwmean, bestweightwstddev, autoencodermodel)\n",
        "            maskedposnegtraindata = maskedposnegtraindata.detach()\n",
        "\n",
        "\n",
        "            originaladvtraindata = torch.cat((posnegtraindata, originaladvtraindata), 0)\n",
        "            originaladvtraintargets = torch.cat((posnegtraintargets, originaladvtraintargets), 0)\n",
        "            finaladvtraindata = torch.cat((maskedposnegtraindata, finaladvtraindata), 0)\n",
        "            finaladvtraintargets = torch.cat((posnegtraintargets, finaladvtraintargets), 0)\n",
        "\n",
        "\n",
        "    finaladvtraindata = torch.cat((originaladvtraindata, finaladvtraindata), 0)\n",
        "    finaladvtraintargets = torch.cat((originaladvtraintargets, finaladvtraintargets), 0)\n",
        "    final_adv_train_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(finaladvtraindata, finaladvtraintargets.long()),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "    for epoch in range(1, args['epochs'] + 1):\n",
        "        # train(args, model, final_adv_train_data_loader, optimizer, 1)\n",
        "        train(args, model, final_adv_train_data_loader, optimizer, epoch)\n",
        "    torch.save(model.state_dict(), args['finaltrainmodelsavepath'])\n",
        "    model.load_state_dict(torch.load(args['finaltrainmodelsavepath']))\n",
        "\n",
        "    final_error3_1, final_overallerror3_1, final_tprserrors3_1 = test(args, model, final_adv_test_data_loader)\n",
        "    print('final error3_1', final_error3_1)\n",
        "    print('final overallerror3_1', final_overallerror3_1)\n",
        "\n",
        "    # sys.exit()\n",
        "\n",
        "\n",
        "\n",
        "    # Clear below after saving manipulated and misclassified images for all input datasets\n",
        "\n",
        "    if(not savemanipulations):\n",
        "        finaladvtestdata = torch.cat((originaladvtestdata, finaladvtestdata), 0)\n",
        "        finaladvtesttargets = torch.cat((originaladvtesttargets, finaladvtesttargets), 0)\n",
        "    # Combining original data with manipulated data because testing error is too high on manipulated data alone.\n",
        "        # To manually find manipulated data remove original data\n",
        "    print('finaladvtestdata.shape',finaladvtestdata.shape)\n",
        "    print('originaladvtestdata.shape',originaladvtestdata.shape)\n",
        "\n",
        "    final_adv_test_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(finaladvtestdata, finaladvtesttargets.long(), finaladvtestdata),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "    if(savemanipulations):\n",
        "        final_adv_test_data_loader = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(finaladvtestdata, finaladvtesttargets.long(), originaladvtestdata),\n",
        "            batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "    initial_test_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(originaladvtestdata, originaladvtesttargets.long(), originaladvtestdata),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "    model = Net()\n",
        "    model.load_state_dict(torch.load(args['initialtrainmodelsavepath']))\n",
        "\n",
        "    if(not savemanipulations):\n",
        "        final_error1, final_overallerror1, final_tprserrors1 = test(args, model,\n",
        "                                                                    initial_test_data_loader)  # Train on x-train and test on x-test\n",
        "        print('final error1', final_error1)\n",
        "        print('final overall error1', final_overallerror1)\n",
        "\n",
        "    final_error2_1, final_overallerror2_1, final_tprserrors2_1 = test(args, model, final_adv_test_data_loader)\n",
        "\n",
        "\n",
        "    finaladvtraindata = torch.cat((originaladvtraindata, finaladvtraindata), 0)\n",
        "    finaladvtraintargets = torch.cat((originaladvtraintargets, finaladvtraintargets), 0)\n",
        "    final_adv_train_data_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(finaladvtraindata, finaladvtraintargets.long()),\n",
        "        batch_size=args['test_batch_size'], shuffle=True, num_workers=4)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "    for epoch in range(1, args['epochs'] + 1):\n",
        "    # train(args, model, final_adv_train_data_loader, optimizer, 1)\n",
        "        train(args, model, final_adv_train_data_loader, optimizer, epoch)\n",
        "    torch.save(model.state_dict(), args['finaltrainmodelsavepath'])\n",
        "\n",
        "    model.load_state_dict(torch.load(args['finaltrainmodelsavepath']))\n",
        "\n",
        "    final_error3_1, final_overallerror3_1, final_tprserrors3_1 = test(args, model, final_adv_test_data_loader)\n",
        "    print('final error3_1', final_error3_1)\n",
        "    print('final overallerror3_1', final_overallerror3_1)\n",
        "\n",
        "    sys.stdout = output_capture.original_stdout\n",
        "    output_capture.close()\n",
        "    print(f\"All output saved to: {log_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20720dd9-a295-4ecf-ba78-c1eadbcaa7ae",
      "metadata": {
        "id": "20720dd9-a295-4ecf-ba78-c1eadbcaa7ae",
        "outputId": "915b00f6-8f9a-456d-886b-9380e7c47b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preprocessing done !\n",
            "data.shape target.shape torch.Size([879, 3, 64, 64]) torch.Size([879])\n",
            "traindata.shape traintargets.shape torch.Size([0, 3, 64, 64]) torch.Size([0])\n",
            "data.shape target.shape torch.Size([890, 3, 64, 64]) torch.Size([890])\n",
            "traindata.shape traintargets.shape torch.Size([879, 3, 64, 64]) torch.Size([879])\n",
            "Training autoencoder and cnn models completed on mnist database. Start game preprocessing on labelsets.\n",
            "Game Data preprocessing done !\n",
            "Game Data postprocessing done !\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\College\\miniconda3\\envs\\tfenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\College\\miniconda3\\envs\\tfenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing labelsets and Loading models done. Start game to generate manipulations.\n",
            "argstarget, splitlabel 0 1\n",
            "=========================================Begin Game======================================================\n",
            "batcherror=====================,savemanipulations 3.125 True\n",
            "batcherror=====================,savemanipulations 3.076923076923077 True\n",
            "batcherror=====================,savemanipulations 4.255319148936165 True\n",
            "batcherror=====================,savemanipulations 4.0000000000000036 True\n",
            "batcherror=====================,savemanipulations 3.7735849056603765 True\n",
            "batcherror=====================,savemanipulations 4.6875 True\n",
            "batcherror=====================,savemanipulations 3.9301310043668103 True\n",
            "batcherror=====================,savemanipulations 3.435114503816794 True\n",
            "batcherror=====================,savemanipulations 3.0100334448160515 True\n",
            "batcherror=====================,savemanipulations 2.6548672566371723 True\n",
            "batcherror=====================,savemanipulations 2.4390243902439046 True\n",
            "batcherror=====================,savemanipulations 2.2277227722772297 True\n",
            "batcherror=====================,savemanipulations 2.050113895216399 True\n",
            "batcherror=====================,savemanipulations 2.3454157782516027 True\n",
            "batcherror=====================,savemanipulations 2.409638554216864 True\n",
            "batcherror=====================,savemanipulations 2.2727272727272707 True\n",
            "batcherror=====================,savemanipulations 2.2927689594356315 True\n",
            "batcherror=====================,savemanipulations 2.5210084033613467 True\n",
            "batcherror=====================,savemanipulations 2.4154589371980673 True\n",
            "batcherror=====================,savemanipulations 2.300613496932513 True\n",
            "batcherror=====================,savemanipulations 2.1929824561403466 True\n",
            "batcherror=====================,savemanipulations 2.0949720670391025 True\n",
            "batcherror=====================,savemanipulations 2.0053475935828846 True\n",
            "batcherror=====================,savemanipulations 1.9305019305019266 True\n",
            "batcherror=====================,savemanipulations 1.8610421836228297 True\n",
            "batcherror=====================,savemanipulations 1.8072289156626509 True\n",
            "batcherror=====================,savemanipulations 1.744186046511631 True\n",
            "batcherror=====================,savemanipulations 1.7064846416382284 True\n",
            "initial train error1 1.7064846416382284  given argstarget, splitlabel  0 1\n",
            "batcherror=====================,savemanipulations 3.125 True\n",
            "batcherror=====================,savemanipulations 3.125 True\n",
            "batcherror=====================,savemanipulations 4.1666666666666625 True\n",
            "batcherror=====================,savemanipulations 4.958677685950407 True\n",
            "batcherror=====================,savemanipulations 5.228758169934644 True\n",
            "incorrectidx.shape torch.Size([64])\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 1\n",
            "origclass 0\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 1\n",
            "origclass 1\n",
            "predclass 1\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 1\n",
            "origclass 1\n",
            "predclass 1\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 1\n",
            "predclass 0\n",
            "origclass 0\n",
            "predclass 0\n",
            "batcherror=====================,savemanipulations 4.918032786885251 True\n",
            "batcherror=====================,savemanipulations 4.545454545454541 True\n",
            "initial test error1 4.545454545454541  given argstarget, splitlabel  0 1\n",
            "torch.Size([890, 128])\n",
            "torch.Size([879, 128])\n",
            "torch.Size([1769])\n",
            "tensor([[ 4.7907e-02, -9.4068e-02, -5.3737e-02,  ..., -1.1999e-01,\n",
            "          1.2115e-01,  1.2993e-01],\n",
            "        [-1.6384e-01,  2.7717e-02,  4.2531e-02,  ..., -1.0033e-01,\n",
            "          2.6799e-02,  3.0165e-01],\n",
            "        [ 7.1693e-02,  1.9607e-01, -7.9906e-03,  ..., -2.4178e-04,\n",
            "          1.1452e-01, -5.9366e-02],\n",
            "        ...,\n",
            "        [ 8.0013e-03,  1.8622e-01, -2.8325e-02,  ..., -2.2916e-01,\n",
            "          2.4722e-01, -1.2631e-01],\n",
            "        [-2.9103e-02, -1.6266e-01,  8.1307e-02,  ..., -4.6930e-02,\n",
            "          8.9942e-02, -1.2268e-01],\n",
            "        [ 4.7077e-02, -1.7354e-02, -2.2136e-02,  ..., -2.5051e-01,\n",
            "         -8.2655e-02,  7.6082e-02]], grad_fn=<AddmmBackward0>) tensor([[ 0.0561, -0.1664,  0.0268,  ...,  0.1320, -0.0728, -0.0336],\n",
            "        [-0.1282, -0.5389, -0.0708,  ...,  0.0198,  0.2459,  0.1707],\n",
            "        [ 0.0058,  0.0089, -0.0152,  ...,  0.0111, -0.0471,  0.0172],\n",
            "        ...,\n",
            "        [ 0.0047,  0.1728,  0.0543,  ...,  0.0768, -0.0459, -0.2131],\n",
            "        [-0.0999, -0.0615, -0.2384,  ...,  0.1625,  0.0149,  0.0970],\n",
            "        [ 0.0692,  0.0582,  0.0820,  ...,  0.1317, -0.1007,  0.1123]],\n",
            "       grad_fn=<AddmmBackward0>) encodedposnegreconwmean, encodedposnegreconwstddev\n",
            "autoencodermodel VAE_VGGFACES2(\n",
            "  (encoder): Encoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mean): Linear(in_features=4096, out_features=128, bias=True)\n",
            "    (logvar): Linear(in_features=4096, out_features=128, bias=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (latent_to_features): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (decoder): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (2): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (5): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (8): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (9): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (10): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (cdl_layer): CDLLayer()\n",
            ")\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.13586956521739468 True\n",
            "batcherror=====================,savemanipulations 0.13003901170350884 True\n",
            "batcherror=====================,savemanipulations 0.12594458438287548 True\n",
            "batcherror=====================,savemanipulations 0.12048192771084709 True\n",
            "batcherror=====================,savemanipulations 0.23148148148147696 True\n",
            "batcherror=====================,savemanipulations 0.22753128555176305 True\n",
            "after encoding+decoding initial error1 0.22753128555176305  given argstarget, splitlabel  0 1\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.7462686567164201 True\n",
            "batcherror=====================,savemanipulations 0.6172839506172867 True\n",
            "batcherror=====================,savemanipulations 0.5025125628140725 True\n",
            "batcherror=====================,savemanipulations 0.43290043290042934 True\n",
            "batcherror=====================,savemanipulations 0.3759398496240629 True\n",
            "batcherror=====================,savemanipulations 0.3311258278145712 True\n",
            "batcherror=====================,savemanipulations 0.5970149253731294 True\n",
            "batcherror=====================,savemanipulations 0.540540540540535 True\n",
            "batcherror=====================,savemanipulations 0.5102040816326481 True\n",
            "batcherror=====================,savemanipulations 0.47961630695443347 True\n",
            "batcherror=====================,savemanipulations 0.4484304932735439 True\n",
            "batcherror=====================,savemanipulations 0.4184100418409997 True\n",
            "batcherror=====================,savemanipulations 0.3968253968253954 True\n",
            "batcherror=====================,savemanipulations 0.37037037037036535 True\n",
            "batcherror=====================,savemanipulations 0.34965034965035446 True\n",
            "batcherror=====================,savemanipulations 0.33277870216306127 True\n",
            "batcherror=====================,savemanipulations 0.31695721077654726 True\n",
            "batcherror=====================,savemanipulations 0.45731707317072656 True\n",
            "batcherror=====================,savemanipulations 0.43478260869564966 True\n",
            "batcherror=====================,savemanipulations 0.4137931034482789 True\n",
            "batcherror=====================,savemanipulations 0.5326231691078598 True\n",
            "batcherror=====================,savemanipulations 0.5115089514066473 True\n",
            "batcherror=====================,savemanipulations 0.4895960832313362 True\n",
            "batcherror=====================,savemanipulations 0.4678362573099393 True\n",
            "batcherror=====================,savemanipulations 0.4550625711035261 True\n",
            "initialmanipcost tensor([16605.2422], grad_fn=<AddBackward0>)\n",
            "weightwmean, weightwstddev tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]]) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "initial fitnessfnvalue -20091.8879843039\n",
            "initial error2 0.4550625711035261\n",
            "initial manipcost tensor([16605.2422], grad_fn=<AddBackward0>)\n",
            "Alternating least squares attack started for alsiter: 1\n",
            "=========================================Begin Mean Attack======================================================\n",
            "bestwmeanpayoff, bestwmeanerror2, bestwmeanmanipcost before mean attack -20091.8879843039 0.4550625711035261 tensor([16605.2422], grad_fn=<AddBackward0>)\n",
            "args[maxiter], args[numsteps], args[mininc] 100 10000003 0.1\n",
            "---------------------------------------Starting SA loops--------------------------------------------\n",
            "cid in optimizemean=True 0\n",
            "epsilon 7.757403608366076e-10\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 0 0 3.052208287812343e-09 7.757403608366076e-10 tensor(0.0078)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.14880952380952328 True\n",
            "batcherror=====================,savemanipulations 0.28169014084507005 True\n",
            "batcherror=====================,savemanipulations 0.2691790040376896 True\n",
            "batcherror=====================,savemanipulations 0.2577319587628857 True\n",
            "batcherror=====================,savemanipulations 0.24420024420024333 True\n",
            "batcherror=====================,savemanipulations 0.23446658851113966 True\n",
            "batcherror=====================,savemanipulations 0.22753128555176305 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 0 0 3.052208287812343e-09 3.052208287812343e-09\n",
            "candidate fitnessfnvalue -260287.42887496445\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff -240195.54089066054\n",
            "candidate error2 0.22753128555176305\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff -0.22753128555176305\n",
            "candidate alphacost 215113.765625\n",
            "Exiting sa for bestweightwmean\n",
            "loopflag False\n",
            "\n",
            "\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.283286118980175 True\n",
            "batcherror=====================,savemanipulations 0.26385224274406704 True\n",
            "batcherror=====================,savemanipulations 0.48192771084337727 True\n",
            "batcherror=====================,savemanipulations 0.44345898004434225 True\n",
            "batcherror=====================,savemanipulations 0.4123711340206171 True\n",
            "batcherror=====================,savemanipulations 0.3913894324853229 True\n",
            "batcherror=====================,savemanipulations 0.36832412523020164 True\n",
            "batcherror=====================,savemanipulations 0.3490401396160525 True\n",
            "batcherror=====================,savemanipulations 0.33057851239669533 True\n",
            "batcherror=====================,savemanipulations 0.3144654088050314 True\n",
            "batcherror=====================,savemanipulations 0.3016591251885359 True\n",
            "batcherror=====================,savemanipulations 0.28860028860029363 True\n",
            "batcherror=====================,savemanipulations 0.277392510402219 True\n",
            "batcherror=====================,savemanipulations 0.26385224274406704 True\n",
            "batcherror=====================,savemanipulations 0.2525252525252486 True\n",
            "batcherror=====================,savemanipulations 0.24271844660194164 True\n",
            "batcherror=====================,savemanipulations 0.2333722287047868 True\n",
            "batcherror=====================,savemanipulations 0.22753128555176305 True\n",
            "\n",
            "\n",
            "weightwmean[0, cid],cid tensor(0.) 0\n",
            "bestweightwmean[0, cid],cid tensor(3.0522e-09) 0\n",
            "bestweightwmean[0, cid] + best_x,cid tensor(3.0522e-09) 0\n",
            "best_x 0\n",
            "best_intererror2,best_intermanipcost,best_fitnessfnvalue 0.22753128555176305 21974.263671875 -26588.631511683197\n",
            "deltawmean[0, cid] tensor(0.0078)\n",
            "args[minpercent] 1\n",
            "bestpidx 0\n",
            "classkey, gameiter 01 1\n",
            "\n",
            "\n",
            "cid in optimizemean=True 1\n",
            "epsilon -7.039924199148118e-09\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 1 0 -7.095534270662191e-09 -7.039924199148118e-09 tensor(-0.0704)\n",
            "batcherror=====================,savemanipulations 3.4482758620689613 True\n",
            "batcherror=====================,savemanipulations 1.5873015873015928 True\n",
            "batcherror=====================,savemanipulations 2.0618556701030966 True\n",
            "batcherror=====================,savemanipulations 1.526717557251911 True\n",
            "batcherror=====================,savemanipulations 1.2903225806451646 True\n",
            "batcherror=====================,savemanipulations 1.0695187165775444 True\n",
            "batcherror=====================,savemanipulations 0.9090909090909038 True\n",
            "batcherror=====================,savemanipulations 1.6064257028112428 True\n",
            "batcherror=====================,savemanipulations 1.4184397163120588 True\n",
            "batcherror=====================,savemanipulations 1.2578616352201255 True\n",
            "batcherror=====================,savemanipulations 1.1494252873563204 True\n",
            "batcherror=====================,savemanipulations 1.0471204188481686 True\n",
            "batcherror=====================,savemanipulations 0.9732360097323589 True\n",
            "batcherror=====================,savemanipulations 0.9216589861751112 True\n",
            "batcherror=====================,savemanipulations 0.8547008547008517 True\n",
            "batcherror=====================,savemanipulations 0.8064516129032251 True\n",
            "batcherror=====================,savemanipulations 0.7677543186180413 True\n",
            "batcherror=====================,savemanipulations 0.7194244604316502 True\n",
            "batcherror=====================,savemanipulations 0.6825938566552892 True\n",
            "batcherror=====================,savemanipulations 0.648298217179899 True\n",
            "batcherror=====================,savemanipulations 0.6153846153846176 True\n",
            "batcherror=====================,savemanipulations 0.5839416058394109 True\n",
            "batcherror=====================,savemanipulations 0.5594405594405605 True\n",
            "batcherror=====================,savemanipulations 0.5305039787798393 True\n",
            "batcherror=====================,savemanipulations 0.5108556832694733 True\n",
            "batcherror=====================,savemanipulations 0.4860267314702349 True\n",
            "batcherror=====================,savemanipulations 0.465657741559955 True\n",
            "batcherror=====================,savemanipulations 0.4550625711035261 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 1 0 -7.095534270662191e-09 -7.095534270662191e-09\n",
            "candidate fitnessfnvalue -12293.759390553896\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff 7798.128593750003\n",
            "candidate error2 0.4550625711035261\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff 0.0\n",
            "candidate alphacost 10160.5078125\n",
            "Invoking search\n",
            "loopflag True\n",
            "\n",
            "\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 1 1 -1.6372803829443597e-08 -7.039924199148118e-09 tensor(-0.0704)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.24630541871921707 True\n",
            "batcherror=====================,savemanipulations 0.2277904328018221 True\n",
            "batcherror=====================,savemanipulations 0.42735042735042583 True\n",
            "batcherror=====================,savemanipulations 0.40160642570281624 True\n",
            "batcherror=====================,savemanipulations 0.3780718336483968 True\n",
            "batcherror=====================,savemanipulations 0.3571428571428559 True\n",
            "batcherror=====================,savemanipulations 0.3372681281618939 True\n",
            "batcherror=====================,savemanipulations 0.3159557661927326 True\n",
            "batcherror=====================,savemanipulations 0.29940119760478723 True\n",
            "batcherror=====================,savemanipulations 0.28530670470755526 True\n",
            "batcherror=====================,savemanipulations 0.2743484224965731 True\n",
            "batcherror=====================,savemanipulations 0.26281208935611255 True\n",
            "batcherror=====================,savemanipulations 0.25094102885822034 True\n",
            "batcherror=====================,savemanipulations 0.24154589371980784 True\n",
            "batcherror=====================,savemanipulations 0.23148148148147696 True\n",
            "batcherror=====================,savemanipulations 0.34129692832765013 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 1 1 -1.6372803829443597e-08 -9.277269558781407e-09\n",
            "candidate fitnessfnvalue -14047.066261665423\n",
            "intermediate fitnessfnvalue -12293.759390553896\n",
            "fitnessfndiff -1753.3068711115266\n",
            "candidate error2 0.34129692832765013\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff -0.11376564277587597\n",
            "candidate alphacost 11609.427734375\n",
            "Exiting sa for bestweightwmean\n",
            "loopflag False\n",
            "\n",
            "\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.5050505050505083 True\n",
            "batcherror=====================,savemanipulations 0.43290043290042934 True\n",
            "batcherror=====================,savemanipulations 0.37878787878787845 True\n",
            "batcherror=====================,savemanipulations 0.6711409395973145 True\n",
            "batcherror=====================,savemanipulations 0.6079027355623046 True\n",
            "batcherror=====================,savemanipulations 0.5571030640668551 True\n",
            "batcherror=====================,savemanipulations 0.5141388174807249 True\n",
            "batcherror=====================,savemanipulations 0.4716981132075526 True\n",
            "batcherror=====================,savemanipulations 0.4366812227074246 True\n",
            "batcherror=====================,savemanipulations 0.40816326530612734 True\n",
            "batcherror=====================,savemanipulations 0.3809523809523818 True\n",
            "batcherror=====================,savemanipulations 0.3610108303249149 True\n",
            "batcherror=====================,savemanipulations 0.34188034188034067 True\n",
            "batcherror=====================,savemanipulations 0.3225806451612856 True\n",
            "batcherror=====================,savemanipulations 0.30816640986132127 True\n",
            "batcherror=====================,savemanipulations 0.295857988165682 True\n",
            "batcherror=====================,savemanipulations 0.5673758865248235 True\n",
            "batcherror=====================,savemanipulations 0.540540540540535 True\n",
            "batcherror=====================,savemanipulations 0.6501950585175553 True\n",
            "batcherror=====================,savemanipulations 0.6242197253433224 True\n",
            "batcherror=====================,savemanipulations 0.6024096385542133 True\n",
            "batcherror=====================,savemanipulations 0.5813953488372103 True\n",
            "batcherror=====================,savemanipulations 0.5688282138794132 True\n",
            "\n",
            "\n",
            "weightwmean[0, cid],cid tensor(0.) 1\n",
            "bestweightwmean[0, cid],cid tensor(-2.3468e-08) 1\n",
            "bestweightwmean[0, cid] + best_x,cid tensor(-3.0564e-08) 1\n",
            "best_x -7.095534270662191e-09\n",
            "best_intererror2,best_intermanipcost,best_fitnessfnvalue 0.5688282138794132 2090.43359375 -2528.8558202236204\n",
            "deltawmean[0, cid] tensor(-0.0704)\n",
            "args[minpercent] 1\n",
            "bestpidx 0\n",
            "classkey, gameiter 01 1\n",
            "\n",
            "\n",
            "cid in optimizemean=True 2\n",
            "epsilon 1.7753722936220129e-09\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 2 0 5.696700997299037e-09 1.7753722936220129e-09 tensor(0.0178)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.21645021645021467 True\n",
            "batcherror=====================,savemanipulations 0.20366598778004397 True\n",
            "batcherror=====================,savemanipulations 0.19305019305019266 True\n",
            "batcherror=====================,savemanipulations 0.3676470588235281 True\n",
            "batcherror=====================,savemanipulations 0.35335689045936647 True\n",
            "batcherror=====================,savemanipulations 0.33444816053511683 True\n",
            "batcherror=====================,savemanipulations 0.3205128205128194 True\n",
            "batcherror=====================,savemanipulations 0.3053435114503844 True\n",
            "batcherror=====================,savemanipulations 0.29197080291970545 True\n",
            "batcherror=====================,savemanipulations 0.2739726027397249 True\n",
            "batcherror=====================,savemanipulations 0.26350461133070047 True\n",
            "batcherror=====================,savemanipulations 0.38022813688213253 True\n",
            "batcherror=====================,savemanipulations 0.36452004860266785 True\n",
            "batcherror=====================,savemanipulations 0.34883720930232176 True\n",
            "batcherror=====================,savemanipulations 0.34129692832765013 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 2 0 5.696700997299037e-09 5.696700997299037e-09\n",
            "candidate fitnessfnvalue -288061.52276557166\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff -267969.6347812678\n",
            "candidate error2 0.34129692832765013\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff -0.11376564277587597\n",
            "candidate alphacost 238067.65625\n",
            "Exiting sa for bestweightwmean\n",
            "loopflag False\n",
            "\n",
            "\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.14792899408283544 True\n",
            "batcherror=====================,savemanipulations 0.2865329512893977 True\n",
            "batcherror=====================,savemanipulations 0.2743484224965731 True\n",
            "batcherror=====================,savemanipulations 0.26350461133070047 True\n",
            "batcherror=====================,savemanipulations 0.25348542458808465 True\n",
            "batcherror=====================,savemanipulations 0.24449877750610804 True\n",
            "batcherror=====================,savemanipulations 0.2336448598130869 True\n",
            "batcherror=====================,savemanipulations 0.22753128555176305 True\n",
            "\n",
            "\n",
            "weightwmean[0, cid],cid tensor(0.) 2\n",
            "bestweightwmean[0, cid],cid tensor(5.6967e-09) 2\n",
            "bestweightwmean[0, cid] + best_x,cid tensor(5.6967e-09) 2\n",
            "best_x 0\n",
            "best_intererror2,best_intermanipcost,best_fitnessfnvalue 0.22753128555176305 1518.9825439453125 -1837.7413468882762\n",
            "deltawmean[0, cid] tensor(0.0178)\n",
            "args[minpercent] 1\n",
            "bestpidx 0\n",
            "classkey, gameiter 01 1\n",
            "\n",
            "\n",
            "cid in optimizemean=True 3\n",
            "epsilon 1.3921808150740844e-09\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 3 0 2.6189368412412714e-09 1.3921808150740844e-09 tensor(0.0139)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.4524886877828038 True\n",
            "batcherror=====================,savemanipulations 0.8000000000000007 True\n",
            "batcherror=====================,savemanipulations 1.0714285714285676 True\n",
            "batcherror=====================,savemanipulations 0.952380952380949 True\n",
            "batcherror=====================,savemanipulations 0.8620689655172376 True\n",
            "batcherror=====================,savemanipulations 0.7894736842105288 True\n",
            "batcherror=====================,savemanipulations 0.7263922518159771 True\n",
            "batcherror=====================,savemanipulations 0.6818181818181834 True\n",
            "batcherror=====================,savemanipulations 0.6355932203389814 True\n",
            "batcherror=====================,savemanipulations 0.7936507936507908 True\n",
            "batcherror=====================,savemanipulations 0.92592592592593 True\n",
            "batcherror=====================,savemanipulations 0.8802816901408494 True\n",
            "batcherror=====================,savemanipulations 0.8264462809917328 True\n",
            "batcherror=====================,savemanipulations 0.7886435331230235 True\n",
            "batcherror=====================,savemanipulations 0.7564296520423563 True\n",
            "batcherror=====================,savemanipulations 0.7204610951008661 True\n",
            "batcherror=====================,savemanipulations 0.6858710562414272 True\n",
            "batcherror=====================,savemanipulations 0.6561679790026198 True\n",
            "batcherror=====================,savemanipulations 0.6265664160400974 True\n",
            "batcherror=====================,savemanipulations 0.6016847172081841 True\n",
            "batcherror=====================,savemanipulations 0.5807200929152101 True\n",
            "batcherror=====================,savemanipulations 0.5688282138794132 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 3 0 2.6189368412412714e-09 2.6189368412412714e-09\n",
            "candidate fitnessfnvalue -1934575103.431172\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff -1934555011.5431876\n",
            "candidate error2 0.5688282138794132\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff 0.11376564277588708\n",
            "candidate alphacost 1598822400.0\n",
            "Invoking jump\n",
            "loopflag True\n",
            "\n",
            "\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 3 1 1.0846884641944993e-08 1.3921808150740844e-09 tensor(0.0139)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 1.4814814814814836 True\n",
            "batcherror=====================,savemanipulations 1.1904761904761862 True\n",
            "batcherror=====================,savemanipulations 1.0204081632653073 True\n",
            "batcherror=====================,savemanipulations 0.9090909090909038 True\n",
            "batcherror=====================,savemanipulations 1.1494252873563204 True\n",
            "batcherror=====================,savemanipulations 1.0309278350515427 True\n",
            "batcherror=====================,savemanipulations 0.9404388714733591 True\n",
            "batcherror=====================,savemanipulations 0.8595988538681931 True\n",
            "batcherror=====================,savemanipulations 0.7832898172323799 True\n",
            "batcherror=====================,savemanipulations 0.7281553398058249 True\n",
            "batcherror=====================,savemanipulations 0.6756756756756799 True\n",
            "batcherror=====================,savemanipulations 0.6315789473684164 True\n",
            "batcherror=====================,savemanipulations 0.5893909626719096 True\n",
            "batcherror=====================,savemanipulations 0.5586592178770999 True\n",
            "batcherror=====================,savemanipulations 0.5253940455341555 True\n",
            "batcherror=====================,savemanipulations 0.5008347245408995 True\n",
            "batcherror=====================,savemanipulations 0.4769475357710662 True\n",
            "batcherror=====================,savemanipulations 0.45731707317072656 True\n",
            "batcherror=====================,savemanipulations 0.4310344827586188 True\n",
            "batcherror=====================,savemanipulations 0.4092769440654842 True\n",
            "batcherror=====================,savemanipulations 0.39113428943937656 True\n",
            "batcherror=====================,savemanipulations 0.37359900373599153 True\n",
            "batcherror=====================,savemanipulations 0.3610108303249149 True\n",
            "batcherror=====================,savemanipulations 0.347222222222221 True\n",
            "batcherror=====================,savemanipulations 0.34129692832765013 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 3 1 1.0846884641944993e-08 2.183495821794907e-09\n",
            "candidate fitnessfnvalue -4565.377167427141\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff 15526.510816876758\n",
            "candidate error2 0.34129692832765013\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff -0.11376564277587597\n",
            "candidate alphacost 3773.321044921875\n",
            "Invoking search\n",
            "loopflag True\n",
            "\n",
            "\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 3 2 1.6160048247335013e-08 1.3921808150740844e-09 tensor(0.0139)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.5347593582887722 True\n",
            "batcherror=====================,savemanipulations 0.4524886877828038 True\n",
            "batcherror=====================,savemanipulations 0.38610038610038533 True\n",
            "batcherror=====================,savemanipulations 0.3401360544217691 True\n",
            "batcherror=====================,savemanipulations 0.30211480362537513 True\n",
            "batcherror=====================,savemanipulations 0.27472527472527375 True\n",
            "batcherror=====================,savemanipulations 0.25510204081632404 True\n",
            "batcherror=====================,savemanipulations 0.2358490566037763 True\n",
            "batcherror=====================,savemanipulations 0.22123893805309214 True\n",
            "batcherror=====================,savemanipulations 0.2083333333333326 True\n",
            "batcherror=====================,savemanipulations 0.1945525291828787 True\n",
            "batcherror=====================,savemanipulations 0.18248175182481452 True\n",
            "batcherror=====================,savemanipulations 0.17152658662092923 True\n",
            "batcherror=====================,savemanipulations 0.16339869281045694 True\n",
            "batcherror=====================,savemanipulations 0.15552099533436836 True\n",
            "batcherror=====================,savemanipulations 0.1481481481481528 True\n",
            "batcherror=====================,savemanipulations 0.14124293785310327 True\n",
            "batcherror=====================,savemanipulations 0.13586956521739468 True\n",
            "batcherror=====================,savemanipulations 0.12970168612191912 True\n",
            "batcherror=====================,savemanipulations 0.12453300124533051 True\n",
            "batcherror=====================,savemanipulations 0.12062726176115257 True\n",
            "batcherror=====================,savemanipulations 0.11641443538998875 True\n",
            "batcherror=====================,savemanipulations 0.11376564277588708 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 3 2 1.6160048247335013e-08 5.313163605390019e-09\n",
            "candidate fitnessfnvalue -16513.928421857225\n",
            "intermediate fitnessfnvalue -4565.377167427141\n",
            "fitnessfndiff -11948.551254430084\n",
            "candidate error2 0.11376564277588708\n",
            "intermediate error2 0.34129692832765013\n",
            "errordiff -0.22753128555176305\n",
            "candidate alphacost 13647.96875\n",
            "Exiting sa for bestweightwmean\n",
            "loopflag False\n",
            "\n",
            "\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 1.9417475728155331 True\n",
            "batcherror=====================,savemanipulations 2.1428571428571463 True\n",
            "batcherror=====================,savemanipulations 1.764705882352946 True\n",
            "batcherror=====================,savemanipulations 1.4851485148514865 True\n",
            "batcherror=====================,savemanipulations 1.276595744680853 True\n",
            "batcherror=====================,savemanipulations 1.1111111111111072 True\n",
            "batcherror=====================,savemanipulations 1.0000000000000009 True\n",
            "batcherror=====================,savemanipulations 0.9146341463414642 True\n",
            "batcherror=====================,savemanipulations 0.8310249307479256 True\n",
            "batcherror=====================,savemanipulations 0.7556675062972307 True\n",
            "batcherror=====================,savemanipulations 0.9324009324009341 True\n",
            "batcherror=====================,savemanipulations 0.8714596949891074 True\n",
            "batcherror=====================,savemanipulations 0.8333333333333304 True\n",
            "batcherror=====================,savemanipulations 0.7858546168958758 True\n",
            "batcherror=====================,savemanipulations 0.7366482504604033 True\n",
            "batcherror=====================,savemanipulations 0.6932409012131768 True\n",
            "batcherror=====================,savemanipulations 0.6504065040650375 True\n",
            "batcherror=====================,savemanipulations 0.6230529595015577 True\n",
            "batcherror=====================,savemanipulations 0.5943536404160454 True\n",
            "batcherror=====================,savemanipulations 0.5706134094151216 True\n",
            "batcherror=====================,savemanipulations 0.6830601092896127 True\n",
            "batcherror=====================,savemanipulations 0.6570302233902758 True\n",
            "batcherror=====================,savemanipulations 0.6321112515802807 True\n",
            "batcherror=====================,savemanipulations 0.6097560975609762 True\n",
            "batcherror=====================,savemanipulations 0.5847953216374324 True\n",
            "batcherror=====================,savemanipulations 0.5688282138794132 True\n",
            "\n",
            "\n",
            "weightwmean[0, cid],cid tensor(0.) 3\n",
            "bestweightwmean[0, cid],cid tensor(2.9626e-08) 3\n",
            "bestweightwmean[0, cid] + best_x,cid tensor(4.0473e-08) 3\n",
            "best_x 1.0846884641944993e-08\n",
            "best_intererror2,best_intermanipcost,best_fitnessfnvalue 0.5688282138794132 4367.15771484375 -5283.692006747058\n",
            "deltawmean[0, cid] tensor(0.0139)\n",
            "args[minpercent] 1\n",
            "bestpidx 1\n",
            "classkey, gameiter 01 1\n",
            "\n",
            "\n",
            "cid in optimizemean=True 4\n",
            "epsilon -2.355375672280502e-09\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 4 0 -3.936759499621111e-09 -2.355375672280502e-09 tensor(-0.0236)\n",
            "batcherror=====================,savemanipulations 4.0000000000000036 True\n",
            "batcherror=====================,savemanipulations 1.7241379310344862 True\n",
            "batcherror=====================,savemanipulations 1.1111111111111072 True\n",
            "batcherror=====================,savemanipulations 0.8333333333333304 True\n",
            "batcherror=====================,savemanipulations 0.6622516556291425 True\n",
            "batcherror=====================,savemanipulations 0.5464480874316946 True\n",
            "batcherror=====================,savemanipulations 0.4587155963302725 True\n",
            "batcherror=====================,savemanipulations 0.40322580645161255 True\n",
            "batcherror=====================,savemanipulations 0.727272727272732 True\n",
            "batcherror=====================,savemanipulations 0.6472491909385147 True\n",
            "batcherror=====================,savemanipulations 0.5934718100890191 True\n",
            "batcherror=====================,savemanipulations 0.5291005291005346 True\n",
            "batcherror=====================,savemanipulations 0.49140049140049546 True\n",
            "batcherror=====================,savemanipulations 0.4576659038901587 True\n",
            "batcherror=====================,savemanipulations 0.8474576271186418 True\n",
            "batcherror=====================,savemanipulations 1.0000000000000009 True\n",
            "batcherror=====================,savemanipulations 0.9293680297397744 True\n",
            "batcherror=====================,savemanipulations 0.8756567425569184 True\n",
            "batcherror=====================,savemanipulations 0.8223684210526327 True\n",
            "batcherror=====================,savemanipulations 0.7874015748031482 True\n",
            "batcherror=====================,savemanipulations 0.7462686567164201 True\n",
            "batcherror=====================,savemanipulations 0.7072135785007094 True\n",
            "batcherror=====================,savemanipulations 0.6756756756756799 True\n",
            "batcherror=====================,savemanipulations 0.6561679790026198 True\n",
            "batcherror=====================,savemanipulations 0.6273525721455453 True\n",
            "batcherror=====================,savemanipulations 0.7263922518159771 True\n",
            "batcherror=====================,savemanipulations 0.6984866123399325 True\n",
            "batcherror=====================,savemanipulations 0.6825938566552892 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 4 0 -3.936759499621111e-09 -3.936759499621111e-09\n",
            "candidate fitnessfnvalue -776212.3511561432\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff -756120.4631718394\n",
            "candidate error2 0.6825938566552892\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff 0.22753128555176305\n",
            "candidate alphacost 641498.375\n",
            "Invoking jump\n",
            "loopflag True\n",
            "\n",
            "\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 4 1 -1.7846524607959967e-08 -2.355375672280502e-09 tensor(-0.0236)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.540540540540535 True\n",
            "batcherror=====================,savemanipulations 0.4608294930875556 True\n",
            "batcherror=====================,savemanipulations 0.39215686274509665 True\n",
            "batcherror=====================,savemanipulations 0.34843205574912606 True\n",
            "batcherror=====================,savemanipulations 0.30864197530864335 True\n",
            "batcherror=====================,savemanipulations 0.28571428571428914 True\n",
            "batcherror=====================,savemanipulations 0.26385224274406704 True\n",
            "batcherror=====================,savemanipulations 0.24096385542168308 True\n",
            "batcherror=====================,savemanipulations 0.22271714922048602 True\n",
            "batcherror=====================,savemanipulations 0.20703933747412417 True\n",
            "batcherror=====================,savemanipulations 0.19493177387914784 True\n",
            "batcherror=====================,savemanipulations 0.18621973929237035 True\n",
            "batcherror=====================,savemanipulations 0.17482517482517723 True\n",
            "batcherror=====================,savemanipulations 0.16501650165016146 True\n",
            "batcherror=====================,savemanipulations 0.15822784810126667 True\n",
            "batcherror=====================,savemanipulations 0.1506024096385561 True\n",
            "batcherror=====================,savemanipulations 0.14306151645206988 True\n",
            "batcherror=====================,savemanipulations 0.13642564802183177 True\n",
            "batcherror=====================,savemanipulations 0.13089005235602524 True\n",
            "batcherror=====================,savemanipulations 0.12594458438287548 True\n",
            "batcherror=====================,savemanipulations 0.12180267965895553 True\n",
            "batcherror=====================,savemanipulations 0.1168224299065379 True\n",
            "batcherror=====================,savemanipulations 0.11376564277588708 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 4 1 -1.7846524607959967e-08 -7.516046331165898e-09\n",
            "candidate fitnessfnvalue -19847454.43623436\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff -19827362.548250053\n",
            "candidate error2 0.11376564277588708\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff -0.341296928327639\n",
            "candidate alphacost 16402855.0\n",
            "Exiting sa for bestweightwmean\n",
            "loopflag False\n",
            "\n",
            "\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 1.098901098901095 True\n",
            "batcherror=====================,savemanipulations 0.8000000000000007 True\n",
            "batcherror=====================,savemanipulations 0.6289308176100628 True\n",
            "batcherror=====================,savemanipulations 0.5181347150259086 True\n",
            "batcherror=====================,savemanipulations 0.9049773755656076 True\n",
            "batcherror=====================,savemanipulations 1.1627906976744207 True\n",
            "batcherror=====================,savemanipulations 1.0273972602739767 True\n",
            "batcherror=====================,savemanipulations 0.9146341463414642 True\n",
            "batcherror=====================,savemanipulations 1.1111111111111072 True\n",
            "batcherror=====================,savemanipulations 1.0282776349614386 True\n",
            "batcherror=====================,savemanipulations 0.9615384615384581 True\n",
            "batcherror=====================,savemanipulations 0.8908685968819552 True\n",
            "batcherror=====================,savemanipulations 0.8298755186721962 True\n",
            "batcherror=====================,savemanipulations 0.7766990291262155 True\n",
            "batcherror=====================,savemanipulations 0.727272727272732 True\n",
            "batcherror=====================,savemanipulations 0.692041522491349 True\n",
            "batcherror=====================,savemanipulations 0.658978583196046 True\n",
            "batcherror=====================,savemanipulations 0.6259780907668211 True\n",
            "batcherror=====================,savemanipulations 0.6024096385542133 True\n",
            "batcherror=====================,savemanipulations 0.5730659025787954 True\n",
            "batcherror=====================,savemanipulations 0.5471956224350261 True\n",
            "batcherror=====================,savemanipulations 0.520833333333337 True\n",
            "batcherror=====================,savemanipulations 0.5012531328320802 True\n",
            "batcherror=====================,savemanipulations 0.4778972520907976 True\n",
            "batcherror=====================,savemanipulations 0.4645760743321681 True\n",
            "batcherror=====================,savemanipulations 0.4550625711035261 True\n",
            "\n",
            "\n",
            "weightwmean[0, cid],cid tensor(0.) 4\n",
            "bestweightwmean[0, cid],cid tensor(-2.1783e-08) 4\n",
            "bestweightwmean[0, cid] + best_x,cid tensor(-2.1783e-08) 4\n",
            "best_x 0\n",
            "best_intererror2,best_intermanipcost,best_fitnessfnvalue 0.4550625711035261 682118.875 -825363.3836874289\n",
            "deltawmean[0, cid] tensor(-0.0236)\n",
            "args[minpercent] 1\n",
            "bestpidx 0\n",
            "classkey, gameiter 01 1\n",
            "\n",
            "\n",
            "cid in optimizemean=True 5\n",
            "epsilon 1.8001453661042888e-09\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 5 0 7.309927197920771e-09 1.8001453661042888e-09 tensor(0.0180)\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.0 True\n",
            "batcherror=====================,savemanipulations 0.25706940874036244 True\n",
            "batcherror=====================,savemanipulations 0.23866348448687846 True\n",
            "batcherror=====================,savemanipulations 0.22271714922048602 True\n",
            "batcherror=====================,savemanipulations 0.20790020790020236 True\n",
            "batcherror=====================,savemanipulations 0.19342359767892114 True\n",
            "batcherror=====================,savemanipulations 0.18382352941176405 True\n",
            "batcherror=====================,savemanipulations 0.17513134851138146 True\n",
            "batcherror=====================,savemanipulations 0.16474464579900872 True\n",
            "batcherror=====================,savemanipulations 0.15600624024960652 True\n",
            "batcherror=====================,savemanipulations 0.2962962962962945 True\n",
            "batcherror=====================,savemanipulations 0.42613636363636465 True\n",
            "batcherror=====================,savemanipulations 0.40816326530612734 True\n",
            "batcherror=====================,savemanipulations 0.39113428943937656 True\n",
            "batcherror=====================,savemanipulations 0.37688442211055717 True\n",
            "batcherror=====================,savemanipulations 0.48192771084337727 True\n",
            "batcherror=====================,savemanipulations 0.46511627906976605 True\n",
            "batcherror=====================,savemanipulations 0.4550625711035261 True\n",
            "\n",
            "\n",
            "cid, searchiter, x,x_step 5 0 7.309927197920771e-09 7.309927197920771e-09\n",
            "candidate fitnessfnvalue -7483.794922780458\n",
            "intermediate fitnessfnvalue -20091.8879843039\n",
            "fitnessfndiff 12608.093061523441\n",
            "candidate error2 0.4550625711035261\n",
            "intermediate error2 0.4550625711035261\n",
            "errordiff 0.0\n",
            "candidate alphacost 6185.33056640625\n",
            "Invoking search\n",
            "loopflag True\n",
            "\n",
            "\n",
            "str(gameiter)+classkey, cid, searchiter, x, epsilon, deltawmean[0, cid] 1:01 5 1 1.4996682252073812e-08 1.8001453661042888e-09 tensor(0.0180)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "playgame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f708f9ae-9288-4f33-b28d-86d6d660a4c1",
      "metadata": {
        "id": "f708f9ae-9288-4f33-b28d-86d6d660a4c1",
        "outputId": "bf98ea82-dfec-4f82-885e-a183628dfae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual 32 features selected: 32\n",
            "Actual 64 features selected: 64\n",
            "Actual 128 features selected: 128\n",
            "[ 23  57  37   8  47  91  27  56 122 103  40  70  54  58  65  80   7  77\n",
            "  63  60  86  15  83  87  39 120  84   1  29  25 118   5  18  22  72 115\n",
            "  66  61  67  51  31  48 110  12  93  16  62  41  30 101  94 126  49  73\n",
            " 125   2  90  17 105  75   4  32  50 108 116 123 109  45   9  85  10  36\n",
            " 121  43 102  78  11 106  21  26  81   0  34  88  59 111 127  44  68   3\n",
            "  53  28  35  92  79 104 117  33  71 100  74  97 113  98  55 112  52  13\n",
            "   6  19  38 124  76  42  24  95 114  89 119  14  69  20  46  96  64  99\n",
            "  82 107]\n",
            "[0.60053474 0.56347847 0.5537612  0.49599534 0.48453644 0.4728507\n",
            " 0.45559973 0.32233465 0.2898386  0.2700378  0.16890667 0.13685752\n",
            " 0.13374539 0.1154585  0.10297903 0.07351716 0.05367621 0.01013344\n",
            " 0.00857582 0.00685169 0.00676725 0.00676474 0.00667672 0.00641071\n",
            " 0.00639319 0.00638682 0.00612646 0.00588784 0.00586006 0.00576418\n",
            " 0.00569854 0.0056411  0.00560971 0.00555301 0.0054854  0.00535033\n",
            " 0.00528337 0.00524408 0.00520082 0.00518573 0.00517397 0.0051652\n",
            " 0.00514386 0.00510901 0.00509213 0.00502027 0.00498622 0.00496146\n",
            " 0.00479541 0.00475291 0.00474397 0.00472291 0.00471229 0.00470274\n",
            " 0.00469273 0.00467214 0.00464439 0.00464298 0.00456286 0.00454256\n",
            " 0.00446096 0.00442361 0.00440312 0.00434667 0.00432512 0.00422672\n",
            " 0.00418195 0.00415621 0.00414849 0.00411996 0.0040961  0.00400694\n",
            " 0.00398674 0.00396939 0.00391185 0.00390979 0.00390718 0.00381731\n",
            " 0.00371599 0.00370838 0.00368885 0.003606   0.00358286 0.00348916\n",
            " 0.00347539 0.00346294 0.00346029 0.00345526 0.00336576 0.00335051\n",
            " 0.00334097 0.00332648 0.00330008 0.00327464 0.00325141 0.00324713\n",
            " 0.00321821 0.00320072 0.00315355 0.00313501 0.00312809 0.0030928\n",
            " 0.0030487  0.00295837 0.00291084 0.00286882 0.0028386  0.00283296\n",
            " 0.00280565 0.00280291 0.00279506 0.00277573 0.00276714 0.00267631\n",
            " 0.0026391  0.00260725 0.00257465 0.00244421 0.0023771  0.00225673\n",
            " 0.00225162 0.00217521 0.0020553  0.00204668 0.00204101 0.00174034\n",
            " 0.00156435 0.00143402]\n"
          ]
        }
      ],
      "source": [
        "# Load and check the actual selections\n",
        "features_32 = np.load('data/vae-cdl/vae-cdl_results/final_selected_features_32.npy')\n",
        "features_64 = np.load('data/vae-cdl/vae-cdl_results/final_selected_features_64.npy')\n",
        "features_128 = np.load('data/vae-cdl/vae-cdl_results/final_selected_features_128.npy')\n",
        "\n",
        "print(f\"Actual 32 features selected: {len(features_32)}\")\n",
        "print(f\"Actual 64 features selected: {len(features_64)}\")\n",
        "print(f\"Actual 128 features selected: {len(features_128)}\")\n",
        "print(features_128)\n",
        "weights_128 = np.load('data/vae-cdl/vae-cdl_results/final_feature_weights_128.npy')\n",
        "features_128 = np.load('data/vae-cdl/vae-cdl_results/final_selected_features_128.npy')\n",
        "print(weights_128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4b9314-85a6-46b8-accb-159f750a09d5",
      "metadata": {
        "id": "4c4b9314-85a6-46b8-accb-159f750a09d5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d758367-6784-4d08-8d28-954600865eec",
      "metadata": {
        "id": "5d758367-6784-4d08-8d28-954600865eec",
        "outputId": "2c8de2bb-b528-458a-fc3b-39ac5a7781f4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'positive_targets_ids' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m Rootdir \u001b[38;5;241m=\u001b[39m negative_test\n\u001b[0;32m     40\u001b[0m positive_target_ids \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 41\u001b[0m \u001b[43mpositive_targets_ids\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbkl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     42\u001b[0m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([positive_targets_ids[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbkl\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m     43\u001b[0m targetkey \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'positive_targets_ids' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f518e0-960a-4063-a470-c930a750aac9",
      "metadata": {
        "id": "07f518e0-960a-4063-a470-c930a750aac9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}